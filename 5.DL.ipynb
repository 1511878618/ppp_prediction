{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "from pytorch_lightning import LightningModule, LightningDataModule\n",
    "import torch\n",
    "from pytorch_lightning import trainer, LightningModule\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    SequentialSampler,\n",
    "    RandomSampler,\n",
    "    WeightedRandomSampler,\n",
    "    Dataset,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TableDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        features: list,\n",
    "        label: list,\n",
    "        covariates: list = None,\n",
    "        num_classes=2,\n",
    "        y_type=\"bt\",\n",
    "    ):\n",
    "        super(Dataset, self).__init__()\n",
    "        assert isinstance(df, pd.DataFrame)\n",
    "        assert isinstance(features, list)\n",
    "        assert isinstance(label, list)\n",
    "\n",
    "        for feature in features + label:\n",
    "            assert feature in df.columns\n",
    "        if covariates:\n",
    "            for cov in covariates:\n",
    "\n",
    "                assert cov in df.columns\n",
    "\n",
    "        if not covariates:\n",
    "\n",
    "            self.df = df.dropna(subset=features + label)\n",
    "        else:\n",
    "            self.df = df.dropna(subset=features + label + covariates)\n",
    "        assert len(self.df) > 0\n",
    "        self.features = features\n",
    "        self.covariates = covariates\n",
    "        self.label = label\n",
    "        self.num_classes = num_classes\n",
    "        self.y_type = y_type\n",
    "        self._init_dataset()\n",
    "\n",
    "    def _init_dataset(self):\n",
    "        X = torch.tensor(self.df[self.features].values).float()\n",
    "        if self.covariates:\n",
    "            X_cov = torch.tensor(self.df[self.covariates].values).float()\n",
    "\n",
    "        y = torch.tensor(self.df[self.label].values)\n",
    "        if (self.num_classes != len(self.label)) and self.y_type == \"bt\":\n",
    "            y = F.one_hot(\n",
    "                torch.tensor(y).long(), num_classes=self.num_classes\n",
    "            ).squeeze()\n",
    "\n",
    "        self.X = X\n",
    "        if self.covariates:\n",
    "            self.X_cov = X_cov\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.covariates:\n",
    "            return (self.X[idx], self.X_cov[idx]), self.y[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class DatasetModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train,\n",
    "        test,\n",
    "        batch_size=32,\n",
    "        features: list = None,\n",
    "        covariates: list = None,\n",
    "        label: list = None,\n",
    "        num_classes=2,\n",
    "        y_type=\"bt\",\n",
    "        num_workers=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.features = features\n",
    "        self.covariates = covariates\n",
    "        self.label = label\n",
    "        self.num_classes = num_classes\n",
    "        self.y_type = y_type\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self._init_dataset(train, test)\n",
    "\n",
    "    def _init_dataset(self, train, test):\n",
    "        train, val = train_test_split(train, test_size=0.2)\n",
    "        print(\n",
    "            f\"Train : {train[self.label].value_counts()}\\nval : {val[self.label].value_counts()}\\nTest : {test[self.label].value_counts()}\"\n",
    "        )\n",
    "        if self.y_type == \"bt\" and len(self.label) == 1:\n",
    "\n",
    "            class_weights = dict(\n",
    "                enumerate(\n",
    "                    class_weight.compute_class_weight(\n",
    "                        \"balanced\",\n",
    "                        classes=np.arange(self.num_classes),\n",
    "                        y=train[self.label[0]],\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            self.class_weights = class_weights\n",
    "\n",
    "        self.train = TableDataset(\n",
    "            df=train,\n",
    "            features=self.features,\n",
    "            label=self.label,\n",
    "            covariates=self.covariates,\n",
    "            num_classes=self.num_classes,\n",
    "            y_type=self.y_type,\n",
    "        )\n",
    "        self.validation = TableDataset(\n",
    "            df=val,\n",
    "            features=self.features,\n",
    "            label=self.label,\n",
    "            covariates=self.covariates,\n",
    "            num_classes=self.num_classes,\n",
    "            y_type=self.y_type,\n",
    "        )\n",
    "        self.test = TableDataset(\n",
    "            df=test,\n",
    "            features=self.features,\n",
    "            label=self.label,\n",
    "            covariates=self.covariates,\n",
    "            num_classes=self.num_classes,\n",
    "            y_type=self.y_type,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        if self.y_type == \"bt\":\n",
    "            train_class_weights = [\n",
    "                self.class_weights[torch.argmax(i).item()] for i in self.train.y\n",
    "            ]\n",
    "            sampler = WeightedRandomSampler(\n",
    "                train_class_weights, len(train_class_weights), replacement=True\n",
    "            )\n",
    "        else:\n",
    "            sampler = RandomSampler(self.train)\n",
    "\n",
    "        return DataLoader(\n",
    "            self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=sampler,\n",
    "            drop_last=True,\n",
    "            persistent_workers=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.validation,\n",
    "            batch_size=self.batch_size,\n",
    "            persistent_workers=True,\n",
    "            num_workers=self.num_workers,\n",
    "            sampler=SequentialSampler(self.validation),\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test,\n",
    "            batch_size=self.batch_size,\n",
    "            persistent_workers=True,\n",
    "            num_workers=self.num_workers,\n",
    "            sampler=SequentialSampler(self.test),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed = pd.read_pickle(\"result/part1/train_imputed.pkl\")\n",
    "test_imputed = pd.read_pickle(\"result/part1/test_imputed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C3',\n",
       " 'KLK7',\n",
       " 'GCHFR',\n",
       " 'NHLRC3',\n",
       " 'APOD',\n",
       " 'GAPDH',\n",
       " 'TP53I3',\n",
       " 'CPA4',\n",
       " 'ANXA2',\n",
       " 'GRSF1',\n",
       " 'IL25',\n",
       " 'HMMR',\n",
       " 'MRPL52',\n",
       " 'PAIP2B',\n",
       " 'THAP12',\n",
       " 'FOS',\n",
       " 'FGF9',\n",
       " 'PITHD1',\n",
       " 'THSD1',\n",
       " 'PTGES2',\n",
       " 'DEFB103A_DEFB103B',\n",
       " 'ATP1B4',\n",
       " 'CYB5A',\n",
       " 'UNC79',\n",
       " 'SLC34A3',\n",
       " 'TAGLN3',\n",
       " 'SLIRP',\n",
       " 'CLASP1',\n",
       " 'PSMC3',\n",
       " 'KIR3DL2',\n",
       " 'BEX3',\n",
       " 'PFDN4',\n",
       " 'BCL7A',\n",
       " 'SMC3',\n",
       " 'SLC28A1',\n",
       " 'CDC123',\n",
       " 'GJA8',\n",
       " 'NMRK2',\n",
       " 'GATA3',\n",
       " 'CPLX2',\n",
       " 'RASGRF1',\n",
       " 'FGF7',\n",
       " 'ANKRA2',\n",
       " 'RBM25',\n",
       " 'LYZL2',\n",
       " 'CDK1',\n",
       " 'CREB3',\n",
       " 'CREBZF',\n",
       " 'IGLON5',\n",
       " 'SHC1',\n",
       " 'ZP4',\n",
       " 'TMOD4',\n",
       " 'CEP152',\n",
       " 'MYH7B',\n",
       " 'CEP350',\n",
       " 'CDC25A',\n",
       " 'TRIM26',\n",
       " 'MANEAL',\n",
       " 'MUCL3',\n",
       " 'GIMAP8',\n",
       " 'CYTH3',\n",
       " 'PDXDC1',\n",
       " 'CLINT1',\n",
       " 'MAPRE3',\n",
       " 'EVI2B',\n",
       " 'STAU1',\n",
       " 'PCNA',\n",
       " 'DNAJA1',\n",
       " 'JMJD1C',\n",
       " 'GAGE2A',\n",
       " 'GAD1',\n",
       " 'IZUMO1',\n",
       " 'PDCL2',\n",
       " 'PDE1C',\n",
       " 'STOML2',\n",
       " 'BSND',\n",
       " 'MAPK13',\n",
       " 'PDIA2',\n",
       " 'BTLA',\n",
       " 'MLLT1',\n",
       " 'TPRKB',\n",
       " 'ARHGAP5',\n",
       " 'BTNL10',\n",
       " 'PHLDB2',\n",
       " 'PDIA5',\n",
       " 'ATF4',\n",
       " 'PRAME',\n",
       " 'TOP1MT',\n",
       " 'KHDC3L',\n",
       " 'DCUN1D2',\n",
       " 'IL3',\n",
       " 'DCLRE1C',\n",
       " 'ERCC1',\n",
       " 'DCDC2C',\n",
       " 'VCPKMT',\n",
       " 'SPRING1',\n",
       " 'MORN4',\n",
       " 'ESPL1',\n",
       " 'H2AP',\n",
       " 'MORF4L2',\n",
       " 'SSH3',\n",
       " 'VWA5A',\n",
       " 'PBK',\n",
       " 'REST',\n",
       " 'SHD',\n",
       " 'TXNL1',\n",
       " 'TPM3',\n",
       " 'NEB',\n",
       " 'ATP1B2',\n",
       " 'CEP112',\n",
       " 'SART1',\n",
       " 'ATP6V1G2',\n",
       " 'ATP2B4',\n",
       " 'SAT1',\n",
       " 'ATP1B1',\n",
       " 'NECAP2',\n",
       " 'ATP5F1D',\n",
       " 'ATP1B3',\n",
       " 'ARNTL',\n",
       " 'ARL2BP',\n",
       " 'SCGB2A2',\n",
       " 'GAMT',\n",
       " 'ASS1',\n",
       " 'NFYA',\n",
       " 'GASK1A',\n",
       " 'MANSC4',\n",
       " 'HMGCS1',\n",
       " 'MMUT',\n",
       " 'CBX2',\n",
       " 'BRD3',\n",
       " 'BRDT',\n",
       " 'MAP1LC3B2',\n",
       " 'CASQ2',\n",
       " 'HIP1',\n",
       " 'GSTM4',\n",
       " 'GUK1',\n",
       " 'CALY',\n",
       " 'C1GALT1C1',\n",
       " 'TEF',\n",
       " 'CACNA1H',\n",
       " 'HADH',\n",
       " 'MEGF11',\n",
       " 'MED21',\n",
       " 'THRAP3',\n",
       " 'SPINK8',\n",
       " 'NAA10',\n",
       " 'MRPL24',\n",
       " 'GBP6',\n",
       " 'MYOM2',\n",
       " 'B3GAT3',\n",
       " 'GCLM',\n",
       " 'MYL1',\n",
       " 'HSD17B3',\n",
       " 'MYH4',\n",
       " 'TMED4',\n",
       " 'TMED10',\n",
       " 'SKIV2L',\n",
       " 'SLC12A2',\n",
       " 'SLC51B',\n",
       " 'MTR',\n",
       " 'CD2',\n",
       " 'BHMT2',\n",
       " 'SNU13',\n",
       " 'GP1BB',\n",
       " 'ARL13B',\n",
       " 'HCG22',\n",
       " 'RYR1',\n",
       " 'FDX2',\n",
       " 'ADRA2A',\n",
       " 'ERVV-1',\n",
       " 'EXOSC10',\n",
       " 'EXTL1',\n",
       " 'CYP24A1',\n",
       " 'KIF1C',\n",
       " 'USP47',\n",
       " 'PRKD2',\n",
       " 'PROCR',\n",
       " 'PACS2',\n",
       " 'KIF22',\n",
       " 'NXPE4',\n",
       " 'RTKN2',\n",
       " 'CSRP3',\n",
       " 'NUDT15',\n",
       " 'UHRF2',\n",
       " 'UGDH',\n",
       " 'CSF2',\n",
       " 'KRT17',\n",
       " 'FDX1',\n",
       " 'PYY',\n",
       " 'UBQLN3',\n",
       " 'CSDE1',\n",
       " 'DDA1',\n",
       " 'PALM3',\n",
       " 'VSIG10L',\n",
       " 'PKD2',\n",
       " 'ABCA2',\n",
       " 'EDEM2',\n",
       " 'ABRAXAS2',\n",
       " 'ECI2',\n",
       " 'PGLYRP4',\n",
       " 'PDZD2',\n",
       " 'EIF2AK3',\n",
       " 'EIF5',\n",
       " 'ELOB',\n",
       " 'ITPA',\n",
       " 'ACSL1',\n",
       " 'DENND2B',\n",
       " 'ZCCHC8',\n",
       " 'ACTN2',\n",
       " 'PDE4D',\n",
       " 'ACY3',\n",
       " 'ENOX2',\n",
       " 'YOD1',\n",
       " 'ENPEP',\n",
       " 'PMCH',\n",
       " 'PMM2',\n",
       " 'DHODH',\n",
       " 'KRT6C',\n",
       " 'NUP50',\n",
       " 'LAMA1',\n",
       " 'COPB2',\n",
       " 'LRCH4',\n",
       " 'TSNAX',\n",
       " 'LPP',\n",
       " 'TRPV3',\n",
       " 'IGHMBP2',\n",
       " 'LILRA4',\n",
       " 'FHIP2A',\n",
       " 'NOP56',\n",
       " 'RIPK4',\n",
       " 'TRAF3IP2',\n",
       " 'IGF2BP3',\n",
       " 'NFKB1',\n",
       " 'NFX1',\n",
       " 'REXO2',\n",
       " 'TSPAN15',\n",
       " 'RBM19',\n",
       " 'FRMD4B',\n",
       " 'NOS2',\n",
       " 'TPR',\n",
       " 'NPR1',\n",
       " 'RAB33A',\n",
       " 'RAB39B',\n",
       " 'RPS10',\n",
       " 'ANK2',\n",
       " 'IFNW1',\n",
       " 'CPTP',\n",
       " 'TTN',\n",
       " 'IL36G',\n",
       " 'IL31RA',\n",
       " 'RNASE4',\n",
       " 'LRIG3',\n",
       " 'CACNA1C',\n",
       " 'SCIN',\n",
       " 'DNLZ',\n",
       " 'STEAP4',\n",
       " 'CBLN1',\n",
       " 'CHP1',\n",
       " 'SAG',\n",
       " 'DOCK9',\n",
       " 'RRP15',\n",
       " 'SYNGAP1',\n",
       " 'CNTF',\n",
       " 'ECSCR',\n",
       " 'ELAVL4',\n",
       " 'FZD8',\n",
       " 'SCN2A',\n",
       " 'CNGB3',\n",
       " 'GABRA4',\n",
       " 'CACNB1',\n",
       " 'DEFB118',\n",
       " 'PNMA2',\n",
       " 'SMS',\n",
       " 'CDH4',\n",
       " 'SH3BGRL2',\n",
       " 'RAB3GAP1',\n",
       " 'RANBP2',\n",
       " 'MYOM1',\n",
       " 'CDKL5',\n",
       " 'CSPG5',\n",
       " 'CTNNA1',\n",
       " 'OMP',\n",
       " 'OTOA',\n",
       " 'GLP1R',\n",
       " 'CEND1',\n",
       " 'SNAP25',\n",
       " 'PCARE',\n",
       " 'FH',\n",
       " 'CORO6',\n",
       " 'SCN3B',\n",
       " 'DCUN1D1',\n",
       " 'NLGN2',\n",
       " 'DEFB104A_DEFB104B',\n",
       " 'DEFB116',\n",
       " 'CRYM',\n",
       " 'SPTBN2',\n",
       " 'GPR101',\n",
       " 'DGCR6',\n",
       " 'GRIN2B',\n",
       " 'ZPR1',\n",
       " 'CD3D',\n",
       " 'HTR1A',\n",
       " 'TFAP2A',\n",
       " 'BLOC1S2',\n",
       " 'IMPG1',\n",
       " 'BRME1',\n",
       " 'KLRC1',\n",
       " 'HTR1B',\n",
       " 'IFNL2',\n",
       " 'VAV3',\n",
       " 'ITPRIP',\n",
       " 'KLF4',\n",
       " 'KIF20B',\n",
       " 'ATXN2',\n",
       " 'TSPAN7',\n",
       " 'BCAT2',\n",
       " 'IGDCC3',\n",
       " 'LELP1',\n",
       " 'TMPRSS11B',\n",
       " 'KCNC4',\n",
       " 'MAP1LC3A',\n",
       " 'BRD2',\n",
       " 'LYPLA2',\n",
       " 'BOLA1',\n",
       " 'ART5',\n",
       " 'AGBL2',\n",
       " 'UPK3A',\n",
       " 'IL13RA2',\n",
       " 'HDAC9',\n",
       " 'ARMCX2',\n",
       " 'KIRREL1',\n",
       " 'TJP3',\n",
       " 'TUBB3',\n",
       " 'ARID3A',\n",
       " 'KRT8',\n",
       " 'BHLHE40',\n",
       " 'ARHGEF5',\n",
       " 'ADGRV1',\n",
       " 'LMOD2',\n",
       " 'GFRAL',\n",
       " 'DNAJB6',\n",
       " 'CD7',\n",
       " 'NAGA',\n",
       " 'PTPN9',\n",
       " 'NDUFA5',\n",
       " 'SCPEP1',\n",
       " 'PRR4',\n",
       " 'CSF3R',\n",
       " 'UNC5D',\n",
       " 'TYRP1',\n",
       " 'SHH',\n",
       " 'GLI2',\n",
       " 'GIPR',\n",
       " 'UBE2Z',\n",
       " 'GAD2',\n",
       " 'SLITRK1',\n",
       " 'BCL2L15',\n",
       " 'TLR1',\n",
       " 'EDNRB',\n",
       " 'NUMB',\n",
       " 'ALPI',\n",
       " 'KLRF1',\n",
       " 'SIRT1',\n",
       " 'HS6ST2',\n",
       " 'GIT1',\n",
       " 'CD36',\n",
       " 'TLR4',\n",
       " 'CSNK1D',\n",
       " 'CSF2RB',\n",
       " 'CD3G',\n",
       " 'RNF168',\n",
       " 'RAP1A',\n",
       " 'FGF12',\n",
       " 'REPS1',\n",
       " 'FOLH1',\n",
       " 'RICTOR',\n",
       " 'TRAF3',\n",
       " 'NFAT5',\n",
       " 'FOXJ3',\n",
       " 'CEBPA',\n",
       " 'TPSG1',\n",
       " 'NEDD9',\n",
       " 'RNF31',\n",
       " 'CEMIP2',\n",
       " 'RPA2',\n",
       " 'CLEC12A',\n",
       " 'NEDD4L',\n",
       " 'S100A13',\n",
       " 'NECTIN1',\n",
       " 'TOP2B',\n",
       " 'TP53BP1',\n",
       " 'SEMA6C',\n",
       " 'RELB',\n",
       " 'FGF16',\n",
       " 'NME1',\n",
       " 'NPHS2',\n",
       " 'NPHS1',\n",
       " 'FGF20',\n",
       " 'RALB',\n",
       " 'FGF3',\n",
       " 'IL12RB2',\n",
       " 'ANKMY2',\n",
       " 'FGF6',\n",
       " 'PTP4A3',\n",
       " 'BAG4',\n",
       " 'CPOX',\n",
       " 'TSPYL1',\n",
       " 'BABAM1',\n",
       " 'LATS1',\n",
       " 'TSC1',\n",
       " 'IGFL4',\n",
       " 'RBPMS',\n",
       " 'CD226',\n",
       " 'NXPH3',\n",
       " 'MTDH',\n",
       " 'DGKA',\n",
       " 'STX7',\n",
       " 'STX5',\n",
       " 'HIF1A',\n",
       " 'EIF4E',\n",
       " 'IL36A',\n",
       " 'CASP9',\n",
       " 'PGR',\n",
       " 'DENR',\n",
       " 'ST8SIA1',\n",
       " 'TGFBR1',\n",
       " 'KDM3A',\n",
       " 'PPL',\n",
       " 'DDX4',\n",
       " 'DDX39A',\n",
       " 'ACP1',\n",
       " 'PDZK1',\n",
       " 'SMPD3',\n",
       " 'MKI67',\n",
       " 'POLR2A',\n",
       " 'POF1B',\n",
       " 'PIKFYVE',\n",
       " 'C1QL2',\n",
       " 'ACRV1',\n",
       " 'ZBP1',\n",
       " 'PLCB1',\n",
       " 'YY1',\n",
       " 'ZNF174',\n",
       " 'ADAM12',\n",
       " 'XIAP',\n",
       " 'EP300',\n",
       " 'TERF1',\n",
       " 'ADAMTS1',\n",
       " 'WASL',\n",
       " 'SUMF1',\n",
       " 'ADAMTS4',\n",
       " 'PPM1B',\n",
       " 'STAT2',\n",
       " 'ERMAP',\n",
       " 'HDAC8',\n",
       " 'DAPK2',\n",
       " 'DAND5',\n",
       " 'IL21R',\n",
       " 'IL31',\n",
       " 'VAMP8',\n",
       " 'IL20RB',\n",
       " 'CCNE1',\n",
       " 'EVI5',\n",
       " 'MRPS16',\n",
       " 'PRR5',\n",
       " 'PRSS22',\n",
       " 'PSMG4',\n",
       " 'AKR7L',\n",
       " 'PER3',\n",
       " 'BLNK',\n",
       " 'CA8',\n",
       " 'DBN1',\n",
       " 'SPRED2',\n",
       " 'PALLD',\n",
       " 'SSBP1',\n",
       " 'BNIP3L',\n",
       " 'VEGFB',\n",
       " 'MCEMP1',\n",
       " 'ITGAL',\n",
       " 'INSR',\n",
       " 'ESR1',\n",
       " 'IFI30',\n",
       " 'CNP',\n",
       " 'NAGK',\n",
       " 'LAMP1',\n",
       " 'TP73',\n",
       " 'PGM2',\n",
       " 'DYNLT1',\n",
       " 'CHM',\n",
       " 'PFDN6',\n",
       " 'TPBGL',\n",
       " 'FZD10',\n",
       " 'CLIC5',\n",
       " 'DTX2',\n",
       " 'CLNS1A',\n",
       " 'RRAS',\n",
       " 'CLGN',\n",
       " 'PDRG1',\n",
       " 'RPGR',\n",
       " 'DUSP29',\n",
       " 'CLEC2L',\n",
       " 'EFNB2',\n",
       " 'CHRM1',\n",
       " 'CIT',\n",
       " 'LRFN2',\n",
       " 'AP2B1',\n",
       " 'FRMD7',\n",
       " 'CRTAP',\n",
       " 'PTH',\n",
       " 'FARSA',\n",
       " 'AKR1B10',\n",
       " 'PSMD5',\n",
       " 'FBN2',\n",
       " 'CUZD1',\n",
       " 'OSTN',\n",
       " 'UROS',\n",
       " 'AIDA',\n",
       " 'PRKAG3',\n",
       " 'NRXN3',\n",
       " 'AMIGO1',\n",
       " 'DCC',\n",
       " 'PPT1',\n",
       " 'ERC2',\n",
       " 'DOC2B',\n",
       " 'RAC3',\n",
       " 'DDX25',\n",
       " 'DDX53',\n",
       " 'TTF2',\n",
       " 'KCNH2',\n",
       " 'DIPK1C',\n",
       " 'RBP1',\n",
       " 'TRIM40',\n",
       " 'NLGN1',\n",
       " 'PMS1',\n",
       " 'COL28A1',\n",
       " 'EPB41L5',\n",
       " 'IFT20',\n",
       " 'CNTNAP4',\n",
       " 'LRP2',\n",
       " 'C2orf69',\n",
       " 'LYSMD3',\n",
       " 'MAG',\n",
       " 'MRI1',\n",
       " 'SCT',\n",
       " 'CASC3',\n",
       " 'LRTM1',\n",
       " 'SLC44A4',\n",
       " 'GTPBP2',\n",
       " 'TDO2',\n",
       " 'SLC1A4',\n",
       " 'SV2A',\n",
       " 'MFAP3L',\n",
       " 'GBA',\n",
       " 'SOX9',\n",
       " 'CAMLG',\n",
       " 'MN1',\n",
       " 'CABP2',\n",
       " 'CCDC28A',\n",
       " 'TMCO5A',\n",
       " 'NAA80',\n",
       " 'TEX101',\n",
       " 'STX1B',\n",
       " 'BATF',\n",
       " 'CADPS',\n",
       " 'LRRC38',\n",
       " 'SEZ6',\n",
       " 'MSLNL',\n",
       " 'MYL6B',\n",
       " 'MDM1',\n",
       " 'SOWAHA',\n",
       " 'LRP2BP',\n",
       " 'SCN2B',\n",
       " 'CD164L2',\n",
       " 'TBR1',\n",
       " 'MYLPF',\n",
       " 'CGN',\n",
       " 'TARM1',\n",
       " 'MICALL2',\n",
       " 'GNGT1',\n",
       " 'SCN3A',\n",
       " 'HNF1A',\n",
       " 'ANXA1',\n",
       " 'SUSD5',\n",
       " 'RBPMS2',\n",
       " 'RANBP1',\n",
       " 'COQ7',\n",
       " 'MYBPC2',\n",
       " 'DMP1',\n",
       " 'ANP32C',\n",
       " 'PRRT3',\n",
       " 'PNMA1',\n",
       " 'HSDL2',\n",
       " 'TMEM132A',\n",
       " 'IGSF21',\n",
       " 'MYL4',\n",
       " 'DLL4',\n",
       " 'DMD',\n",
       " 'MYL3',\n",
       " 'EDN1',\n",
       " 'GIP',\n",
       " 'HSBP1',\n",
       " 'BOLA2_BOLA2B',\n",
       " 'AIF1L',\n",
       " 'OXCT1',\n",
       " 'PAGR1',\n",
       " 'SNED1',\n",
       " 'OPLAH',\n",
       " 'GNPDA1',\n",
       " 'SNX5',\n",
       " 'AHNAK2',\n",
       " 'AHNAK',\n",
       " 'BECN1',\n",
       " 'FAM172A',\n",
       " 'VIPR1',\n",
       " 'HRC',\n",
       " 'KHK',\n",
       " 'POMC',\n",
       " 'HS1BP3',\n",
       " 'NUDT10',\n",
       " 'PYDC1',\n",
       " 'SIL1',\n",
       " 'HMGCL',\n",
       " 'SIGLEC8',\n",
       " 'CRYZL1',\n",
       " 'CCER2',\n",
       " 'LAMB1',\n",
       " 'GRP',\n",
       " 'CBS',\n",
       " 'ADAMTSL4',\n",
       " 'EPPK1',\n",
       " 'LIPF',\n",
       " 'B3GNT7',\n",
       " 'RECK',\n",
       " 'SCRIB',\n",
       " 'SEC31A',\n",
       " 'RNF149',\n",
       " 'COMMD1',\n",
       " 'ATP6V1G1',\n",
       " 'RNF5',\n",
       " 'ROBO4',\n",
       " 'FSHB',\n",
       " 'RPL14',\n",
       " 'CEP170',\n",
       " 'AAMDC',\n",
       " 'EIF2S2',\n",
       " 'SCN4B',\n",
       " 'SEL1L',\n",
       " 'INPP5D',\n",
       " 'FSTL1',\n",
       " 'EHD3',\n",
       " 'PECR',\n",
       " 'ECHS1',\n",
       " 'MECR',\n",
       " 'TOR1AIP1',\n",
       " 'ASRGL1',\n",
       " 'IDO1',\n",
       " 'ZP3',\n",
       " 'GADD45GIP1',\n",
       " 'RNASE10',\n",
       " 'MAN1A2',\n",
       " 'COL2A1',\n",
       " 'NIT1',\n",
       " 'ITPR1',\n",
       " 'ENPP6',\n",
       " 'ENO3',\n",
       " 'LONP1',\n",
       " 'DNAJC6',\n",
       " 'NFE2',\n",
       " 'ENTR1',\n",
       " 'GATD3',\n",
       " 'M6PR',\n",
       " 'CALCOCO2',\n",
       " 'APOBR',\n",
       " 'ECM1',\n",
       " 'ACYP1',\n",
       " 'WFDC1',\n",
       " 'GM2A',\n",
       " 'PLG',\n",
       " 'SH3GL3',\n",
       " 'PCBD1',\n",
       " 'RLN2',\n",
       " 'C1QTNF9',\n",
       " 'SERPINI1',\n",
       " 'GLA',\n",
       " 'CACYBP',\n",
       " 'MARS1',\n",
       " 'HMCN2',\n",
       " 'C7',\n",
       " 'LPA',\n",
       " 'FGA',\n",
       " 'CLEC3B',\n",
       " 'PAXX',\n",
       " 'C1QTNF5',\n",
       " 'MENT',\n",
       " 'ADGRD1',\n",
       " 'VTI1A',\n",
       " 'DAAM1',\n",
       " 'GNPDA2',\n",
       " 'PENK',\n",
       " 'SYAP1',\n",
       " 'ADD1',\n",
       " 'PINLYP',\n",
       " 'JAM3',\n",
       " 'PRKG1',\n",
       " 'ITGA2',\n",
       " 'DNAJB2',\n",
       " 'SNX15',\n",
       " 'DIPK2B',\n",
       " 'TBCA',\n",
       " 'GP5',\n",
       " 'YWHAQ',\n",
       " 'PDE5A',\n",
       " 'DTD1',\n",
       " 'DDI2',\n",
       " 'ADH1B',\n",
       " 'ST13',\n",
       " 'INHBB',\n",
       " 'ERP29',\n",
       " 'PHYKPL',\n",
       " 'MOCS2',\n",
       " 'AFAP1',\n",
       " 'SPART',\n",
       " 'HEG1',\n",
       " 'BMPER',\n",
       " 'PDIA3',\n",
       " 'DCTD',\n",
       " 'MFAP4',\n",
       " 'BMP10',\n",
       " 'SPINK2',\n",
       " 'EPHA4',\n",
       " 'ACHE',\n",
       " 'CHAD',\n",
       " 'UBXN1',\n",
       " 'TNFRSF17',\n",
       " 'SLC9A3R1',\n",
       " 'LZTFL1',\n",
       " 'ARHGAP45',\n",
       " 'AMOT',\n",
       " 'CD72',\n",
       " 'CELSR2',\n",
       " 'GIMAP7',\n",
       " 'SDK2',\n",
       " 'GHR',\n",
       " 'RABEP1',\n",
       " 'CD300A',\n",
       " 'SEMA3G',\n",
       " 'CRELD1',\n",
       " 'RIDA',\n",
       " 'SFRP4',\n",
       " 'MXRA8',\n",
       " 'APPL2',\n",
       " 'MYOM3',\n",
       " 'FGFR4',\n",
       " 'TNFAIP8L2',\n",
       " 'PTRHD1',\n",
       " 'COL5A1',\n",
       " 'FUOM',\n",
       " 'AKAP12',\n",
       " 'CTSE',\n",
       " 'SCGB3A1',\n",
       " 'TPD52L2',\n",
       " 'NAGPA',\n",
       " 'UROD',\n",
       " 'GMPR2',\n",
       " 'SNCA',\n",
       " 'GLRX5',\n",
       " 'KCTD5',\n",
       " 'UPK3BL1',\n",
       " 'TRIM24',\n",
       " 'CTAG1A_CTAG1B',\n",
       " 'FUT1',\n",
       " 'HRAS',\n",
       " 'TET2',\n",
       " 'COL4A4',\n",
       " 'TCN1',\n",
       " 'KLKB1',\n",
       " 'QSOX1',\n",
       " 'CEACAM18',\n",
       " 'EFCAB2',\n",
       " 'NEK7',\n",
       " 'NFKB2',\n",
       " 'CEACAM20',\n",
       " 'RGL2',\n",
       " 'SEPTIN7',\n",
       " 'SAP18',\n",
       " 'ARAF',\n",
       " 'GABARAPL1',\n",
       " 'SAT2',\n",
       " 'ARHGAP30',\n",
       " 'TRDMT1',\n",
       " 'ID4',\n",
       " 'PKN3',\n",
       " 'MAPKAPK2',\n",
       " 'TNPO1',\n",
       " 'TAP1',\n",
       " 'TCP11',\n",
       " 'ITGAX',\n",
       " 'IFIT3',\n",
       " 'ACADM',\n",
       " 'CEP290',\n",
       " 'TAB2',\n",
       " 'GAS2',\n",
       " 'RPE',\n",
       " 'ZNF75D',\n",
       " 'LSM8',\n",
       " 'CENPJ',\n",
       " 'CINP',\n",
       " 'RNF43',\n",
       " 'IFIT1',\n",
       " 'CA7',\n",
       " 'RNF4',\n",
       " 'CENPF',\n",
       " 'TPPP2',\n",
       " 'IL9',\n",
       " 'PAFAH2',\n",
       " 'EPN1',\n",
       " 'COL9A2',\n",
       " 'PPIE',\n",
       " 'TLR2',\n",
       " 'MNAT1',\n",
       " 'ERI1',\n",
       " 'CD3E',\n",
       " 'MAGEA3',\n",
       " 'ALMS1',\n",
       " 'PPP1R12B',\n",
       " 'VPS28',\n",
       " 'PTTG1',\n",
       " 'MORF4L1',\n",
       " 'KIAA1549',\n",
       " 'SPRR1B',\n",
       " 'SLK',\n",
       " 'TK1',\n",
       " 'OFD1',\n",
       " 'KIAA1549L',\n",
       " 'MTHFSD',\n",
       " 'EVPL',\n",
       " 'GADD45B',\n",
       " 'TIGIT',\n",
       " 'CCND2',\n",
       " 'BRD1',\n",
       " 'SHPK',\n",
       " 'VSTM2B',\n",
       " 'TEX33',\n",
       " 'GUCY2C',\n",
       " 'CDH22',\n",
       " 'SERPINH1',\n",
       " 'RAPGEF2',\n",
       " 'PRUNE2',\n",
       " 'MTUS1',\n",
       " 'TMED1',\n",
       " 'GTF2IRD1',\n",
       " 'CASP4',\n",
       " 'OGT',\n",
       " 'RAD51',\n",
       " 'TXK',\n",
       " 'PARD3',\n",
       " 'CD82',\n",
       " 'BCHE',\n",
       " 'SERPINF2',\n",
       " 'SERPINA1',\n",
       " 'SERPINA4',\n",
       " 'SGSH',\n",
       " 'CFB',\n",
       " 'NPC2',\n",
       " 'PRDX2',\n",
       " 'TXN',\n",
       " 'CYB5R2',\n",
       " 'MST1',\n",
       " 'CAT',\n",
       " 'CTBS',\n",
       " 'SERPINF1',\n",
       " 'BRAP',\n",
       " 'HPSE',\n",
       " 'SERPINA5',\n",
       " 'F11',\n",
       " 'MBL2',\n",
       " 'CFHR5',\n",
       " 'IST1',\n",
       " 'PGLYRP2',\n",
       " 'CWC15',\n",
       " 'PALM',\n",
       " 'TTR',\n",
       " 'PSAP',\n",
       " 'ASAH1',\n",
       " 'HGFAC',\n",
       " 'AMOTL2',\n",
       " 'CRISP3',\n",
       " 'NMI',\n",
       " 'EIF2AK2',\n",
       " 'APCS',\n",
       " 'SLURP1',\n",
       " 'DTNB',\n",
       " 'LACRT',\n",
       " 'BTN1A1',\n",
       " 'THTPA',\n",
       " 'MPRIP',\n",
       " 'KLK15',\n",
       " 'RNASE6',\n",
       " 'NAP1L4',\n",
       " 'CDC26',\n",
       " 'LMNB1',\n",
       " 'NUDT16',\n",
       " 'PPBP',\n",
       " 'PF4',\n",
       " 'CFHR2',\n",
       " 'GSR',\n",
       " 'MDH1',\n",
       " 'IL2RG',\n",
       " 'REG3G',\n",
       " 'FNTA',\n",
       " 'RFC4',\n",
       " 'CMIP',\n",
       " 'NUBP1',\n",
       " 'FAM171B',\n",
       " 'NENF',\n",
       " 'AHSA1',\n",
       " 'IL22',\n",
       " 'COMMD9',\n",
       " 'VSIG10',\n",
       " 'KIAA2013',\n",
       " 'RCC1',\n",
       " 'ALDH2',\n",
       " 'UNG',\n",
       " 'VPS4B',\n",
       " 'RALY',\n",
       " 'RAB44',\n",
       " 'PXDNL',\n",
       " 'RAB2B',\n",
       " 'VSIG2',\n",
       " 'KIR2DL2',\n",
       " 'USP25',\n",
       " 'UBE2B',\n",
       " 'LARP1',\n",
       " 'S100A3',\n",
       " 'TDP1',\n",
       " 'CAPN3',\n",
       " 'MINDY1',\n",
       " 'SUSD4',\n",
       " 'TADA3',\n",
       " 'TARS1',\n",
       " 'LRRFIP1',\n",
       " 'TG',\n",
       " 'STAM',\n",
       " 'TGFB2',\n",
       " 'LTB',\n",
       " 'LUZP2',\n",
       " 'MAMDC4',\n",
       " 'HSPA2',\n",
       " 'BCL7B',\n",
       " 'CCDC134',\n",
       " 'GPRC5C',\n",
       " 'LAMTOR5',\n",
       " 'MTSS2',\n",
       " 'NDST1',\n",
       " 'GABARAP',\n",
       " 'CHCHD6',\n",
       " 'NACC1',\n",
       " 'AP1G2',\n",
       " 'TRIM58',\n",
       " 'SLC13A1',\n",
       " 'GPD1',\n",
       " 'SMAD2',\n",
       " 'SMAD3',\n",
       " 'GLYR1',\n",
       " 'SMPDL3B',\n",
       " 'SNX2',\n",
       " 'ARG2',\n",
       " 'SDCCAG8',\n",
       " 'TMEM106A',\n",
       " 'ACRBP',\n",
       " 'DUSP13',\n",
       " 'DYNC1H1',\n",
       " 'EDDM3B',\n",
       " 'DYNLT3',\n",
       " 'WDR46',\n",
       " 'PCDHB15',\n",
       " 'EPGN',\n",
       " 'DHPS',\n",
       " 'IMMT',\n",
       " 'PRC1',\n",
       " 'PPP1CC',\n",
       " 'ERN1',\n",
       " 'ZNRF4',\n",
       " 'ZNF830',\n",
       " 'YJU2',\n",
       " 'PCSK7',\n",
       " 'INSL4',\n",
       " 'ENOPH1',\n",
       " 'ITIH5',\n",
       " 'ENSA',\n",
       " 'TMPRSS11D',\n",
       " 'FTCD',\n",
       " 'PLSCR3',\n",
       " 'SEPTIN8',\n",
       " 'PRKAR2A',\n",
       " 'SMTN',\n",
       " 'NFU1',\n",
       " 'PBXIP1',\n",
       " 'HIP1R',\n",
       " 'ZFYVE19',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteomics = test_imputed.columns[test_imputed.columns.tolist().index(\"C3\") :].tolist()\n",
    "risk_factors = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"ldl_a\",\n",
    "    \"hdl_a\",\n",
    "    \"tc_a\",\n",
    "    \"tg_a\",\n",
    "    \"sbp_a\",\n",
    "    \"BMI\",\n",
    "    \"smoking\",\n",
    "    \"prevalent_diabetes\",\n",
    "]\n",
    "important_protein = [\n",
    "    \"NTproBNP\",\n",
    "    \"MMP12\",\n",
    "    \"REN\",\n",
    "    \"LTBP2\",\n",
    "    \"LGALS4\",\n",
    "    \"LPA\",\n",
    "    \"NRCAM\",\n",
    "    \"CD99\",\n",
    "    \"BCAM\",\n",
    "    \"VWC2\",\n",
    "    \"GCHFR\",\n",
    "    \"SPINT2\",\n",
    "    \"SDC4\",\n",
    "    \"SCN4B\",\n",
    "    \"SERPINA3\",\n",
    "    \"APLP1\",\n",
    "    \"DPY30\",\n",
    "    \"NOTCH3\",\n",
    "    \"DTX3\",\n",
    "    \"CDH3\",\n",
    "]\n",
    "PRS = [\"PRS\"]\n",
    "proteomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : incident_cad\n",
      "0.0             27209\n",
      "1.0              1596\n",
      "dtype: int64\n",
      "val : incident_cad\n",
      "0.0             6799\n",
      "1.0              403\n",
      "dtype: int64\n",
      "Test : incident_cad\n",
      "0.0             14599\n",
      "1.0               833\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15008/3827040605.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y).long(), num_classes=self.num_classes\n",
      "/tmp/ipykernel_15008/3827040605.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y).long(), num_classes=self.num_classes\n",
      "/tmp/ipykernel_15008/3827040605.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y).long(), num_classes=self.num_classes\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetModule(\n",
    "    train=train_imputed,\n",
    "    test=test_imputed,\n",
    "    features=proteomics,\n",
    "    covariates=risk_factors,\n",
    "    label=[\"incident_cad\"],\n",
    "    num_classes=2,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(129)\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.train_dataloader():\n",
    "    # print(x.shape, y.shape)\n",
    "    print(torch.argmax(y, dim=1).sum())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FullyResNetWork(pl.LightningModule):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         hidden_size,\n",
    "#         features,\n",
    "#         output_size,\n",
    "#         # num_resblocks=3,\n",
    "#         lr=1e-3,\n",
    "#         weight_decay=1e-2,\n",
    "#         weight=[1, 1],\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         super(FullyResNetWork, self).__init__()\n",
    "\n",
    "#         input_size = len(features)\n",
    "#         self.features = features\n",
    "#         self.norm = nn.BatchNorm1d(input_size)\n",
    "\n",
    "#         self.sharedNetWork = nn.Sequential(\n",
    "#             nn.Linear(input_size, hidden_size),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(hidden_size, hidden_size),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(hidden_size, hidden_size * 2),\n",
    "#             nn.SiLU(),\n",
    "#         )\n",
    "#         self.ResidualHeadNetwork_1 = nn.Sequential(\n",
    "#             nn.Linear(hidden_size * 2, 256),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(128, 32),\n",
    "#             nn.SiLU(),\n",
    "#         )\n",
    "#         self.ResidualHeadNetwork_2 = nn.Sequential(\n",
    "#             nn.Linear(input_size, 256),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(128, 32),\n",
    "#             nn.SiLU(),\n",
    "#         )\n",
    "#         self.ResidualHeadNetwork_3 = nn.Sequential(\n",
    "#             nn.Linear(32, 128),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(128, output_size),\n",
    "#         )\n",
    "\n",
    "#         self.lr = lr\n",
    "#         self.weight_decay = weight_decay\n",
    "\n",
    "#         self.mertic = {\n",
    "#             \"train_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "#             \"val_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "#         }\n",
    "#         self.history = defaultdict(dict)\n",
    "#         self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(weight).float())\n",
    "\n",
    "#     def forward(self, x):\n",
    "\n",
    "#         x = self.norm(x)\n",
    "\n",
    "#         out = self.sharedNetWork(x)\n",
    "\n",
    "#         out = self.ResidualHeadNetwork_1(out) + self.ResidualHeadNetwork_2(x)\n",
    "#         out = self.ResidualHeadNetwork_3(out)\n",
    "#         return out\n",
    "\n",
    "#     def training_step(self, train_batch, batch_idx):\n",
    "#         x, y = train_batch\n",
    "#         outputs = self.forward(x)\n",
    "#         loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "#         self.mertic[\"train_auc\"].update(\n",
    "#             torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "#         )\n",
    "\n",
    "#         self.log(\"ptl/train_loss\", loss, on_epoch=True, prog_bar=True, on_step=False)\n",
    "#         return loss\n",
    "\n",
    "#     def validation_step(self, val_batch, batch_idx):\n",
    "#         x, y = val_batch\n",
    "#         outputs = self.forward(x)\n",
    "#         loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "#         self.mertic[\"val_auc\"].update(\n",
    "#             torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "#         )\n",
    "\n",
    "#         self.log(\"ptl/val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "#     def on_train_epoch_end(self):\n",
    "\n",
    "#         auc = self.mertic[\"train_auc\"].compute()\n",
    "#         self.log(\"ptl/train_auc\", auc, prog_bar=True)\n",
    "\n",
    "#     def on_validation_epoch_end(self):\n",
    "#         auc = self.mertic[\"val_auc\"].compute()\n",
    "#         self.log(\"ptl/val_auc\", auc, prog_bar=True)\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(\n",
    "#             self.parameters(), lr=self.lr, weight_decay=self.weight_decay\n",
    "#         )\n",
    "#         return optimizer\n",
    "\n",
    "#     def predict_df(self, df, batch_size=256):\n",
    "\n",
    "#         for feature in self.features:\n",
    "#             assert feature in df.columns\n",
    "#         print(f\"input df have NA: {df[self.features].isna().sum(axis=1).sum()}\")\n",
    "#         df = df.copy().dropna(subset=self.features)\n",
    "\n",
    "#         predict_dataloader = DataLoader(\n",
    "#             torch.tensor(df[self.features].values).float(),\n",
    "#             batch_size=batch_size,\n",
    "#             persistent_workers=True,\n",
    "#             num_workers=4,\n",
    "#         )\n",
    "\n",
    "#         self.eval()\n",
    "#         pred = []\n",
    "#         with torch.no_grad():\n",
    "#             for x in predict_dataloader:\n",
    "#                 y_hat = self.forward(x).cpu().detach()\n",
    "#                 y_hat = torch.softmax(y_hat, dim=-1)[:, 1]\n",
    "\n",
    "#                 pred.append(y_hat)\n",
    "#         pred = torch.cat(pred).numpy()\n",
    "#         df[\"pred\"] = pred\n",
    "#         return df\n",
    "\n",
    "\n",
    "# class FullyConnectedNet(pl.LightningModule):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         hidden_size,\n",
    "#         features,\n",
    "#         output_size,\n",
    "#         num_resblocks=3,\n",
    "#         lr=1e-3,\n",
    "#         weight_decay=1e-2,\n",
    "#         weight=[1, 1],\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         super(FullyConnectedNet, self).__init__()\n",
    "#         input_size = len(features)\n",
    "#         self.features = features\n",
    "#         self.norm = nn.BatchNorm1d(input_size)\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "#         self.resblocks = nn.Sequential(\n",
    "#             *[LinearResBlock(hidden_size, hidden_size) for _ in range(num_resblocks)]\n",
    "#         )\n",
    "#         self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "#         self.lr = lr\n",
    "#         self.weight_decay = weight_decay\n",
    "\n",
    "#         self.mertic = {\n",
    "#             \"train_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "#             \"val_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "#         }\n",
    "#         self.history = defaultdict(dict)\n",
    "#         self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(weight).float())\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.norm(x)\n",
    "#         out = torch.relu(self.fc1(x))\n",
    "#         out = self.resblocks(out)\n",
    "#         out = self.fc2(out)\n",
    "#         return out\n",
    "\n",
    "#     def training_step(self, train_batch, batch_idx):\n",
    "#         x, y = train_batch\n",
    "#         outputs = self.forward(x)\n",
    "#         loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "#         self.mertic[\"train_auc\"].update(\n",
    "#             torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "#         )\n",
    "\n",
    "#         self.log(\"ptl/train_loss\", loss, on_epoch=True, prog_bar=True, on_step=False)\n",
    "#         return loss\n",
    "\n",
    "#     def validation_step(self, val_batch, batch_idx):\n",
    "#         x, y = val_batch\n",
    "#         outputs = self.forward(x)\n",
    "#         loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "#         self.mertic[\"val_auc\"].update(\n",
    "#             torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "#         )\n",
    "\n",
    "#         self.log(\"ptl/val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "#     def on_train_epoch_end(self):\n",
    "\n",
    "#         auc = self.mertic[\"train_auc\"].compute()\n",
    "#         self.log(\"ptl/train_auc\", auc, prog_bar=True)\n",
    "\n",
    "#     def on_validation_epoch_end(self):\n",
    "#         auc = self.mertic[\"val_auc\"].compute()\n",
    "#         self.log(\"ptl/val_auc\", auc, prog_bar=True)\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(\n",
    "#             self.parameters(), lr=self.lr, weight_decay=self.weight_decay\n",
    "#         )\n",
    "#         return optimizer\n",
    "\n",
    "#     def predict_df(self, df, batch_size=256):\n",
    "\n",
    "#         for feature in self.features:\n",
    "#             assert feature in df.columns\n",
    "#         print(f\"input df have NA: {df[self.features].isna().sum(axis=1).sum()}\")\n",
    "#         df = df.copy().dropna(subset=self.features)\n",
    "\n",
    "#         predict_dataloader = DataLoader(\n",
    "#             torch.tensor(df[self.features].values).float(),\n",
    "#             batch_size=batch_size,\n",
    "#             persistent_workers=True,\n",
    "#             num_workers=4,\n",
    "#         )\n",
    "\n",
    "#         self.eval()\n",
    "#         pred = []\n",
    "#         with torch.no_grad():\n",
    "#             for x in predict_dataloader:\n",
    "#                 y_hat = self.forward(x).cpu().detach()\n",
    "#                 y_hat = torch.softmax(y_hat, dim=-1)[:, 1]\n",
    "\n",
    "#                 pred.append(y_hat)\n",
    "#         pred = torch.cat(pred).numpy()\n",
    "#         df[\"pred\"] = pred\n",
    "#         return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class LinearResBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=None, dropout=0.1):\n",
    "        super(LinearResBlock, self).__init__()\n",
    "        if d_ff is None:\n",
    "            d_ff = d_model * 2\n",
    "\n",
    "        self.fc1 = nn.Linear(d_model, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # d_model => d_model (default is d_model)\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.dropout1(self.fc1(x))\n",
    "        x = self.norm2(x)\n",
    "        x = x + self.dropout2(self.ff(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearTransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=None, num_classes=0, num_layers=3, dropout=0.1):\n",
    "        super(LinearTransformerEncoder, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            *[\n",
    "                LinearResBlock(d_model, d_ff=d_ff, dropout=dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_norm = (\n",
    "            nn.LayerNorm(d_model, eps=1e-6) if num_classes > 0 else nn.Identity()\n",
    "        )\n",
    "        self.head_drop = nn.Dropout(dropout)\n",
    "        self.head = (\n",
    "            nn.Linear(d_model, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        )\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "\n",
    "        x = self.fc_norm(x)\n",
    "        x = self.head_drop(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearActivationNormDropOut(nn.Module):\n",
    "    def __init__(self, d_in, d_out, activation=nn.SiLU(), dropout=0.1):\n",
    "        super(LinearActivationNormDropOut, self).__init__()\n",
    "        self.fc = nn.Linear(d_in, d_out)\n",
    "        self.norm = nn.LayerNorm(d_out)\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearFeatureExtractor(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=None, d_out=None, dropout=0.1):\n",
    "        super(LinearFeatureExtractor, self).__init__()\n",
    "        if d_ff is None:\n",
    "            d_ff = d_model * 2\n",
    "        if d_out is None:\n",
    "            d_out = d_model\n",
    "\n",
    "        self.extractor = nn.Sequential(\n",
    "            LinearActivationNormDropOut(\n",
    "                d_model, d_ff, activation=nn.SiLU(), dropout=dropout\n",
    "            ),\n",
    "            LinearActivationNormDropOut(\n",
    "                d_ff, d_ff, activation=nn.SiLU(), dropout=dropout\n",
    "            ),\n",
    "            LinearActivationNormDropOut(\n",
    "                d_ff, d_out, activation=nn.SiLU(), dropout=dropout\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.extractor(x)\n",
    "\n",
    "\n",
    "class LinearFeatureFusionBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model_list,\n",
    "        d_ff=128,  # median layer dim. recommanded not to higher than any of d_model passed\n",
    "        d_out=128,\n",
    "        dropout=0.1,\n",
    "        fusion_method=\"add\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        fusion_method: add\n",
    "        \"\"\"\n",
    "        super(LinearFeatureFusionBlock, self).__init__()\n",
    "        self.EachPartModuleList = nn.ModuleList(\n",
    "            [\n",
    "                LinearFeatureExtractor(\n",
    "                    d_model, d_ff=d_model * 2, d_out=d_ff, dropout=dropout\n",
    "                )\n",
    "                for d_model in d_model_list\n",
    "            ]\n",
    "        )\n",
    "        self.d_ff = d_ff\n",
    "        self.fusionDecoder = LinearFeatureExtractor(\n",
    "            d_ff, d_ff=d_ff * 2, d_out=d_out, dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.d_model_list = d_model_list\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.dropout = dropout\n",
    "        self.fusion_method = fusion_method\n",
    "\n",
    "    def intermidiate_forward(self, *x_list):\n",
    "        return [module(x) for module, x in zip(self.EachPartModuleList, x_list)]\n",
    "\n",
    "    def forward(self, *x_list):\n",
    "        x_list = self.intermidiate_forward(*x_list)\n",
    "\n",
    "        if self.fusion_method == \"add\":\n",
    "            x = torch.stack(x_list, dim=-1).sum(dim=-1)\n",
    "        # elif self.fusion_method == \"concat\":\n",
    "        #     x = torch.cat(x_list, dim=-1)\n",
    "        # elif self.fusion_method == \"minus\":\n",
    "        else:\n",
    "            raise NotImplementedError(\"Not implemented\")\n",
    "\n",
    "        x = self.fusionDecoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        features_dict,\n",
    "        covariates_dict=None,\n",
    "        d_ff=128,\n",
    "        num_classes=2,\n",
    "        num_layers=3,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super(LinearTransformer, self).__init__()\n",
    "        self.features_dict = features_dict\n",
    "        self.covariates_dict = covariates_dict if covariates_dict else None\n",
    "        self.features_name = list(features_dict.keys())[0]\n",
    "        self.covariates_name = (\n",
    "            list(covariates_dict.keys())[0] if covariates_dict else None\n",
    "        )\n",
    "        self.features = features_dict[self.features_name]\n",
    "        self.covariates = (\n",
    "            covariates_dict[self.covariates_name] if covariates_dict else None\n",
    "        )\n",
    "\n",
    "        self.d_featurs = len(self.features)\n",
    "        self.d_covariates = len(self.covariates) if covariates_dict else None\n",
    "        self.d_ff = d_ff if d_ff else self.d_featurs\n",
    "\n",
    "        self.encoder = LinearTransformerEncoder(\n",
    "            self.d_featurs,\n",
    "            d_ff=self.d_ff,\n",
    "            num_classes=d_ff,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "        )  # d_features => d_ff\n",
    "\n",
    "        d_model_list = (\n",
    "            [self.d_ff, self.d_covariates]\n",
    "            if self.d_covariates is not None\n",
    "            else [self.d_ff]\n",
    "        )\n",
    "        self.decoder = LinearFeatureFusionBlock(\n",
    "            d_model_list=d_model_list, d_out=d_ff, dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.fc_norm = (\n",
    "            nn.LayerNorm(d_ff, eps=1e-6) if num_classes > 0 else nn.Identity()\n",
    "        )\n",
    "        self.head_drop = nn.Dropout(dropout)\n",
    "        self.head = nn.Linear(d_ff, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def run_encoder(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def forward(self, x, cov=None):\n",
    "\n",
    "        x = self.run_encoder(x)\n",
    "\n",
    "        if cov is not None:\n",
    "            out = self.decoder(x, cov)\n",
    "        else:\n",
    "            out = self.decoder(x)\n",
    "\n",
    "        out = self.fc_norm(out)\n",
    "        out = self.head_drop(out)\n",
    "        out = self.head(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelParametersNum(model):\n",
    "    totalNum = sum([i.numel() for i in model.parameters()])\n",
    "    print(f\"模型总参数个数：{totalNum}\\t占用的总显存为{totalNum*4/1024/1024:.2f}MB\")\n",
    "    return totalNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数个数：288906\t占用的总显存为1.10MB\n",
      "288906\n",
      "torch.Size([32, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearTransformer(\n",
       "  (encoder): LinearTransformerEncoder(\n",
       "    (layers): Sequential(\n",
       "      (0): LinearResBlock(\n",
       "        (fc1): Linear(in_features=20, out_features=20, bias=True)\n",
       "        (norm1): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=20, out_features=128, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=20, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): LinearResBlock(\n",
       "        (fc1): Linear(in_features=20, out_features=20, bias=True)\n",
       "        (norm1): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=20, out_features=128, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=20, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_norm): LayerNorm((20,), eps=1e-06, elementwise_affine=True)\n",
       "    (head_drop): Dropout(p=0.1, inplace=False)\n",
       "    (head): Linear(in_features=20, out_features=128, bias=True)\n",
       "  )\n",
       "  (decoder): LinearFeatureFusionBlock(\n",
       "    (EachPartModuleList): ModuleList(\n",
       "      (0): LinearFeatureExtractor(\n",
       "        (extractor): Sequential(\n",
       "          (0): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): LinearFeatureExtractor(\n",
       "        (extractor): Sequential(\n",
       "          (0): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=20, out_features=40, bias=True)\n",
       "            (norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=40, out_features=40, bias=True)\n",
       "            (norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=40, out_features=128, bias=True)\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fusionDecoder): LinearFeatureExtractor(\n",
       "      (extractor): Sequential(\n",
       "        (0): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "  (head_drop): Dropout(p=0.1, inplace=False)\n",
       "  (head): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt = LinearTransformer(\n",
    "    features_dict={\"important_protein\": important_protein},\n",
    "    covariates_dict={\"important_protein\": important_protein},\n",
    "    d_ff=128,\n",
    "    num_classes=2,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    ")\n",
    "print(modelParametersNum(lt))\n",
    "print(\n",
    "    lt(\n",
    "        torch.randn(32, len(important_protein)), torch.randn(32, len(important_protein))\n",
    "    ).shape\n",
    ")\n",
    "lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数个数：26387254\t占用的总显存为100.66MB\n",
      "26387254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearTransformer(\n",
       "  (encoder): LinearTransformerEncoder(\n",
       "    (layers): Sequential(\n",
       "      (0): LinearResBlock(\n",
       "        (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "        (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=2911, out_features=512, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=2911, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): LinearResBlock(\n",
       "        (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "        (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=2911, out_features=512, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=2911, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_norm): LayerNorm((2911,), eps=1e-06, elementwise_affine=True)\n",
       "    (head_drop): Dropout(p=0.1, inplace=False)\n",
       "    (head): Linear(in_features=2911, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): LinearFeatureFusionBlock(\n",
       "    (EachPartModuleList): ModuleList(\n",
       "      (0): LinearFeatureExtractor(\n",
       "        (extractor): Sequential(\n",
       "          (0): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=1024, out_features=128, bias=True)\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fusionDecoder): LinearFeatureExtractor(\n",
       "      (extractor): Sequential(\n",
       "        (0): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  (head_drop): Dropout(p=0.1, inplace=False)\n",
       "  (head): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt = LinearTransformer(\n",
    "    features_dict={\"proteomics\": proteomics},\n",
    "    # covariates_dict={\"risk_factors\": risk_factors},\n",
    "    d_ff=512,\n",
    "    num_classes=2,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    ")\n",
    "print(modelParametersNum(lt))\n",
    "# print(lt(torch.randn(32, len(proteomics)), torch.randn(32, len(risk_factors))).shape)\n",
    "lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearFeatureFusionBlock(\n",
       "  (EachPartModuleList): ModuleList(\n",
       "    (0): LinearFeatureExtractor(\n",
       "      (extractor): Sequential(\n",
       "        (0): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): LinearFeatureExtractor(\n",
       "      (extractor): Sequential(\n",
       "        (0): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=10, out_features=20, bias=True)\n",
       "          (norm): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=20, out_features=20, bias=True)\n",
       "          (norm): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=20, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fusionDecoder): LinearFeatureExtractor(\n",
       "    (extractor): Sequential(\n",
       "      (0): LinearActivationNormDropOut(\n",
       "        (fc): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): SiLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): LinearActivationNormDropOut(\n",
       "        (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): SiLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): LinearActivationNormDropOut(\n",
       "        (fc): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): SiLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lff = LinearFeatureFusionBlock([128, 10], d_ff=256, d_out=128, dropout=0.1)\n",
    "print(lff(torch.randn(32, 128), torch.randn(32, 10)).shape)\n",
    "lff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearTransformerEncoder(\n",
       "  (layers): Sequential(\n",
       "    (0): LinearResBlock(\n",
       "      (fc1): Linear(in_features=30, out_features=30, bias=True)\n",
       "      (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=30, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=30, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): LinearResBlock(\n",
       "      (fc1): Linear(in_features=30, out_features=30, bias=True)\n",
       "      (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=30, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=30, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): LinearResBlock(\n",
       "      (fc1): Linear(in_features=30, out_features=30, bias=True)\n",
       "      (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=30, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=30, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc_norm): LayerNorm((30,), eps=1e-06, elementwise_affine=True)\n",
       "  (head_drop): Dropout(p=0.1, inplace=False)\n",
       "  (head): Linear(in_features=30, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lte = LinearTransformerEncoder(d_model=30, d_ff=256, num_classes=128, num_layers=3)\n",
    "print(lte(torch.randn(32, 30)).shape)\n",
    "lte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTransformerPL(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        features_dict,\n",
    "        covariates_dict=None,\n",
    "        d_ff=512,\n",
    "        num_classes=2,\n",
    "        num_layers=2,\n",
    "        dropout=0.1,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-2,\n",
    "        weight=[1, 1],\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super(LinearTransformerPL, self).__init__()\n",
    "\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.mertic = {\n",
    "            \"train_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "            \"val_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "        }\n",
    "        self.history = defaultdict(dict)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(weight).float())\n",
    "        self.model = LinearTransformer(\n",
    "            features_dict=features_dict,\n",
    "            covariates_dict=covariates_dict,\n",
    "            d_ff=d_ff,\n",
    "            num_classes=num_classes,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.model(*x) if isinstance(x, (list, tuple)) else self.model(x)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        outputs = self.forward(x)\n",
    "        loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "        self.mertic[\"train_auc\"].update(\n",
    "            torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "        )\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss, on_epoch=True, prog_bar=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        outputs = self.forward(x)\n",
    "        loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "        self.mertic[\"val_auc\"].update(\n",
    "            torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "        )\n",
    "\n",
    "        self.log(\"ptl/val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "\n",
    "        auc = self.mertic[\"train_auc\"].compute()\n",
    "        self.log(\"ptl/train_auc\", auc, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        auc = self.mertic[\"val_auc\"].compute()\n",
    "        self.log(\"ptl/val_auc\", auc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), lr=self.lr, weight_decay=self.weight_decay\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def predict_df(self, df, batch_size=256):\n",
    "\n",
    "        for feature in self.features:\n",
    "            assert feature in df.columns\n",
    "        print(f\"input df have NA: {df[self.features].isna().sum(axis=1).sum()}\")\n",
    "        df = df.copy().dropna(subset=self.features)\n",
    "\n",
    "        predict_dataloader = DataLoader(\n",
    "            torch.tensor(df[self.features].values).float(),\n",
    "            batch_size=batch_size,\n",
    "            persistent_workers=True,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "        self.eval()\n",
    "        pred = []\n",
    "        with torch.no_grad():\n",
    "            for x in predict_dataloader:\n",
    "                y_hat = self.forward(x).cpu().detach()\n",
    "                y_hat = torch.softmax(y_hat, dim=-1)[:, 1]\n",
    "\n",
    "                pred.append(y_hat)\n",
    "        pred = torch.cat(pred).numpy()\n",
    "        df[\"pred\"] = pred\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trainer\n",
    "# used_fatures = proteomics\n",
    "# # + risk_factors + PRS\n",
    "# model = LinearTransformerPL(\n",
    "#     features_dict={\"proteomics\": proteomics},\n",
    "#     covariates_dict={\"risk_factors\": risk_factors},\n",
    "#     d_ff=512,\n",
    "#     num_classes=2,\n",
    "#     num_layers=2,\n",
    "#     dropout=0.1,\n",
    "#     lr=1e-3,\n",
    "#     weight_decay=1e-5,\n",
    "#     weight=[1, 1],\n",
    "# )\n",
    "\n",
    "# dataset = DatasetModule(\n",
    "#     train=train_imputed,\n",
    "#     test=test_imputed,\n",
    "#     features=used_fatures,\n",
    "#     covariates=risk_factors,\n",
    "#     label=[\"incident_cad\"],\n",
    "#     num_classes=2,\n",
    "#     batch_size=256,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(126)\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.train_dataloader():\n",
    "    # print(x.shape, y.shape)\n",
    "    print(torch.argmax(y, dim=1).sum())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : incident_cad\n",
      "0.0             27232\n",
      "1.0              1573\n",
      "dtype: int64\n",
      "val : incident_cad\n",
      "0.0             6776\n",
      "1.0              426\n",
      "dtype: int64\n",
      "Test : incident_cad\n",
      "0.0             14599\n",
      "1.0               833\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15008/3827040605.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y).long(), num_classes=self.num_classes\n",
      "/tmp/ipykernel_15008/3827040605.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y).long(), num_classes=self.num_classes\n",
      "/tmp/ipykernel_15008/3827040605.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y).long(), num_classes=self.num_classes\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss_fn | CrossEntropyLoss  | 0     \n",
      "1 | model   | LinearTransformer | 288 K \n",
      "----------------------------------------------\n",
      "288 K     Trainable params\n",
      "0         Non-trainable params\n",
      "288 K     Total params\n",
      "1.156     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c55bb094ad4922a99b61f823e8a7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ab70841b6c4f16bc19b4519e834ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74948fd794864faf981e6b17ecc9edc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d966f8251d412cba8d0f2c8f2b8f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e46454c3fc643a0a38abb0f9d197051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c26b8c6fd842349e73a8537a78cdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771ed2b547024530b8449c12e56e2559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead2c45393854d4a9872824738e7995a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfda0c8c05f44aaea1321830707f4dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7155b746d6e24a4a800f19c7deb2f6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591a9c82edc24eb09bbf04ace6790676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8b3cd774504bc787a67318447da853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# trainer\n",
    "\n",
    "\n",
    "model = LinearTransformerPL(\n",
    "    # features_dict={\"proteomics\": proteomics},\n",
    "    features_dict={\"important_protein\": important_protein},\n",
    "    covariates_dict={\"important_protein\": important_protein},\n",
    "    d_ff=128,\n",
    "    num_classes=2,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    weight=[1, 1],\n",
    ")\n",
    "\n",
    "dataset = DatasetModule(\n",
    "    train=train_imputed,\n",
    "    test=test_imputed,\n",
    "    features=important_protein,\n",
    "    covariates=important_protein,\n",
    "    label=[\"incident_cad\"],\n",
    "    num_classes=2,\n",
    "    batch_size=256,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=1,\n",
    ")\n",
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main_embedd = model.model.run_encoder(x[0].to(model.device))\n",
    "# main_embedd.shape\n",
    "# o = model.model.decoder.intermidiate_forward(main_embedd, x[1].to(model.device))\n",
    "# o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C3',\n",
       " 'KLK7',\n",
       " 'GCHFR',\n",
       " 'NHLRC3',\n",
       " 'APOD',\n",
       " 'GAPDH',\n",
       " 'TP53I3',\n",
       " 'CPA4',\n",
       " 'ANXA2',\n",
       " 'GRSF1',\n",
       " 'IL25',\n",
       " 'HMMR',\n",
       " 'MRPL52',\n",
       " 'PAIP2B',\n",
       " 'THAP12',\n",
       " 'FOS',\n",
       " 'FGF9',\n",
       " 'PITHD1',\n",
       " 'THSD1',\n",
       " 'PTGES2',\n",
       " 'DEFB103A_DEFB103B',\n",
       " 'ATP1B4',\n",
       " 'CYB5A',\n",
       " 'UNC79',\n",
       " 'SLC34A3',\n",
       " 'TAGLN3',\n",
       " 'SLIRP',\n",
       " 'CLASP1',\n",
       " 'PSMC3',\n",
       " 'KIR3DL2',\n",
       " 'BEX3',\n",
       " 'PFDN4',\n",
       " 'BCL7A',\n",
       " 'SMC3',\n",
       " 'SLC28A1',\n",
       " 'CDC123',\n",
       " 'GJA8',\n",
       " 'NMRK2',\n",
       " 'GATA3',\n",
       " 'CPLX2',\n",
       " 'RASGRF1',\n",
       " 'FGF7',\n",
       " 'ANKRA2',\n",
       " 'RBM25',\n",
       " 'LYZL2',\n",
       " 'CDK1',\n",
       " 'CREB3',\n",
       " 'CREBZF',\n",
       " 'IGLON5',\n",
       " 'SHC1',\n",
       " 'ZP4',\n",
       " 'TMOD4',\n",
       " 'CEP152',\n",
       " 'MYH7B',\n",
       " 'CEP350',\n",
       " 'CDC25A',\n",
       " 'TRIM26',\n",
       " 'MANEAL',\n",
       " 'MUCL3',\n",
       " 'GIMAP8',\n",
       " 'CYTH3',\n",
       " 'PDXDC1',\n",
       " 'CLINT1',\n",
       " 'MAPRE3',\n",
       " 'EVI2B',\n",
       " 'STAU1',\n",
       " 'PCNA',\n",
       " 'DNAJA1',\n",
       " 'JMJD1C',\n",
       " 'GAGE2A',\n",
       " 'GAD1',\n",
       " 'IZUMO1',\n",
       " 'PDCL2',\n",
       " 'PDE1C',\n",
       " 'STOML2',\n",
       " 'BSND',\n",
       " 'MAPK13',\n",
       " 'PDIA2',\n",
       " 'BTLA',\n",
       " 'MLLT1',\n",
       " 'TPRKB',\n",
       " 'ARHGAP5',\n",
       " 'BTNL10',\n",
       " 'PHLDB2',\n",
       " 'PDIA5',\n",
       " 'ATF4',\n",
       " 'PRAME',\n",
       " 'TOP1MT',\n",
       " 'KHDC3L',\n",
       " 'DCUN1D2',\n",
       " 'IL3',\n",
       " 'DCLRE1C',\n",
       " 'ERCC1',\n",
       " 'DCDC2C',\n",
       " 'VCPKMT',\n",
       " 'SPRING1',\n",
       " 'MORN4',\n",
       " 'ESPL1',\n",
       " 'H2AP',\n",
       " 'MORF4L2',\n",
       " 'SSH3',\n",
       " 'VWA5A',\n",
       " 'PBK',\n",
       " 'REST',\n",
       " 'SHD',\n",
       " 'TXNL1',\n",
       " 'TPM3',\n",
       " 'NEB',\n",
       " 'ATP1B2',\n",
       " 'CEP112',\n",
       " 'SART1',\n",
       " 'ATP6V1G2',\n",
       " 'ATP2B4',\n",
       " 'SAT1',\n",
       " 'ATP1B1',\n",
       " 'NECAP2',\n",
       " 'ATP5F1D',\n",
       " 'ATP1B3',\n",
       " 'ARNTL',\n",
       " 'ARL2BP',\n",
       " 'SCGB2A2',\n",
       " 'GAMT',\n",
       " 'ASS1',\n",
       " 'NFYA',\n",
       " 'GASK1A',\n",
       " 'MANSC4',\n",
       " 'HMGCS1',\n",
       " 'MMUT',\n",
       " 'CBX2',\n",
       " 'BRD3',\n",
       " 'BRDT',\n",
       " 'MAP1LC3B2',\n",
       " 'CASQ2',\n",
       " 'HIP1',\n",
       " 'GSTM4',\n",
       " 'GUK1',\n",
       " 'CALY',\n",
       " 'C1GALT1C1',\n",
       " 'TEF',\n",
       " 'CACNA1H',\n",
       " 'HADH',\n",
       " 'MEGF11',\n",
       " 'MED21',\n",
       " 'THRAP3',\n",
       " 'SPINK8',\n",
       " 'NAA10',\n",
       " 'MRPL24',\n",
       " 'GBP6',\n",
       " 'MYOM2',\n",
       " 'B3GAT3',\n",
       " 'GCLM',\n",
       " 'MYL1',\n",
       " 'HSD17B3',\n",
       " 'MYH4',\n",
       " 'TMED4',\n",
       " 'TMED10',\n",
       " 'SKIV2L',\n",
       " 'SLC12A2',\n",
       " 'SLC51B',\n",
       " 'MTR',\n",
       " 'CD2',\n",
       " 'BHMT2',\n",
       " 'SNU13',\n",
       " 'GP1BB',\n",
       " 'ARL13B',\n",
       " 'HCG22',\n",
       " 'RYR1',\n",
       " 'FDX2',\n",
       " 'ADRA2A',\n",
       " 'ERVV-1',\n",
       " 'EXOSC10',\n",
       " 'EXTL1',\n",
       " 'CYP24A1',\n",
       " 'KIF1C',\n",
       " 'USP47',\n",
       " 'PRKD2',\n",
       " 'PROCR',\n",
       " 'PACS2',\n",
       " 'KIF22',\n",
       " 'NXPE4',\n",
       " 'RTKN2',\n",
       " 'CSRP3',\n",
       " 'NUDT15',\n",
       " 'UHRF2',\n",
       " 'UGDH',\n",
       " 'CSF2',\n",
       " 'KRT17',\n",
       " 'FDX1',\n",
       " 'PYY',\n",
       " 'UBQLN3',\n",
       " 'CSDE1',\n",
       " 'DDA1',\n",
       " 'PALM3',\n",
       " 'VSIG10L',\n",
       " 'PKD2',\n",
       " 'ABCA2',\n",
       " 'EDEM2',\n",
       " 'ABRAXAS2',\n",
       " 'ECI2',\n",
       " 'PGLYRP4',\n",
       " 'PDZD2',\n",
       " 'EIF2AK3',\n",
       " 'EIF5',\n",
       " 'ELOB',\n",
       " 'ITPA',\n",
       " 'ACSL1',\n",
       " 'DENND2B',\n",
       " 'ZCCHC8',\n",
       " 'ACTN2',\n",
       " 'PDE4D',\n",
       " 'ACY3',\n",
       " 'ENOX2',\n",
       " 'YOD1',\n",
       " 'ENPEP',\n",
       " 'PMCH',\n",
       " 'PMM2',\n",
       " 'DHODH',\n",
       " 'KRT6C',\n",
       " 'NUP50',\n",
       " 'LAMA1',\n",
       " 'COPB2',\n",
       " 'LRCH4',\n",
       " 'TSNAX',\n",
       " 'LPP',\n",
       " 'TRPV3',\n",
       " 'IGHMBP2',\n",
       " 'LILRA4',\n",
       " 'FHIP2A',\n",
       " 'NOP56',\n",
       " 'RIPK4',\n",
       " 'TRAF3IP2',\n",
       " 'IGF2BP3',\n",
       " 'NFKB1',\n",
       " 'NFX1',\n",
       " 'REXO2',\n",
       " 'TSPAN15',\n",
       " 'RBM19',\n",
       " 'FRMD4B',\n",
       " 'NOS2',\n",
       " 'TPR',\n",
       " 'NPR1',\n",
       " 'RAB33A',\n",
       " 'RAB39B',\n",
       " 'RPS10',\n",
       " 'ANK2',\n",
       " 'IFNW1',\n",
       " 'CPTP',\n",
       " 'TTN',\n",
       " 'IL36G',\n",
       " 'IL31RA',\n",
       " 'RNASE4',\n",
       " 'LRIG3',\n",
       " 'CACNA1C',\n",
       " 'SCIN',\n",
       " 'DNLZ',\n",
       " 'STEAP4',\n",
       " 'CBLN1',\n",
       " 'CHP1',\n",
       " 'SAG',\n",
       " 'DOCK9',\n",
       " 'RRP15',\n",
       " 'SYNGAP1',\n",
       " 'CNTF',\n",
       " 'ECSCR',\n",
       " 'ELAVL4',\n",
       " 'FZD8',\n",
       " 'SCN2A',\n",
       " 'CNGB3',\n",
       " 'GABRA4',\n",
       " 'CACNB1',\n",
       " 'DEFB118',\n",
       " 'PNMA2',\n",
       " 'SMS',\n",
       " 'CDH4',\n",
       " 'SH3BGRL2',\n",
       " 'RAB3GAP1',\n",
       " 'RANBP2',\n",
       " 'MYOM1',\n",
       " 'CDKL5',\n",
       " 'CSPG5',\n",
       " 'CTNNA1',\n",
       " 'OMP',\n",
       " 'OTOA',\n",
       " 'GLP1R',\n",
       " 'CEND1',\n",
       " 'SNAP25',\n",
       " 'PCARE',\n",
       " 'FH',\n",
       " 'CORO6',\n",
       " 'SCN3B',\n",
       " 'DCUN1D1',\n",
       " 'NLGN2',\n",
       " 'DEFB104A_DEFB104B',\n",
       " 'DEFB116',\n",
       " 'CRYM',\n",
       " 'SPTBN2',\n",
       " 'GPR101',\n",
       " 'DGCR6',\n",
       " 'GRIN2B',\n",
       " 'ZPR1',\n",
       " 'CD3D',\n",
       " 'HTR1A',\n",
       " 'TFAP2A',\n",
       " 'BLOC1S2',\n",
       " 'IMPG1',\n",
       " 'BRME1',\n",
       " 'KLRC1',\n",
       " 'HTR1B',\n",
       " 'IFNL2',\n",
       " 'VAV3',\n",
       " 'ITPRIP',\n",
       " 'KLF4',\n",
       " 'KIF20B',\n",
       " 'ATXN2',\n",
       " 'TSPAN7',\n",
       " 'BCAT2',\n",
       " 'IGDCC3',\n",
       " 'LELP1',\n",
       " 'TMPRSS11B',\n",
       " 'KCNC4',\n",
       " 'MAP1LC3A',\n",
       " 'BRD2',\n",
       " 'LYPLA2',\n",
       " 'BOLA1',\n",
       " 'ART5',\n",
       " 'AGBL2',\n",
       " 'UPK3A',\n",
       " 'IL13RA2',\n",
       " 'HDAC9',\n",
       " 'ARMCX2',\n",
       " 'KIRREL1',\n",
       " 'TJP3',\n",
       " 'TUBB3',\n",
       " 'ARID3A',\n",
       " 'KRT8',\n",
       " 'BHLHE40',\n",
       " 'ARHGEF5',\n",
       " 'ADGRV1',\n",
       " 'LMOD2',\n",
       " 'GFRAL',\n",
       " 'DNAJB6',\n",
       " 'CD7',\n",
       " 'NAGA',\n",
       " 'PTPN9',\n",
       " 'NDUFA5',\n",
       " 'SCPEP1',\n",
       " 'PRR4',\n",
       " 'CSF3R',\n",
       " 'UNC5D',\n",
       " 'TYRP1',\n",
       " 'SHH',\n",
       " 'GLI2',\n",
       " 'GIPR',\n",
       " 'UBE2Z',\n",
       " 'GAD2',\n",
       " 'SLITRK1',\n",
       " 'BCL2L15',\n",
       " 'TLR1',\n",
       " 'EDNRB',\n",
       " 'NUMB',\n",
       " 'ALPI',\n",
       " 'KLRF1',\n",
       " 'SIRT1',\n",
       " 'HS6ST2',\n",
       " 'GIT1',\n",
       " 'CD36',\n",
       " 'TLR4',\n",
       " 'CSNK1D',\n",
       " 'CSF2RB',\n",
       " 'CD3G',\n",
       " 'RNF168',\n",
       " 'RAP1A',\n",
       " 'FGF12',\n",
       " 'REPS1',\n",
       " 'FOLH1',\n",
       " 'RICTOR',\n",
       " 'TRAF3',\n",
       " 'NFAT5',\n",
       " 'FOXJ3',\n",
       " 'CEBPA',\n",
       " 'TPSG1',\n",
       " 'NEDD9',\n",
       " 'RNF31',\n",
       " 'CEMIP2',\n",
       " 'RPA2',\n",
       " 'CLEC12A',\n",
       " 'NEDD4L',\n",
       " 'S100A13',\n",
       " 'NECTIN1',\n",
       " 'TOP2B',\n",
       " 'TP53BP1',\n",
       " 'SEMA6C',\n",
       " 'RELB',\n",
       " 'FGF16',\n",
       " 'NME1',\n",
       " 'NPHS2',\n",
       " 'NPHS1',\n",
       " 'FGF20',\n",
       " 'RALB',\n",
       " 'FGF3',\n",
       " 'IL12RB2',\n",
       " 'ANKMY2',\n",
       " 'FGF6',\n",
       " 'PTP4A3',\n",
       " 'BAG4',\n",
       " 'CPOX',\n",
       " 'TSPYL1',\n",
       " 'BABAM1',\n",
       " 'LATS1',\n",
       " 'TSC1',\n",
       " 'IGFL4',\n",
       " 'RBPMS',\n",
       " 'CD226',\n",
       " 'NXPH3',\n",
       " 'MTDH',\n",
       " 'DGKA',\n",
       " 'STX7',\n",
       " 'STX5',\n",
       " 'HIF1A',\n",
       " 'EIF4E',\n",
       " 'IL36A',\n",
       " 'CASP9',\n",
       " 'PGR',\n",
       " 'DENR',\n",
       " 'ST8SIA1',\n",
       " 'TGFBR1',\n",
       " 'KDM3A',\n",
       " 'PPL',\n",
       " 'DDX4',\n",
       " 'DDX39A',\n",
       " 'ACP1',\n",
       " 'PDZK1',\n",
       " 'SMPD3',\n",
       " 'MKI67',\n",
       " 'POLR2A',\n",
       " 'POF1B',\n",
       " 'PIKFYVE',\n",
       " 'C1QL2',\n",
       " 'ACRV1',\n",
       " 'ZBP1',\n",
       " 'PLCB1',\n",
       " 'YY1',\n",
       " 'ZNF174',\n",
       " 'ADAM12',\n",
       " 'XIAP',\n",
       " 'EP300',\n",
       " 'TERF1',\n",
       " 'ADAMTS1',\n",
       " 'WASL',\n",
       " 'SUMF1',\n",
       " 'ADAMTS4',\n",
       " 'PPM1B',\n",
       " 'STAT2',\n",
       " 'ERMAP',\n",
       " 'HDAC8',\n",
       " 'DAPK2',\n",
       " 'DAND5',\n",
       " 'IL21R',\n",
       " 'IL31',\n",
       " 'VAMP8',\n",
       " 'IL20RB',\n",
       " 'CCNE1',\n",
       " 'EVI5',\n",
       " 'MRPS16',\n",
       " 'PRR5',\n",
       " 'PRSS22',\n",
       " 'PSMG4',\n",
       " 'AKR7L',\n",
       " 'PER3',\n",
       " 'BLNK',\n",
       " 'CA8',\n",
       " 'DBN1',\n",
       " 'SPRED2',\n",
       " 'PALLD',\n",
       " 'SSBP1',\n",
       " 'BNIP3L',\n",
       " 'VEGFB',\n",
       " 'MCEMP1',\n",
       " 'ITGAL',\n",
       " 'INSR',\n",
       " 'ESR1',\n",
       " 'IFI30',\n",
       " 'CNP',\n",
       " 'NAGK',\n",
       " 'LAMP1',\n",
       " 'TP73',\n",
       " 'PGM2',\n",
       " 'DYNLT1',\n",
       " 'CHM',\n",
       " 'PFDN6',\n",
       " 'TPBGL',\n",
       " 'FZD10',\n",
       " 'CLIC5',\n",
       " 'DTX2',\n",
       " 'CLNS1A',\n",
       " 'RRAS',\n",
       " 'CLGN',\n",
       " 'PDRG1',\n",
       " 'RPGR',\n",
       " 'DUSP29',\n",
       " 'CLEC2L',\n",
       " 'EFNB2',\n",
       " 'CHRM1',\n",
       " 'CIT',\n",
       " 'LRFN2',\n",
       " 'AP2B1',\n",
       " 'FRMD7',\n",
       " 'CRTAP',\n",
       " 'PTH',\n",
       " 'FARSA',\n",
       " 'AKR1B10',\n",
       " 'PSMD5',\n",
       " 'FBN2',\n",
       " 'CUZD1',\n",
       " 'OSTN',\n",
       " 'UROS',\n",
       " 'AIDA',\n",
       " 'PRKAG3',\n",
       " 'NRXN3',\n",
       " 'AMIGO1',\n",
       " 'DCC',\n",
       " 'PPT1',\n",
       " 'ERC2',\n",
       " 'DOC2B',\n",
       " 'RAC3',\n",
       " 'DDX25',\n",
       " 'DDX53',\n",
       " 'TTF2',\n",
       " 'KCNH2',\n",
       " 'DIPK1C',\n",
       " 'RBP1',\n",
       " 'TRIM40',\n",
       " 'NLGN1',\n",
       " 'PMS1',\n",
       " 'COL28A1',\n",
       " 'EPB41L5',\n",
       " 'IFT20',\n",
       " 'CNTNAP4',\n",
       " 'LRP2',\n",
       " 'C2orf69',\n",
       " 'LYSMD3',\n",
       " 'MAG',\n",
       " 'MRI1',\n",
       " 'SCT',\n",
       " 'CASC3',\n",
       " 'LRTM1',\n",
       " 'SLC44A4',\n",
       " 'GTPBP2',\n",
       " 'TDO2',\n",
       " 'SLC1A4',\n",
       " 'SV2A',\n",
       " 'MFAP3L',\n",
       " 'GBA',\n",
       " 'SOX9',\n",
       " 'CAMLG',\n",
       " 'MN1',\n",
       " 'CABP2',\n",
       " 'CCDC28A',\n",
       " 'TMCO5A',\n",
       " 'NAA80',\n",
       " 'TEX101',\n",
       " 'STX1B',\n",
       " 'BATF',\n",
       " 'CADPS',\n",
       " 'LRRC38',\n",
       " 'SEZ6',\n",
       " 'MSLNL',\n",
       " 'MYL6B',\n",
       " 'MDM1',\n",
       " 'SOWAHA',\n",
       " 'LRP2BP',\n",
       " 'SCN2B',\n",
       " 'CD164L2',\n",
       " 'TBR1',\n",
       " 'MYLPF',\n",
       " 'CGN',\n",
       " 'TARM1',\n",
       " 'MICALL2',\n",
       " 'GNGT1',\n",
       " 'SCN3A',\n",
       " 'HNF1A',\n",
       " 'ANXA1',\n",
       " 'SUSD5',\n",
       " 'RBPMS2',\n",
       " 'RANBP1',\n",
       " 'COQ7',\n",
       " 'MYBPC2',\n",
       " 'DMP1',\n",
       " 'ANP32C',\n",
       " 'PRRT3',\n",
       " 'PNMA1',\n",
       " 'HSDL2',\n",
       " 'TMEM132A',\n",
       " 'IGSF21',\n",
       " 'MYL4',\n",
       " 'DLL4',\n",
       " 'DMD',\n",
       " 'MYL3',\n",
       " 'EDN1',\n",
       " 'GIP',\n",
       " 'HSBP1',\n",
       " 'BOLA2_BOLA2B',\n",
       " 'AIF1L',\n",
       " 'OXCT1',\n",
       " 'PAGR1',\n",
       " 'SNED1',\n",
       " 'OPLAH',\n",
       " 'GNPDA1',\n",
       " 'SNX5',\n",
       " 'AHNAK2',\n",
       " 'AHNAK',\n",
       " 'BECN1',\n",
       " 'FAM172A',\n",
       " 'VIPR1',\n",
       " 'HRC',\n",
       " 'KHK',\n",
       " 'POMC',\n",
       " 'HS1BP3',\n",
       " 'NUDT10',\n",
       " 'PYDC1',\n",
       " 'SIL1',\n",
       " 'HMGCL',\n",
       " 'SIGLEC8',\n",
       " 'CRYZL1',\n",
       " 'CCER2',\n",
       " 'LAMB1',\n",
       " 'GRP',\n",
       " 'CBS',\n",
       " 'ADAMTSL4',\n",
       " 'EPPK1',\n",
       " 'LIPF',\n",
       " 'B3GNT7',\n",
       " 'RECK',\n",
       " 'SCRIB',\n",
       " 'SEC31A',\n",
       " 'RNF149',\n",
       " 'COMMD1',\n",
       " 'ATP6V1G1',\n",
       " 'RNF5',\n",
       " 'ROBO4',\n",
       " 'FSHB',\n",
       " 'RPL14',\n",
       " 'CEP170',\n",
       " 'AAMDC',\n",
       " 'EIF2S2',\n",
       " 'SCN4B',\n",
       " 'SEL1L',\n",
       " 'INPP5D',\n",
       " 'FSTL1',\n",
       " 'EHD3',\n",
       " 'PECR',\n",
       " 'ECHS1',\n",
       " 'MECR',\n",
       " 'TOR1AIP1',\n",
       " 'ASRGL1',\n",
       " 'IDO1',\n",
       " 'ZP3',\n",
       " 'GADD45GIP1',\n",
       " 'RNASE10',\n",
       " 'MAN1A2',\n",
       " 'COL2A1',\n",
       " 'NIT1',\n",
       " 'ITPR1',\n",
       " 'ENPP6',\n",
       " 'ENO3',\n",
       " 'LONP1',\n",
       " 'DNAJC6',\n",
       " 'NFE2',\n",
       " 'ENTR1',\n",
       " 'GATD3',\n",
       " 'M6PR',\n",
       " 'CALCOCO2',\n",
       " 'APOBR',\n",
       " 'ECM1',\n",
       " 'ACYP1',\n",
       " 'WFDC1',\n",
       " 'GM2A',\n",
       " 'PLG',\n",
       " 'SH3GL3',\n",
       " 'PCBD1',\n",
       " 'RLN2',\n",
       " 'C1QTNF9',\n",
       " 'SERPINI1',\n",
       " 'GLA',\n",
       " 'CACYBP',\n",
       " 'MARS1',\n",
       " 'HMCN2',\n",
       " 'C7',\n",
       " 'LPA',\n",
       " 'FGA',\n",
       " 'CLEC3B',\n",
       " 'PAXX',\n",
       " 'C1QTNF5',\n",
       " 'MENT',\n",
       " 'ADGRD1',\n",
       " 'VTI1A',\n",
       " 'DAAM1',\n",
       " 'GNPDA2',\n",
       " 'PENK',\n",
       " 'SYAP1',\n",
       " 'ADD1',\n",
       " 'PINLYP',\n",
       " 'JAM3',\n",
       " 'PRKG1',\n",
       " 'ITGA2',\n",
       " 'DNAJB2',\n",
       " 'SNX15',\n",
       " 'DIPK2B',\n",
       " 'TBCA',\n",
       " 'GP5',\n",
       " 'YWHAQ',\n",
       " 'PDE5A',\n",
       " 'DTD1',\n",
       " 'DDI2',\n",
       " 'ADH1B',\n",
       " 'ST13',\n",
       " 'INHBB',\n",
       " 'ERP29',\n",
       " 'PHYKPL',\n",
       " 'MOCS2',\n",
       " 'AFAP1',\n",
       " 'SPART',\n",
       " 'HEG1',\n",
       " 'BMPER',\n",
       " 'PDIA3',\n",
       " 'DCTD',\n",
       " 'MFAP4',\n",
       " 'BMP10',\n",
       " 'SPINK2',\n",
       " 'EPHA4',\n",
       " 'ACHE',\n",
       " 'CHAD',\n",
       " 'UBXN1',\n",
       " 'TNFRSF17',\n",
       " 'SLC9A3R1',\n",
       " 'LZTFL1',\n",
       " 'ARHGAP45',\n",
       " 'AMOT',\n",
       " 'CD72',\n",
       " 'CELSR2',\n",
       " 'GIMAP7',\n",
       " 'SDK2',\n",
       " 'GHR',\n",
       " 'RABEP1',\n",
       " 'CD300A',\n",
       " 'SEMA3G',\n",
       " 'CRELD1',\n",
       " 'RIDA',\n",
       " 'SFRP4',\n",
       " 'MXRA8',\n",
       " 'APPL2',\n",
       " 'MYOM3',\n",
       " 'FGFR4',\n",
       " 'TNFAIP8L2',\n",
       " 'PTRHD1',\n",
       " 'COL5A1',\n",
       " 'FUOM',\n",
       " 'AKAP12',\n",
       " 'CTSE',\n",
       " 'SCGB3A1',\n",
       " 'TPD52L2',\n",
       " 'NAGPA',\n",
       " 'UROD',\n",
       " 'GMPR2',\n",
       " 'SNCA',\n",
       " 'GLRX5',\n",
       " 'KCTD5',\n",
       " 'UPK3BL1',\n",
       " 'TRIM24',\n",
       " 'CTAG1A_CTAG1B',\n",
       " 'FUT1',\n",
       " 'HRAS',\n",
       " 'TET2',\n",
       " 'COL4A4',\n",
       " 'TCN1',\n",
       " 'KLKB1',\n",
       " 'QSOX1',\n",
       " 'CEACAM18',\n",
       " 'EFCAB2',\n",
       " 'NEK7',\n",
       " 'NFKB2',\n",
       " 'CEACAM20',\n",
       " 'RGL2',\n",
       " 'SEPTIN7',\n",
       " 'SAP18',\n",
       " 'ARAF',\n",
       " 'GABARAPL1',\n",
       " 'SAT2',\n",
       " 'ARHGAP30',\n",
       " 'TRDMT1',\n",
       " 'ID4',\n",
       " 'PKN3',\n",
       " 'MAPKAPK2',\n",
       " 'TNPO1',\n",
       " 'TAP1',\n",
       " 'TCP11',\n",
       " 'ITGAX',\n",
       " 'IFIT3',\n",
       " 'ACADM',\n",
       " 'CEP290',\n",
       " 'TAB2',\n",
       " 'GAS2',\n",
       " 'RPE',\n",
       " 'ZNF75D',\n",
       " 'LSM8',\n",
       " 'CENPJ',\n",
       " 'CINP',\n",
       " 'RNF43',\n",
       " 'IFIT1',\n",
       " 'CA7',\n",
       " 'RNF4',\n",
       " 'CENPF',\n",
       " 'TPPP2',\n",
       " 'IL9',\n",
       " 'PAFAH2',\n",
       " 'EPN1',\n",
       " 'COL9A2',\n",
       " 'PPIE',\n",
       " 'TLR2',\n",
       " 'MNAT1',\n",
       " 'ERI1',\n",
       " 'CD3E',\n",
       " 'MAGEA3',\n",
       " 'ALMS1',\n",
       " 'PPP1R12B',\n",
       " 'VPS28',\n",
       " 'PTTG1',\n",
       " 'MORF4L1',\n",
       " 'KIAA1549',\n",
       " 'SPRR1B',\n",
       " 'SLK',\n",
       " 'TK1',\n",
       " 'OFD1',\n",
       " 'KIAA1549L',\n",
       " 'MTHFSD',\n",
       " 'EVPL',\n",
       " 'GADD45B',\n",
       " 'TIGIT',\n",
       " 'CCND2',\n",
       " 'BRD1',\n",
       " 'SHPK',\n",
       " 'VSTM2B',\n",
       " 'TEX33',\n",
       " 'GUCY2C',\n",
       " 'CDH22',\n",
       " 'SERPINH1',\n",
       " 'RAPGEF2',\n",
       " 'PRUNE2',\n",
       " 'MTUS1',\n",
       " 'TMED1',\n",
       " 'GTF2IRD1',\n",
       " 'CASP4',\n",
       " 'OGT',\n",
       " 'RAD51',\n",
       " 'TXK',\n",
       " 'PARD3',\n",
       " 'CD82',\n",
       " 'BCHE',\n",
       " 'SERPINF2',\n",
       " 'SERPINA1',\n",
       " 'SERPINA4',\n",
       " 'SGSH',\n",
       " 'CFB',\n",
       " 'NPC2',\n",
       " 'PRDX2',\n",
       " 'TXN',\n",
       " 'CYB5R2',\n",
       " 'MST1',\n",
       " 'CAT',\n",
       " 'CTBS',\n",
       " 'SERPINF1',\n",
       " 'BRAP',\n",
       " 'HPSE',\n",
       " 'SERPINA5',\n",
       " 'F11',\n",
       " 'MBL2',\n",
       " 'CFHR5',\n",
       " 'IST1',\n",
       " 'PGLYRP2',\n",
       " 'CWC15',\n",
       " 'PALM',\n",
       " 'TTR',\n",
       " 'PSAP',\n",
       " 'ASAH1',\n",
       " 'HGFAC',\n",
       " 'AMOTL2',\n",
       " 'CRISP3',\n",
       " 'NMI',\n",
       " 'EIF2AK2',\n",
       " 'APCS',\n",
       " 'SLURP1',\n",
       " 'DTNB',\n",
       " 'LACRT',\n",
       " 'BTN1A1',\n",
       " 'THTPA',\n",
       " 'MPRIP',\n",
       " 'KLK15',\n",
       " 'RNASE6',\n",
       " 'NAP1L4',\n",
       " 'CDC26',\n",
       " 'LMNB1',\n",
       " 'NUDT16',\n",
       " 'PPBP',\n",
       " 'PF4',\n",
       " 'CFHR2',\n",
       " 'GSR',\n",
       " 'MDH1',\n",
       " 'IL2RG',\n",
       " 'REG3G',\n",
       " 'FNTA',\n",
       " 'RFC4',\n",
       " 'CMIP',\n",
       " 'NUBP1',\n",
       " 'FAM171B',\n",
       " 'NENF',\n",
       " 'AHSA1',\n",
       " 'IL22',\n",
       " 'COMMD9',\n",
       " 'VSIG10',\n",
       " 'KIAA2013',\n",
       " 'RCC1',\n",
       " 'ALDH2',\n",
       " 'UNG',\n",
       " 'VPS4B',\n",
       " 'RALY',\n",
       " 'RAB44',\n",
       " 'PXDNL',\n",
       " 'RAB2B',\n",
       " 'VSIG2',\n",
       " 'KIR2DL2',\n",
       " 'USP25',\n",
       " 'UBE2B',\n",
       " 'LARP1',\n",
       " 'S100A3',\n",
       " 'TDP1',\n",
       " 'CAPN3',\n",
       " 'MINDY1',\n",
       " 'SUSD4',\n",
       " 'TADA3',\n",
       " 'TARS1',\n",
       " 'LRRFIP1',\n",
       " 'TG',\n",
       " 'STAM',\n",
       " 'TGFB2',\n",
       " 'LTB',\n",
       " 'LUZP2',\n",
       " 'MAMDC4',\n",
       " 'HSPA2',\n",
       " 'BCL7B',\n",
       " 'CCDC134',\n",
       " 'GPRC5C',\n",
       " 'LAMTOR5',\n",
       " 'MTSS2',\n",
       " 'NDST1',\n",
       " 'GABARAP',\n",
       " 'CHCHD6',\n",
       " 'NACC1',\n",
       " 'AP1G2',\n",
       " 'TRIM58',\n",
       " 'SLC13A1',\n",
       " 'GPD1',\n",
       " 'SMAD2',\n",
       " 'SMAD3',\n",
       " 'GLYR1',\n",
       " 'SMPDL3B',\n",
       " 'SNX2',\n",
       " 'ARG2',\n",
       " 'SDCCAG8',\n",
       " 'TMEM106A',\n",
       " 'ACRBP',\n",
       " 'DUSP13',\n",
       " 'DYNC1H1',\n",
       " 'EDDM3B',\n",
       " 'DYNLT3',\n",
       " 'WDR46',\n",
       " 'PCDHB15',\n",
       " 'EPGN',\n",
       " 'DHPS',\n",
       " 'IMMT',\n",
       " 'PRC1',\n",
       " 'PPP1CC',\n",
       " 'ERN1',\n",
       " 'ZNRF4',\n",
       " 'ZNF830',\n",
       " 'YJU2',\n",
       " 'PCSK7',\n",
       " 'INSL4',\n",
       " 'ENOPH1',\n",
       " 'ITIH5',\n",
       " 'ENSA',\n",
       " 'TMPRSS11D',\n",
       " 'FTCD',\n",
       " 'PLSCR3',\n",
       " 'SEPTIN8',\n",
       " 'PRKAR2A',\n",
       " 'SMTN',\n",
       " 'NFU1',\n",
       " 'PBXIP1',\n",
       " 'HIP1R',\n",
       " 'ZFYVE19',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_fatures = proteomics\n",
    "# + risk_factors + PRS\n",
    "used_fatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-04-17 20:16:49</td></tr>\n",
       "<tr><td>Running for: </td><td>00:39:53.41        </td></tr>\n",
       "<tr><td>Memory:      </td><td>27.6/50.1 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=40<br>Bracket: Iter 16.000: 0.6701245307922363 | Iter 8.000: 0.6966633200645447 | Iter 4.000: 0.6992420554161072 | Iter 2.000: 0.6884346008300781 | Iter 1.000: 0.5658209025859833<br>Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">    train_loop_config/ba\n",
       "tch_size</th><th>train_loop_config/co\n",
       "variates_dict                     </th><th style=\"text-align: right;\">    train_loop_config/d_\n",
       "ff</th><th style=\"text-align: right;\">         train_loop_config/dr\n",
       "opout</th><th style=\"text-align: right;\">  train_loop_config/lr</th><th style=\"text-align: right;\">  train_loop_config/nu\n",
       "m_layers</th><th>train_loop_config/we\n",
       "ight           </th><th style=\"text-align: right;\">            train_loop_config/we\n",
       "ight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ptl/val_loss</th><th style=\"text-align: right;\">  ptl/val_auc</th><th style=\"text-align: right;\">  ptl/train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_cb745_00040</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.217157</td><td style=\"text-align: right;\">           0.000188959</td><td style=\"text-align: right;\">1</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.000724475</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00041</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.25085 </td><td style=\"text-align: right;\">           0.0078362  </td><td style=\"text-align: right;\">1</td><td>[0.1, 1]  </td><td style=\"text-align: right;\">0.00361529 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00042</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">512</td><td>{&#x27;risk_factors&#x27;_0400</td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.204488</td><td style=\"text-align: right;\">           0.00444088 </td><td style=\"text-align: right;\">2</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.00173372 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00043</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">512</td><td>{&#x27;risk_factors&#x27;_4a00</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.480957</td><td style=\"text-align: right;\">           0.0014951  </td><td style=\"text-align: right;\">3</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.00822204 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00044</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.331868</td><td style=\"text-align: right;\">           0.00422364 </td><td style=\"text-align: right;\">5</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.00551316 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00045</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\"> 64</td><td>{&#x27;risk_factors&#x27;_8700</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.439083</td><td style=\"text-align: right;\">           0.00190886 </td><td style=\"text-align: right;\">5</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.00155947 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00046</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.243367</td><td style=\"text-align: right;\">           0.00262025 </td><td style=\"text-align: right;\">1</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.00617807 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00047</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.143739</td><td style=\"text-align: right;\">           0.0957064  </td><td style=\"text-align: right;\">4</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.00021416 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00048</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.100008</td><td style=\"text-align: right;\">           0.00447773 </td><td style=\"text-align: right;\">4</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.00892221 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00049</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">512</td><td>{&#x27;risk_factors&#x27;_b640</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.332562</td><td style=\"text-align: right;\">           0.000409618</td><td style=\"text-align: right;\">2</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.00394281 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">              </td><td style=\"text-align: right;\">             </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00000</td><td>TERMINATED</td><td>172.26.71.104:13996</td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.216143</td><td style=\"text-align: right;\">           0.000649131</td><td style=\"text-align: right;\">3</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.000498383</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        338.498 </td><td style=\"text-align: right;\">      0.714883</td><td style=\"text-align: right;\">     0.664634</td><td style=\"text-align: right;\">       0.363787 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00001</td><td>TERMINATED</td><td>172.26.71.104:15270</td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.19116 </td><td style=\"text-align: right;\">           0.00853526 </td><td style=\"text-align: right;\">2</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.00699515 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.1435</td><td style=\"text-align: right;\">      0.477785</td><td style=\"text-align: right;\">     0.51457 </td><td style=\"text-align: right;\">       0.32923  </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00002</td><td>TERMINATED</td><td>172.26.71.104:15583</td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.248011</td><td style=\"text-align: right;\">           0.000397284</td><td style=\"text-align: right;\">2</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.000374452</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         61.9539</td><td style=\"text-align: right;\">      0.599629</td><td style=\"text-align: right;\">     0.664609</td><td style=\"text-align: right;\">       0.0524153</td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00003</td><td>TERMINATED</td><td>172.26.71.104:16043</td><td style=\"text-align: right;\">256</td><td>{&#x27;risk_factors&#x27;_7f40</td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.191966</td><td style=\"text-align: right;\">           0.0686765  </td><td style=\"text-align: right;\">2</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.00490494 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.051 </td><td style=\"text-align: right;\">      0.778144</td><td style=\"text-align: right;\">     0.501907</td><td style=\"text-align: right;\">       2.11413  </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00004</td><td>TERMINATED</td><td>172.26.71.104:16367</td><td style=\"text-align: right;\">256</td><td>{&#x27;risk_factors&#x27;_dd00</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.374305</td><td style=\"text-align: right;\">           0.00139471 </td><td style=\"text-align: right;\">5</td><td>[0.1, 1]  </td><td style=\"text-align: right;\">0.000180074</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        125.022 </td><td style=\"text-align: right;\">      0.287559</td><td style=\"text-align: right;\">     0.577736</td><td style=\"text-align: right;\">       0.161692 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00005</td><td>TERMINATED</td><td>172.26.71.104:17509</td><td style=\"text-align: right;\"> 64</td><td>                    </td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.359041</td><td style=\"text-align: right;\">           0.00140208 </td><td style=\"text-align: right;\">4</td><td>[0.1, 1]  </td><td style=\"text-align: right;\">0.000461313</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        183.843 </td><td style=\"text-align: right;\">      0.244292</td><td style=\"text-align: right;\">     0.622077</td><td style=\"text-align: right;\">       0.165922 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00006</td><td>TERMINATED</td><td>172.26.71.104:18379</td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.380479</td><td style=\"text-align: right;\">           0.00836945 </td><td style=\"text-align: right;\">4</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.00168697 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.504 </td><td style=\"text-align: right;\">      0.899329</td><td style=\"text-align: right;\">     0.588115</td><td style=\"text-align: right;\">       0.762679 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00007</td><td>TERMINATED</td><td>172.26.71.104:18705</td><td style=\"text-align: right;\">256</td><td>{&#x27;risk_factors&#x27;_1880</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.358256</td><td style=\"text-align: right;\">           0.0819833  </td><td style=\"text-align: right;\">2</td><td>[0.1, 1]  </td><td style=\"text-align: right;\">0.00664463 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.594 </td><td style=\"text-align: right;\">      0.23135 </td><td style=\"text-align: right;\">     0.507706</td><td style=\"text-align: right;\">       0.494993 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00008</td><td>TERMINATED</td><td>172.26.71.104:19025</td><td style=\"text-align: right;\">512</td><td>{&#x27;risk_factors&#x27;_3ec0</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.336824</td><td style=\"text-align: right;\">           0.000119401</td><td style=\"text-align: right;\">3</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.000310779</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        162.489 </td><td style=\"text-align: right;\">      0.424243</td><td style=\"text-align: right;\">     0.666694</td><td style=\"text-align: right;\">       0.162708 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00009</td><td>TERMINATED</td><td>172.26.71.104:19622</td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.233803</td><td style=\"text-align: right;\">           0.000775038</td><td style=\"text-align: right;\">3</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.000116518</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         53.977 </td><td style=\"text-align: right;\">      0.510008</td><td style=\"text-align: right;\">     0.68616 </td><td style=\"text-align: right;\">       0.226474 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00010</td><td>TERMINATED</td><td>172.26.71.104:20039</td><td style=\"text-align: right;\"> 64</td><td>{&#x27;risk_factors&#x27;_2200</td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.252546</td><td style=\"text-align: right;\">           0.0625613  </td><td style=\"text-align: right;\">1</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.000287889</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.2049</td><td style=\"text-align: right;\">      0.492505</td><td style=\"text-align: right;\">     0.502293</td><td style=\"text-align: right;\">       0.925577 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00011</td><td>TERMINATED</td><td>172.26.71.104:20369</td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.445129</td><td style=\"text-align: right;\">           0.00447013 </td><td style=\"text-align: right;\">5</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.000287529</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         25.7149</td><td style=\"text-align: right;\">      0.661455</td><td style=\"text-align: right;\">     0.568599</td><td style=\"text-align: right;\">       0.702996 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00012</td><td>TERMINATED</td><td>172.26.71.104:20712</td><td style=\"text-align: right;\"> 64</td><td>                    </td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.416739</td><td style=\"text-align: right;\">           0.00199038 </td><td style=\"text-align: right;\">4</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.000111347</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         38.7415</td><td style=\"text-align: right;\">      0.730022</td><td style=\"text-align: right;\">     0.459512</td><td style=\"text-align: right;\">       0.701363 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00013</td><td>TERMINATED</td><td>172.26.71.104:21087</td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.451789</td><td style=\"text-align: right;\">           0.0190887  </td><td style=\"text-align: right;\">2</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.00657516 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8083</td><td style=\"text-align: right;\">      0.576662</td><td style=\"text-align: right;\">     0.517734</td><td style=\"text-align: right;\">       0.466137 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00014</td><td>TERMINATED</td><td>172.26.71.104:21402</td><td style=\"text-align: right;\"> 64</td><td>{&#x27;risk_factors&#x27;_3bc0</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.449087</td><td style=\"text-align: right;\">           0.00233504 </td><td style=\"text-align: right;\">1</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.00413981 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.9757</td><td style=\"text-align: right;\">      0.974249</td><td style=\"text-align: right;\">     0.563043</td><td style=\"text-align: right;\">       0.601289 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00015</td><td>TERMINATED</td><td>172.26.71.104:21752</td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.318777</td><td style=\"text-align: right;\">           0.000243897</td><td style=\"text-align: right;\">4</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.00011836 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         29.7149</td><td style=\"text-align: right;\">      0.588495</td><td style=\"text-align: right;\">     0.610371</td><td style=\"text-align: right;\">       0.293962 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00016</td><td>TERMINATED</td><td>172.26.71.104:22106</td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.465635</td><td style=\"text-align: right;\">           0.000940633</td><td style=\"text-align: right;\">4</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.00335965 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        129.575 </td><td style=\"text-align: right;\">      0.685333</td><td style=\"text-align: right;\">     0.657808</td><td style=\"text-align: right;\">       0.693094 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00017</td><td>TERMINATED</td><td>172.26.71.104:22728</td><td style=\"text-align: right;\">256</td><td>{&#x27;risk_factors&#x27;_8bc0</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.310384</td><td style=\"text-align: right;\">           0.00093535 </td><td style=\"text-align: right;\">4</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.00145516 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         45.857 </td><td style=\"text-align: right;\">      0.462059</td><td style=\"text-align: right;\">     0.688196</td><td style=\"text-align: right;\">       0.244884 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00018</td><td>TERMINATED</td><td>172.26.71.104:23133</td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.457206</td><td style=\"text-align: right;\">           0.000390623</td><td style=\"text-align: right;\">4</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.00297717 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.0612</td><td style=\"text-align: right;\">      0.793254</td><td style=\"text-align: right;\">     0.538093</td><td style=\"text-align: right;\">       0.524505 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00019</td><td>TERMINATED</td><td>172.26.71.104:23456</td><td style=\"text-align: right;\"> 64</td><td>{&#x27;risk_factors&#x27;_3c40</td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.268014</td><td style=\"text-align: right;\">           0.0569797  </td><td style=\"text-align: right;\">2</td><td>[0.1, 1]  </td><td style=\"text-align: right;\">0.000524182</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         27.3954</td><td style=\"text-align: right;\">      0.242519</td><td style=\"text-align: right;\">     0.498001</td><td style=\"text-align: right;\">       0.301101 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00020</td><td>TERMINATED</td><td>172.26.71.104:23805</td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.141951</td><td style=\"text-align: right;\">           0.00573356 </td><td style=\"text-align: right;\">5</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.00019293 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         33.8172</td><td style=\"text-align: right;\">      0.744997</td><td style=\"text-align: right;\">     0.550927</td><td style=\"text-align: right;\">       0.404197 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00021</td><td>TERMINATED</td><td>172.26.71.104:24164</td><td style=\"text-align: right;\">256</td><td>{&#x27;risk_factors&#x27;_ea00</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.21215 </td><td style=\"text-align: right;\">           0.0346222  </td><td style=\"text-align: right;\">5</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.00223791 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.7138</td><td style=\"text-align: right;\">      0.827203</td><td style=\"text-align: right;\">     0.499119</td><td style=\"text-align: right;\">       0.789335 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00022</td><td>TERMINATED</td><td>172.26.71.104:24495</td><td style=\"text-align: right;\">512</td><td>{&#x27;risk_factors&#x27;_34c0</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.330571</td><td style=\"text-align: right;\">           0.0315996  </td><td style=\"text-align: right;\">2</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.000272976</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.4928</td><td style=\"text-align: right;\">      0.84589 </td><td style=\"text-align: right;\">     0.522096</td><td style=\"text-align: right;\">       1.25064  </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00023</td><td>TERMINATED</td><td>172.26.71.104:24808</td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.166481</td><td style=\"text-align: right;\">           0.000211673</td><td style=\"text-align: right;\">2</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.000202713</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         99.6976</td><td style=\"text-align: right;\">      0.49996 </td><td style=\"text-align: right;\">     0.700045</td><td style=\"text-align: right;\">       0.178384 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00024</td><td>TERMINATED</td><td>172.26.71.104:25334</td><td style=\"text-align: right;\">512</td><td>{&#x27;risk_factors&#x27;_7100</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.47678 </td><td style=\"text-align: right;\">           0.0717992  </td><td style=\"text-align: right;\">1</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.00207871 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         33.3129</td><td style=\"text-align: right;\">      1.17853 </td><td style=\"text-align: right;\">     0.504997</td><td style=\"text-align: right;\">       1.76815  </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00025</td><td>TERMINATED</td><td>172.26.71.104:25674</td><td style=\"text-align: right;\"> 64</td><td>{&#x27;risk_factors&#x27;_e580</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.412864</td><td style=\"text-align: right;\">           0.00320358 </td><td style=\"text-align: right;\">5</td><td>[0.1, 1]  </td><td style=\"text-align: right;\">0.00198688 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         51.3026</td><td style=\"text-align: right;\">      0.236935</td><td style=\"text-align: right;\">     0.52167 </td><td style=\"text-align: right;\">       0.169198 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00026</td><td>TERMINATED</td><td>172.26.71.104:26072</td><td style=\"text-align: right;\">512</td><td>{&#x27;risk_factors&#x27;_7ec0</td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.210148</td><td style=\"text-align: right;\">           0.0155512  </td><td style=\"text-align: right;\">1</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.00220838 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         20.8733</td><td style=\"text-align: right;\">      0.784556</td><td style=\"text-align: right;\">     0.530237</td><td style=\"text-align: right;\">       0.869087 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00027</td><td>TERMINATED</td><td>172.26.71.104:26390</td><td style=\"text-align: right;\">512</td><td>{&#x27;risk_factors&#x27;_a640</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.167597</td><td style=\"text-align: right;\">           0.0130139  </td><td style=\"text-align: right;\">3</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.00303996 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.4841</td><td style=\"text-align: right;\">      0.848707</td><td style=\"text-align: right;\">     0.498808</td><td style=\"text-align: right;\">       1.53536  </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00028</td><td>TERMINATED</td><td>172.26.71.104:26702</td><td style=\"text-align: right;\">256</td><td>{&#x27;risk_factors&#x27;_2000</td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.362871</td><td style=\"text-align: right;\">           0.00180659 </td><td style=\"text-align: right;\">4</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.000891406</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         55.5006</td><td style=\"text-align: right;\">      0.809484</td><td style=\"text-align: right;\">     0.6782  </td><td style=\"text-align: right;\">       0.378858 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00029</td><td>TERMINATED</td><td>172.26.71.104:27110</td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.363849</td><td style=\"text-align: right;\">           0.00144243 </td><td style=\"text-align: right;\">2</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.00998337 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         21.6044</td><td style=\"text-align: right;\">      0.501369</td><td style=\"text-align: right;\">     0.670353</td><td style=\"text-align: right;\">       0.276139 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00030</td><td>TERMINATED</td><td>172.26.71.104:27439</td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.15806 </td><td style=\"text-align: right;\">           0.00273479 </td><td style=\"text-align: right;\">1</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.000689529</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.7624</td><td style=\"text-align: right;\">      0.601368</td><td style=\"text-align: right;\">     0.478316</td><td style=\"text-align: right;\">       0.778024 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00031</td><td>TERMINATED</td><td>172.26.71.104:27753</td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.36327 </td><td style=\"text-align: right;\">           0.0130323  </td><td style=\"text-align: right;\">4</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.00965896 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         21.4263</td><td style=\"text-align: right;\">      0.695477</td><td style=\"text-align: right;\">     0.475402</td><td style=\"text-align: right;\">       0.703398 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00032</td><td>TERMINATED</td><td>172.26.71.104:28068</td><td style=\"text-align: right;\">256</td><td>{&#x27;risk_factors&#x27;_4140</td><td style=\"text-align: right;\">512</td><td style=\"text-align: right;\">0.437231</td><td style=\"text-align: right;\">           0.000142724</td><td style=\"text-align: right;\">1</td><td>[0.1, 1]  </td><td style=\"text-align: right;\">0.000219604</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         81.4021</td><td style=\"text-align: right;\">      0.243216</td><td style=\"text-align: right;\">     0.713144</td><td style=\"text-align: right;\">       0.0527005</td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00033</td><td>TERMINATED</td><td>172.26.71.104:28763</td><td style=\"text-align: right;\">256</td><td>                    </td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.178684</td><td style=\"text-align: right;\">           0.000100467</td><td style=\"text-align: right;\">2</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.000538918</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        103.43  </td><td style=\"text-align: right;\">      0.877604</td><td style=\"text-align: right;\">     0.715518</td><td style=\"text-align: right;\">       0.137495 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00034</td><td>TERMINATED</td><td>172.26.71.104:29344</td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.227442</td><td style=\"text-align: right;\">           0.00216676 </td><td style=\"text-align: right;\">4</td><td>[0.1, 10] </td><td style=\"text-align: right;\">0.00217685 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         64.5789</td><td style=\"text-align: right;\">      0.456538</td><td style=\"text-align: right;\">     0.676035</td><td style=\"text-align: right;\">       0.249646 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00035</td><td>TERMINATED</td><td>172.26.71.104:29839</td><td style=\"text-align: right;\">256</td><td>{&#x27;risk_factors&#x27;_7dc0</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.341786</td><td style=\"text-align: right;\">           0.00710633 </td><td style=\"text-align: right;\">3</td><td>[0.1, 1]  </td><td style=\"text-align: right;\">0.000531891</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         19.0341</td><td style=\"text-align: right;\">      0.26484 </td><td style=\"text-align: right;\">     0.575768</td><td style=\"text-align: right;\">       0.184845 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00036</td><td>TERMINATED</td><td>172.26.71.104:30157</td><td style=\"text-align: right;\">512</td><td>{&#x27;risk_factors&#x27;_5540</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.444641</td><td style=\"text-align: right;\">           0.00753568 </td><td style=\"text-align: right;\">3</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.000627203</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         34.3699</td><td style=\"text-align: right;\">      1.00026 </td><td style=\"text-align: right;\">     0.468021</td><td style=\"text-align: right;\">       1.23698  </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00037</td><td>TERMINATED</td><td>172.26.71.104:30516</td><td style=\"text-align: right;\">512</td><td>                    </td><td style=\"text-align: right;\"> 64</td><td style=\"text-align: right;\">0.371004</td><td style=\"text-align: right;\">           0.00496874 </td><td style=\"text-align: right;\">4</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.00698554 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.1312</td><td style=\"text-align: right;\">      0.933899</td><td style=\"text-align: right;\">     0.45376 </td><td style=\"text-align: right;\">       1.35135  </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00038</td><td>TERMINATED</td><td>172.26.71.104:30851</td><td style=\"text-align: right;\">512</td><td>{&#x27;risk_factors&#x27;_68c0</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.358819</td><td style=\"text-align: right;\">           0.082095   </td><td style=\"text-align: right;\">3</td><td>[0.1, 1]  </td><td style=\"text-align: right;\">0.00172501 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         38.6142</td><td style=\"text-align: right;\">      0.25849 </td><td style=\"text-align: right;\">     0.469067</td><td style=\"text-align: right;\">       0.384649 </td></tr>\n",
       "<tr><td>TorchTrainer_cb745_00039</td><td>TERMINATED</td><td>172.26.71.104:31203</td><td style=\"text-align: right;\"> 64</td><td>{&#x27;risk_factors&#x27;_be40</td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.170335</td><td style=\"text-align: right;\">           0.0021247  </td><td style=\"text-align: right;\">4</td><td>[1, 1]    </td><td style=\"text-align: right;\">0.00253384 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         37.3979</td><td style=\"text-align: right;\">      0.728457</td><td style=\"text-align: right;\">     0.540538</td><td style=\"text-align: right;\">       0.696136 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 20:00:32,344\tWARNING util.py:202 -- The `process_trial_save` operation took 4.779 s, which may be a performance bottleneck.\n",
      "2024-04-17 20:16:49,642\tWARNING tune.py:229 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-04-17 20:16:49,722\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56' in 0.0672s.\n",
      "2024-04-17 20:16:49,744\tINFO tune.py:1048 -- Total run time: 2393.45 seconds (2393.34 seconds for the tuning loop).\n",
      "2024-04-17 20:16:49,745\tWARNING tune.py:1063 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56\", trainable=...)\n",
      "2024-04-17 20:16:49,856\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 10 trial(s):\n",
      "- TorchTrainer_cb745_00040: FileNotFoundError('Could not fetch metrics for TorchTrainer_cb745_00040: both result.json and progress.csv were not found at /home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56/TorchTrainer_cb745_00040_40_batch_size=256,covariates_dict=None,d_ff=64,dropout=0.2172,lr=0.0002,num_layers=1,weight=0_1_10,weight_2024-04-17_19-36-57')\n",
      "- TorchTrainer_cb745_00041: FileNotFoundError('Could not fetch metrics for TorchTrainer_cb745_00041: both result.json and progress.csv were not found at /home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56/TorchTrainer_cb745_00041_41_batch_size=512,covariates_dict=None,d_ff=64,dropout=0.2509,lr=0.0078,num_layers=1,weight=0_1_1,weight__2024-04-17_19-36-57')\n",
      "- TorchTrainer_cb745_00042: FileNotFoundError('Could not fetch metrics for TorchTrainer_cb745_00042: both result.json and progress.csv were not found at /home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56/TorchTrainer_cb745_00042_42_batch_size=512,covariates_dict=risk_factors_age_sex_ldl_a_hdl_a_tc_a_tg_a_sbp_a_BMI_smoking_prevalent__2024-04-17_19-36-57')\n",
      "- TorchTrainer_cb745_00043: FileNotFoundError('Could not fetch metrics for TorchTrainer_cb745_00043: both result.json and progress.csv were not found at /home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56/TorchTrainer_cb745_00043_43_batch_size=512,covariates_dict=risk_factors_age_sex_ldl_a_hdl_a_tc_a_tg_a_sbp_a_BMI_smoking_prevalent__2024-04-17_19-36-57')\n",
      "- TorchTrainer_cb745_00044: FileNotFoundError('Could not fetch metrics for TorchTrainer_cb745_00044: both result.json and progress.csv were not found at /home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56/TorchTrainer_cb745_00044_44_batch_size=512,covariates_dict=None,d_ff=64,dropout=0.3319,lr=0.0042,num_layers=5,weight=1_1,weight_de_2024-04-17_19-36-57')\n",
      "- TorchTrainer_cb745_00045: FileNotFoundError('Could not fetch metrics for TorchTrainer_cb745_00045: both result.json and progress.csv were not found at /home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56/TorchTrainer_cb745_00045_45_batch_size=64,covariates_dict=risk_factors_age_sex_ldl_a_hdl_a_tc_a_tg_a_sbp_a_BMI_smoking_prevalent_d_2024-04-17_19-36-57')\n",
      "- TorchTrainer_cb745_00046: FileNotFoundError('Could not fetch metrics for TorchTrainer_cb745_00046: both result.json and progress.csv were not found at /home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56/TorchTrainer_cb745_00046_46_batch_size=256,covariates_dict=None,d_ff=128,dropout=0.2434,lr=0.0026,num_layers=1,weight=0_1_100,weig_2024-04-17_19-36-57')\n",
      "- TorchTrainer_cb745_00047: FileNotFoundError('Could not fetch metrics for TorchTrainer_cb745_00047: both result.json and progress.csv were not found at /home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56/TorchTrainer_cb745_00047_47_batch_size=512,covariates_dict=None,d_ff=64,dropout=0.1437,lr=0.0957,num_layers=4,weight=0_1_10,weight_2024-04-17_19-36-57')\n",
      "- TorchTrainer_cb745_00048: FileNotFoundError('Could not fetch metrics for TorchTrainer_cb745_00048: both result.json and progress.csv were not found at /home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56/TorchTrainer_cb745_00048_48_batch_size=256,covariates_dict=None,d_ff=128,dropout=0.1000,lr=0.0045,num_layers=4,weight=1_1,weight_d_2024-04-17_19-36-57')\n",
      "- TorchTrainer_cb745_00049: FileNotFoundError('Could not fetch metrics for TorchTrainer_cb745_00049: both result.json and progress.csv were not found at /home/xutingfeng/ray_results/TorchTrainer_2024-04-17_19-36-56/TorchTrainer_cb745_00049_49_batch_size=512,covariates_dict=risk_factors_age_sex_ldl_a_hdl_a_tc_a_tg_a_sbp_a_BMI_smoking_prevalent__2024-04-17_19-36-57')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearTransformerPL(\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (model): LinearTransformer(\n",
       "    (encoder): LinearTransformerEncoder(\n",
       "      (layers): Sequential(\n",
       "        (0): LinearResBlock(\n",
       "          (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "          (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=2911, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.17868361808817648, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=2911, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.17868361808817648, inplace=False)\n",
       "          (dropout2): Dropout(p=0.17868361808817648, inplace=False)\n",
       "        )\n",
       "        (1): LinearResBlock(\n",
       "          (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "          (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=2911, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.17868361808817648, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=2911, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.17868361808817648, inplace=False)\n",
       "          (dropout2): Dropout(p=0.17868361808817648, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (fc_norm): LayerNorm((2911,), eps=1e-06, elementwise_affine=True)\n",
       "      (head_drop): Dropout(p=0.17868361808817648, inplace=False)\n",
       "      (head): Linear(in_features=2911, out_features=128, bias=True)\n",
       "    )\n",
       "    (decoder): LinearFeatureFusionBlock(\n",
       "      (EachPartModuleList): ModuleList(\n",
       "        (0): LinearFeatureExtractor(\n",
       "          (extractor): Sequential(\n",
       "            (0): LinearActivationNormDropOut(\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation): SiLU()\n",
       "              (dropout): Dropout(p=0.17868361808817648, inplace=False)\n",
       "            )\n",
       "            (1): LinearActivationNormDropOut(\n",
       "              (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation): SiLU()\n",
       "              (dropout): Dropout(p=0.17868361808817648, inplace=False)\n",
       "            )\n",
       "            (2): LinearActivationNormDropOut(\n",
       "              (fc): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation): SiLU()\n",
       "              (dropout): Dropout(p=0.17868361808817648, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fusionDecoder): LinearFeatureExtractor(\n",
       "        (extractor): Sequential(\n",
       "          (0): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.17868361808817648, inplace=False)\n",
       "          )\n",
       "          (1): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.17868361808817648, inplace=False)\n",
       "          )\n",
       "          (2): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.17868361808817648, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "    (head_drop): Dropout(p=0.17868361808817648, inplace=False)\n",
       "    (head): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.train.lightning import (\n",
    "    RayDDPStrategy,\n",
    "    RayLightningEnvironment,\n",
    "    RayTrainReportCallback,\n",
    "    prepare_trainer,\n",
    ")\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "\n",
    "def train_func(config):\n",
    "    features_key = list(config[\"features_dict\"].keys())[0]\n",
    "    covariates_key = (\n",
    "        list(config[\"covariates_dict\"].keys())[0] if config[\"covariates_dict\"] else None\n",
    "    )\n",
    "\n",
    "    dataset = DatasetModule(\n",
    "        train=train_imputed,\n",
    "        test=test_imputed,\n",
    "        features=config[\"features_dict\"][features_key],\n",
    "        covariates=(\n",
    "            config[\"covariates_dict\"][covariates_key]\n",
    "            if config[\"covariates_dict\"]\n",
    "            else None\n",
    "        ),\n",
    "        label=[\"incident_cad\"],\n",
    "        num_classes=2,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "    )\n",
    "    # model = FullyConnectedNet(\n",
    "    #     input_size=len(proteomics),\n",
    "    #     hidden_size=config[\"hidden_size\"],\n",
    "    #     output_size=2,\n",
    "    #     lr=config[\"lr\"],\n",
    "    #     weight_decay=config[\"weight_decay\"],\n",
    "    #     weight=config[\"weight\"],\n",
    "    #     num_resblocks=config[\"num_resblocks\"],\n",
    "    # )\n",
    "    # model = FullyConnectedNet(**config)\n",
    "    model = LinearTransformerPL(**config)\n",
    "    trainer = Trainer(\n",
    "        devices=\"auto\",\n",
    "        strategy=RayDDPStrategy(),\n",
    "        callbacks=[RayTrainReportCallback()],\n",
    "        plugins=[RayLightningEnvironment()],\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "    trainer = prepare_trainer(trainer)\n",
    "    trainer.fit(model, dataset)\n",
    "\n",
    "\n",
    "LinearTransformerPL_search_space = {\n",
    "    \"features_dict\": {\"proteomics\": proteomics},\n",
    "    \"covariates_dict\": tune.choice([{\"risk_factors\": risk_factors}, None]),\n",
    "    \"d_ff\": tune.choice([64, 128, 256, 512]),\n",
    "    \"num_classes\": 2,\n",
    "    \"num_layers\": tune.choice([1, 2, 3, 4, 5]),\n",
    "    \"dropout\": tune.uniform(0.1, 0.5),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"weight_decay\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"weight\": tune.choice([[1, 1], [0.1, 1], [0.1, 10], [0.1, 100]]),\n",
    "    \"batch_size\": tune.choice([64, 256]),\n",
    "}\n",
    "\n",
    "\n",
    "search_space = LinearTransformerPL_search_space\n",
    "\n",
    "\n",
    "# The maximum training epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Number of sampls from parameter space\n",
    "num_samples = 50\n",
    "scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)\n",
    "\n",
    "\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=1, use_gpu=True, resources_per_worker={\"CPU\": 3, \"GPU\": 0.99}\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        num_to_keep=2,\n",
    "        checkpoint_score_attribute=\"ptl/val_auc\",\n",
    "        checkpoint_score_order=\"max\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define a TorchTrainer without hyper-parameters for Tuner\n",
    "ray_trainer = TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "\n",
    "def tune_asha(num_samples=10):\n",
    "    scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        ray_trainer,\n",
    "        param_space={\"train_loop_config\": search_space},\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"ptl/val_auc\",\n",
    "            mode=\"max\",\n",
    "            num_samples=num_samples,\n",
    "            scheduler=scheduler,\n",
    "        ),\n",
    "    )\n",
    "    return tuner.fit()\n",
    "\n",
    "\n",
    "results = tune_asha(num_samples=num_samples)\n",
    "\n",
    "\n",
    "# results.get_best_result(\"ptl/val_auc\")\n",
    "\n",
    "best_result = results.get_best_result(\"ptl/val_auc\")\n",
    "best_params = best_result.config\n",
    "best_result_epoch_dir = (\n",
    "    best_result.get_best_checkpoint(\"ptl/val_auc\", \"max\").path + \"/checkpoint.ckpt\"\n",
    ")\n",
    "best_model_state = torch.load(best_result_epoch_dir)\n",
    "best_model = LinearTransformerPL(**best_params[\"train_loop_config\"])\n",
    "best_model.load_state_dict(best_model_state[\"state_dict\"])\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptl/val_loss</th>\n",
       "      <th>ptl/val_auc</th>\n",
       "      <th>ptl/train_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>...</th>\n",
       "      <th>config/train_loop_config/features</th>\n",
       "      <th>config/train_loop_config/output_size</th>\n",
       "      <th>config/train_loop_config/hidden_size</th>\n",
       "      <th>config/train_loop_config/lr</th>\n",
       "      <th>config/train_loop_config/weight_decay</th>\n",
       "      <th>config/train_loop_config/weight</th>\n",
       "      <th>config/train_loop_config/batch_size</th>\n",
       "      <th>config/train_loop_config/num_resblocks</th>\n",
       "      <th>ptl/train_auc</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.871403</td>\n",
       "      <td>0.429451</td>\n",
       "      <td>0.958023</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323317</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.016544</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.769616</td>\n",
       "      <td>0.442054</td>\n",
       "      <td>17.417240</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323259</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>15.996523</td>\n",
       "      <td>0.493370</td>\n",
       "      <td>31853.636719</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323335</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.082954</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>25.533289</td>\n",
       "      <td>0.495971</td>\n",
       "      <td>203.381638</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323431</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.025166</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.508621</td>\n",
       "      <td>0.496772</td>\n",
       "      <td>305.108185</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323354</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.065775</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.793391</td>\n",
       "      <td>0.503008</td>\n",
       "      <td>113.718765</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323043</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.024657</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.674094</td>\n",
       "      <td>0.503451</td>\n",
       "      <td>379882.031250</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713322953</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.055456</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.607601</td>\n",
       "      <td>0.515016</td>\n",
       "      <td>5.766263</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323084</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.016803</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.581155</td>\n",
       "      <td>0.545226</td>\n",
       "      <td>1769.102905</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323201</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.061769</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.673552</td>\n",
       "      <td>0.553520</td>\n",
       "      <td>0.499288</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713322914</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.519288</td>\n",
       "      <td>cb14d_00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.998612</td>\n",
       "      <td>0.554710</td>\n",
       "      <td>15.840008</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323111</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.027782</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.890610</td>\n",
       "      <td>0.571885</td>\n",
       "      <td>57.018890</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323409</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.035912</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.698224</td>\n",
       "      <td>0.597362</td>\n",
       "      <td>4829.190918</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323499</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.059461</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.286245</td>\n",
       "      <td>0.624409</td>\n",
       "      <td>0.249461</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323000</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.671426</td>\n",
       "      <td>0.624668</td>\n",
       "      <td>0.979755</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323278</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.750641</td>\n",
       "      <td>0.631933</td>\n",
       "      <td>7.161577</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323285</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.022314</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.656647</td>\n",
       "      <td>0.864025</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323326</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.695345</td>\n",
       "      <td>0.659712</td>\n",
       "      <td>0.993335</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323222</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.484194</td>\n",
       "      <td>0.661935</td>\n",
       "      <td>0.307707</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713322938</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.512962</td>\n",
       "      <td>cb14d_00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.479037</td>\n",
       "      <td>0.678859</td>\n",
       "      <td>3.601321</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323454</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.701029</td>\n",
       "      <td>0.686616</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323216</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.680446</td>\n",
       "      <td>0.688562</td>\n",
       "      <td>0.401521</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323454</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.518939</td>\n",
       "      <td>cb14d_00045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.444778</td>\n",
       "      <td>0.692665</td>\n",
       "      <td>9.958006</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323389</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.413909</td>\n",
       "      <td>0.692937</td>\n",
       "      <td>0.325645</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323298</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.696158</td>\n",
       "      <td>0.695748</td>\n",
       "      <td>1.016221</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323242</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.654760</td>\n",
       "      <td>0.695936</td>\n",
       "      <td>0.715324</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323367</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.032581</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.534975</td>\n",
       "      <td>cb14d_00039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.435987</td>\n",
       "      <td>0.697490</td>\n",
       "      <td>0.265652</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323134</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.606820</td>\n",
       "      <td>cb14d_00018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.681322</td>\n",
       "      <td>0.699813</td>\n",
       "      <td>2.491766</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323090</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.667624</td>\n",
       "      <td>0.708358</td>\n",
       "      <td>0.402489</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713322988</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.509991</td>\n",
       "      <td>cb14d_00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.683271</td>\n",
       "      <td>0.710161</td>\n",
       "      <td>0.913886</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323064</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.691682</td>\n",
       "      <td>0.712135</td>\n",
       "      <td>1.031504</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323172</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.423016</td>\n",
       "      <td>0.715426</td>\n",
       "      <td>0.325107</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1713323022</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cb14d_00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.545007</td>\n",
       "      <td>0.721874</td>\n",
       "      <td>0.434878</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323265</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.805252</td>\n",
       "      <td>cb14d_00029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.456293</td>\n",
       "      <td>0.732878</td>\n",
       "      <td>0.230461</td>\n",
       "      <td>9</td>\n",
       "      <td>1110</td>\n",
       "      <td>1713322933</td>\n",
       "      <td>checkpoint_000009</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.909541</td>\n",
       "      <td>cb14d_00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.486532</td>\n",
       "      <td>0.734803</td>\n",
       "      <td>0.293429</td>\n",
       "      <td>7</td>\n",
       "      <td>888</td>\n",
       "      <td>1713323433</td>\n",
       "      <td>checkpoint_000007</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.009428</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.886436</td>\n",
       "      <td>cb14d_00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.540608</td>\n",
       "      <td>0.737997</td>\n",
       "      <td>0.709675</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323346</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.029872</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.526264</td>\n",
       "      <td>cb14d_00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.563464</td>\n",
       "      <td>0.741190</td>\n",
       "      <td>0.423109</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323307</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.799134</td>\n",
       "      <td>cb14d_00033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.160598</td>\n",
       "      <td>0.743172</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323180</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.744891</td>\n",
       "      <td>cb14d_00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.368085</td>\n",
       "      <td>0.743778</td>\n",
       "      <td>0.437846</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323478</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.797224</td>\n",
       "      <td>cb14d_00048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.149722</td>\n",
       "      <td>0.745369</td>\n",
       "      <td>0.087784</td>\n",
       "      <td>3</td>\n",
       "      <td>444</td>\n",
       "      <td>1713323111</td>\n",
       "      <td>checkpoint_000003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.824747</td>\n",
       "      <td>cb14d_00015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.130138</td>\n",
       "      <td>0.745965</td>\n",
       "      <td>0.127794</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323195</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.718975</td>\n",
       "      <td>cb14d_00022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.433692</td>\n",
       "      <td>0.746331</td>\n",
       "      <td>0.374462</td>\n",
       "      <td>3</td>\n",
       "      <td>444</td>\n",
       "      <td>1713322980</td>\n",
       "      <td>checkpoint_000003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.835551</td>\n",
       "      <td>cb14d_00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.154310</td>\n",
       "      <td>0.748137</td>\n",
       "      <td>0.070111</td>\n",
       "      <td>9</td>\n",
       "      <td>1110</td>\n",
       "      <td>1713323070</td>\n",
       "      <td>checkpoint_000009</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.877805</td>\n",
       "      <td>cb14d_00011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.356561</td>\n",
       "      <td>0.748540</td>\n",
       "      <td>0.223118</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323238</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>[0.1, 10]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.605419</td>\n",
       "      <td>cb14d_00026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.164787</td>\n",
       "      <td>0.748580</td>\n",
       "      <td>0.082826</td>\n",
       "      <td>9</td>\n",
       "      <td>1110</td>\n",
       "      <td>1713323029</td>\n",
       "      <td>checkpoint_000009</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.867491</td>\n",
       "      <td>cb14d_00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135635</td>\n",
       "      <td>0.749179</td>\n",
       "      <td>0.137879</td>\n",
       "      <td>3</td>\n",
       "      <td>444</td>\n",
       "      <td>1713322965</td>\n",
       "      <td>checkpoint_000003</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750204</td>\n",
       "      <td>cb14d_00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.168666</td>\n",
       "      <td>0.749420</td>\n",
       "      <td>0.103745</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>1713323157</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.749572</td>\n",
       "      <td>cb14d_00019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.365790</td>\n",
       "      <td>0.759699</td>\n",
       "      <td>0.317901</td>\n",
       "      <td>9</td>\n",
       "      <td>1110</td>\n",
       "      <td>1713323496</td>\n",
       "      <td>checkpoint_000009</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.884686</td>\n",
       "      <td>cb14d_00047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.509674</td>\n",
       "      <td>0.777171</td>\n",
       "      <td>0.540490</td>\n",
       "      <td>9</td>\n",
       "      <td>1110</td>\n",
       "      <td>1713323396</td>\n",
       "      <td>checkpoint_000009</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.011935</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.764836</td>\n",
       "      <td>cb14d_00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.357698</td>\n",
       "      <td>0.778954</td>\n",
       "      <td>0.489880</td>\n",
       "      <td>9</td>\n",
       "      <td>1110</td>\n",
       "      <td>1713323152</td>\n",
       "      <td>checkpoint_000009</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.811519</td>\n",
       "      <td>cb14d_00017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ptl/val_loss  ptl/val_auc  ptl/train_loss  epoch  step   timestamp  \\\n",
       "34      0.871403     0.429451        0.958023      0   111  1713323317   \n",
       "28      0.769616     0.442054       17.417240      0   111  1713323259   \n",
       "36     15.996523     0.493370    31853.636719      0   111  1713323335   \n",
       "44     25.533289     0.495971      203.381638      0   111  1713323431   \n",
       "38      0.508621     0.496772      305.108185      0   111  1713323354   \n",
       "10     14.793391     0.503008      113.718765      0   111  1713323043   \n",
       "3       1.674094     0.503451   379882.031250      0   111  1713322953   \n",
       "13      0.607601     0.515016        5.766263      0   111  1713323084   \n",
       "23      7.581155     0.545226     1769.102905      0   111  1713323201   \n",
       "0       0.673552     0.553520        0.499288      1   222  1713322914   \n",
       "16      0.998612     0.554710       15.840008      0   111  1713323111   \n",
       "42      1.890610     0.571885       57.018890      0   111  1713323409   \n",
       "49      2.698224     0.597362     4829.190918      0   111  1713323499   \n",
       "7       0.286245     0.624409        0.249461      0   111  1713323000   \n",
       "30      0.671426     0.624668        0.979755      0   111  1713323278   \n",
       "31      0.750641     0.631933        7.161577      0   111  1713323285   \n",
       "35      0.652381     0.656647        0.864025      0   111  1713323326   \n",
       "25      0.695345     0.659712        0.993335      0   111  1713323222   \n",
       "2       0.484194     0.661935        0.307707      1   222  1713322938   \n",
       "46      0.479037     0.678859        3.601321      0   111  1713323454   \n",
       "24      0.701029     0.686616        0.841629      0   111  1713323216   \n",
       "45      0.680446     0.688562        0.401521      1   222  1713323454   \n",
       "41      0.444778     0.692665        9.958006      0   111  1713323389   \n",
       "32      0.413909     0.692937        0.325645      0   111  1713323298   \n",
       "27      0.696158     0.695748        1.016221      0   111  1713323242   \n",
       "39      0.654760     0.695936        0.715324      1   222  1713323367   \n",
       "18      0.435987     0.697490        0.265652      1   222  1713323134   \n",
       "14      0.681322     0.699813        2.491766      0   111  1713323090   \n",
       "6       0.667624     0.708358        0.402489      1   222  1713322988   \n",
       "12      0.683271     0.710161        0.913886      0   111  1713323064   \n",
       "20      0.691682     0.712135        1.031504      0   111  1713323172   \n",
       "9       0.423016     0.715426        0.325107      0   111  1713323022   \n",
       "29      0.545007     0.721874        0.434878      1   222  1713323265   \n",
       "1       0.456293     0.732878        0.230461      9  1110  1713322933   \n",
       "43      0.486532     0.734803        0.293429      7   888  1713323433   \n",
       "37      0.540608     0.737997        0.709675      1   222  1713323346   \n",
       "33      0.563464     0.741190        0.423109      1   222  1713323307   \n",
       "21      0.160598     0.743172        0.117119      1   222  1713323180   \n",
       "48      0.368085     0.743778        0.437846      1   222  1713323478   \n",
       "15      0.149722     0.745369        0.087784      3   444  1713323111   \n",
       "22      0.130138     0.745965        0.127794      1   222  1713323195   \n",
       "5       0.433692     0.746331        0.374462      3   444  1713322980   \n",
       "11      0.154310     0.748137        0.070111      9  1110  1713323070   \n",
       "26      0.356561     0.748540        0.223118      1   222  1713323238   \n",
       "8       0.164787     0.748580        0.082826      9  1110  1713323029   \n",
       "4       0.135635     0.749179        0.137879      3   444  1713322965   \n",
       "19      0.168666     0.749420        0.103745      1   222  1713323157   \n",
       "47      0.365790     0.759699        0.317901      9  1110  1713323496   \n",
       "40      0.509674     0.777171        0.540490      9  1110  1713323396   \n",
       "17      0.357698     0.778954        0.489880      9  1110  1713323152   \n",
       "\n",
       "   checkpoint_dir_name  should_checkpoint  done  training_iteration  ...  \\\n",
       "34   checkpoint_000000               True  True                   1  ...   \n",
       "28   checkpoint_000000               True  True                   1  ...   \n",
       "36   checkpoint_000000               True  True                   1  ...   \n",
       "44   checkpoint_000000               True  True                   1  ...   \n",
       "38   checkpoint_000000               True  True                   1  ...   \n",
       "10   checkpoint_000000               True  True                   1  ...   \n",
       "3    checkpoint_000000               True  True                   1  ...   \n",
       "13   checkpoint_000000               True  True                   1  ...   \n",
       "23   checkpoint_000000               True  True                   1  ...   \n",
       "0    checkpoint_000001               True  True                   2  ...   \n",
       "16   checkpoint_000000               True  True                   1  ...   \n",
       "42   checkpoint_000000               True  True                   1  ...   \n",
       "49   checkpoint_000000               True  True                   1  ...   \n",
       "7    checkpoint_000000               True  True                   1  ...   \n",
       "30   checkpoint_000000               True  True                   1  ...   \n",
       "31   checkpoint_000000               True  True                   1  ...   \n",
       "35   checkpoint_000000               True  True                   1  ...   \n",
       "25   checkpoint_000000               True  True                   1  ...   \n",
       "2    checkpoint_000001               True  True                   2  ...   \n",
       "46   checkpoint_000000               True  True                   1  ...   \n",
       "24   checkpoint_000000               True  True                   1  ...   \n",
       "45   checkpoint_000001               True  True                   2  ...   \n",
       "41   checkpoint_000000               True  True                   1  ...   \n",
       "32   checkpoint_000000               True  True                   1  ...   \n",
       "27   checkpoint_000000               True  True                   1  ...   \n",
       "39   checkpoint_000001               True  True                   2  ...   \n",
       "18   checkpoint_000001               True  True                   2  ...   \n",
       "14   checkpoint_000000               True  True                   1  ...   \n",
       "6    checkpoint_000001               True  True                   2  ...   \n",
       "12   checkpoint_000000               True  True                   1  ...   \n",
       "20   checkpoint_000000               True  True                   1  ...   \n",
       "9    checkpoint_000000               True  True                   1  ...   \n",
       "29   checkpoint_000001               True  True                   2  ...   \n",
       "1    checkpoint_000009               True  True                  10  ...   \n",
       "43   checkpoint_000007               True  True                   8  ...   \n",
       "37   checkpoint_000001               True  True                   2  ...   \n",
       "33   checkpoint_000001               True  True                   2  ...   \n",
       "21   checkpoint_000001               True  True                   2  ...   \n",
       "48   checkpoint_000001               True  True                   2  ...   \n",
       "15   checkpoint_000003               True  True                   4  ...   \n",
       "22   checkpoint_000001               True  True                   2  ...   \n",
       "5    checkpoint_000003               True  True                   4  ...   \n",
       "11   checkpoint_000009               True  True                  10  ...   \n",
       "26   checkpoint_000001               True  True                   2  ...   \n",
       "8    checkpoint_000009               True  True                  10  ...   \n",
       "4    checkpoint_000003               True  True                   4  ...   \n",
       "19   checkpoint_000001               True  True                   2  ...   \n",
       "47   checkpoint_000009               True  True                  10  ...   \n",
       "40   checkpoint_000009               True  True                  10  ...   \n",
       "17   checkpoint_000009               True  True                  10  ...   \n",
       "\n",
       "                    config/train_loop_config/features  \\\n",
       "34  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "28  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "36  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "44  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "38  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "10  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "3   [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "13  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "23  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "0   [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "16  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "42  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "49  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "7   [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "30  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "31  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "35  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "25  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "2   [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "46  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "24  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "45  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "41  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "32  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "27  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "39  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "18  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "14  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "6   [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "12  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "20  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "9   [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "29  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "1   [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "43  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "37  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "33  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "21  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "48  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "15  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "22  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "5   [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "11  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "26  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "8   [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "4   [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "19  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "47  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "40  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "17  [C3, KLK7, GCHFR, NHLRC3, APOD, GAPDH, TP53I3,...   \n",
       "\n",
       "   config/train_loop_config/output_size  config/train_loop_config/hidden_size  \\\n",
       "34                                    2                                    64   \n",
       "28                                    2                                   256   \n",
       "36                                    2                                   128   \n",
       "44                                    2                                    64   \n",
       "38                                    2                                   128   \n",
       "10                                    2                                   256   \n",
       "3                                     2                                   256   \n",
       "13                                    2                                   128   \n",
       "23                                    2                                   128   \n",
       "0                                     2                                    64   \n",
       "16                                    2                                   128   \n",
       "42                                    2                                    64   \n",
       "49                                    2                                   256   \n",
       "7                                     2                                    64   \n",
       "30                                    2                                   128   \n",
       "31                                    2                                    64   \n",
       "35                                    2                                   128   \n",
       "25                                    2                                    64   \n",
       "2                                     2                                    64   \n",
       "46                                    2                                    64   \n",
       "24                                    2                                   128   \n",
       "45                                    2                                    64   \n",
       "41                                    2                                   256   \n",
       "32                                    2                                   128   \n",
       "27                                    2                                   256   \n",
       "39                                    2                                   128   \n",
       "18                                    2                                   128   \n",
       "14                                    2                                    64   \n",
       "6                                     2                                    64   \n",
       "12                                    2                                   256   \n",
       "20                                    2                                   256   \n",
       "9                                     2                                   256   \n",
       "29                                    2                                    64   \n",
       "1                                     2                                   256   \n",
       "43                                    2                                   256   \n",
       "37                                    2                                    64   \n",
       "33                                    2                                    64   \n",
       "21                                    2                                   128   \n",
       "48                                    2                                    64   \n",
       "15                                    2                                   256   \n",
       "22                                    2                                   128   \n",
       "5                                     2                                    64   \n",
       "11                                    2                                   256   \n",
       "26                                    2                                   128   \n",
       "8                                     2                                   256   \n",
       "4                                     2                                   256   \n",
       "19                                    2                                   256   \n",
       "47                                    2                                   256   \n",
       "40                                    2                                   256   \n",
       "17                                    2                                   256   \n",
       "\n",
       "    config/train_loop_config/lr  config/train_loop_config/weight_decay  \\\n",
       "34                     0.016544                               0.001542   \n",
       "28                     0.008100                               0.000161   \n",
       "36                     0.082954                               0.000133   \n",
       "44                     0.025166                               0.000702   \n",
       "38                     0.065775                               0.009226   \n",
       "10                     0.024657                               0.000302   \n",
       "3                      0.055456                               0.000116   \n",
       "13                     0.016803                               0.005894   \n",
       "23                     0.061769                               0.000146   \n",
       "0                      0.008995                               0.000364   \n",
       "16                     0.027782                               0.000856   \n",
       "42                     0.035912                               0.001711   \n",
       "49                     0.059461                               0.000461   \n",
       "7                      0.008825                               0.004160   \n",
       "30                     0.002963                               0.009129   \n",
       "31                     0.022314                               0.000261   \n",
       "35                     0.004409                               0.005428   \n",
       "25                     0.000721                               0.000338   \n",
       "2                      0.007954                               0.001458   \n",
       "46                     0.013125                               0.001563   \n",
       "24                     0.001034                               0.004153   \n",
       "45                     0.000281                               0.000760   \n",
       "41                     0.012170                               0.000120   \n",
       "32                     0.001876                               0.003412   \n",
       "27                     0.000236                               0.000117   \n",
       "39                     0.032581                               0.000882   \n",
       "18                     0.002784                               0.006143   \n",
       "14                     0.000144                               0.000612   \n",
       "6                      0.000623                               0.001118   \n",
       "12                     0.001289                               0.000199   \n",
       "20                     0.000305                               0.000172   \n",
       "9                      0.000368                               0.003184   \n",
       "29                     0.001125                               0.001849   \n",
       "1                      0.000145                               0.001997   \n",
       "43                     0.000126                               0.009428   \n",
       "37                     0.029872                               0.000123   \n",
       "33                     0.000960                               0.000139   \n",
       "21                     0.002267                               0.000177   \n",
       "48                     0.000657                               0.001861   \n",
       "15                     0.000541                               0.000109   \n",
       "22                     0.001146                               0.006850   \n",
       "5                      0.000112                               0.000553   \n",
       "11                     0.000854                               0.000222   \n",
       "26                     0.000650                               0.001633   \n",
       "8                      0.000695                               0.001497   \n",
       "4                      0.002320                               0.007747   \n",
       "19                     0.000439                               0.000128   \n",
       "47                     0.002342                               0.000585   \n",
       "40                     0.011935                               0.001056   \n",
       "17                     0.004444                               0.004366   \n",
       "\n",
       "   config/train_loop_config/weight config/train_loop_config/batch_size  \\\n",
       "34                          [1, 1]                                 256   \n",
       "28                      [0.1, 100]                                 256   \n",
       "36                       [0.1, 10]                                 256   \n",
       "44                      [0.1, 100]                                 256   \n",
       "38                        [0.1, 1]                                 256   \n",
       "10                      [0.1, 100]                                 256   \n",
       "3                       [0.1, 100]                                 256   \n",
       "13                       [0.1, 10]                                 256   \n",
       "23                       [0.1, 10]                                 256   \n",
       "0                       [0.1, 100]                                 256   \n",
       "16                       [0.1, 10]                                 256   \n",
       "42                       [0.1, 10]                                 256   \n",
       "49                       [0.1, 10]                                 256   \n",
       "7                         [0.1, 1]                                 256   \n",
       "30                      [0.1, 100]                                 256   \n",
       "31                       [0.1, 10]                                 256   \n",
       "35                      [0.1, 100]                                 256   \n",
       "25                      [0.1, 100]                                 256   \n",
       "2                        [0.1, 10]                                 256   \n",
       "46                       [0.1, 10]                                 256   \n",
       "24                      [0.1, 100]                                 256   \n",
       "45                      [0.1, 100]                                 256   \n",
       "41                       [0.1, 10]                                 256   \n",
       "32                       [0.1, 10]                                 256   \n",
       "27                      [0.1, 100]                                 256   \n",
       "39                        [0.1, 1]                                 256   \n",
       "18                       [0.1, 10]                                 256   \n",
       "14                      [0.1, 100]                                 256   \n",
       "6                       [0.1, 100]                                 256   \n",
       "12                      [0.1, 100]                                 256   \n",
       "20                      [0.1, 100]                                 256   \n",
       "9                        [0.1, 10]                                 256   \n",
       "29                          [1, 1]                                 256   \n",
       "1                           [1, 1]                                 256   \n",
       "43                          [1, 1]                                 256   \n",
       "37                          [1, 1]                                 256   \n",
       "33                          [1, 1]                                 256   \n",
       "21                        [0.1, 1]                                 256   \n",
       "48                          [1, 1]                                 256   \n",
       "15                        [0.1, 1]                                 256   \n",
       "22                        [0.1, 1]                                 256   \n",
       "5                           [1, 1]                                 256   \n",
       "11                        [0.1, 1]                                 256   \n",
       "26                       [0.1, 10]                                 256   \n",
       "8                         [0.1, 1]                                 256   \n",
       "4                         [0.1, 1]                                 256   \n",
       "19                        [0.1, 1]                                 256   \n",
       "47                          [1, 1]                                 256   \n",
       "40                          [1, 1]                                 256   \n",
       "17                          [1, 1]                                 256   \n",
       "\n",
       "    config/train_loop_config/num_resblocks  ptl/train_auc       logdir  \n",
       "34                                       3            NaN  cb14d_00034  \n",
       "28                                       3            NaN  cb14d_00028  \n",
       "36                                       3            NaN  cb14d_00036  \n",
       "44                                       3            NaN  cb14d_00044  \n",
       "38                                       3            NaN  cb14d_00038  \n",
       "10                                       3            NaN  cb14d_00010  \n",
       "3                                        3            NaN  cb14d_00003  \n",
       "13                                       3            NaN  cb14d_00013  \n",
       "23                                       3            NaN  cb14d_00023  \n",
       "0                                        3       0.519288  cb14d_00000  \n",
       "16                                       3            NaN  cb14d_00016  \n",
       "42                                       3            NaN  cb14d_00042  \n",
       "49                                       3            NaN  cb14d_00049  \n",
       "7                                        3            NaN  cb14d_00007  \n",
       "30                                       3            NaN  cb14d_00030  \n",
       "31                                       3            NaN  cb14d_00031  \n",
       "35                                       3            NaN  cb14d_00035  \n",
       "25                                       3            NaN  cb14d_00025  \n",
       "2                                        3       0.512962  cb14d_00002  \n",
       "46                                       3            NaN  cb14d_00046  \n",
       "24                                       3            NaN  cb14d_00024  \n",
       "45                                       3       0.518939  cb14d_00045  \n",
       "41                                       3            NaN  cb14d_00041  \n",
       "32                                       3            NaN  cb14d_00032  \n",
       "27                                       3            NaN  cb14d_00027  \n",
       "39                                       3       0.534975  cb14d_00039  \n",
       "18                                       3       0.606820  cb14d_00018  \n",
       "14                                       3            NaN  cb14d_00014  \n",
       "6                                        3       0.509991  cb14d_00006  \n",
       "12                                       3            NaN  cb14d_00012  \n",
       "20                                       3            NaN  cb14d_00020  \n",
       "9                                        3            NaN  cb14d_00009  \n",
       "29                                       3       0.805252  cb14d_00029  \n",
       "1                                        3       0.909541  cb14d_00001  \n",
       "43                                       3       0.886436  cb14d_00043  \n",
       "37                                       3       0.526264  cb14d_00037  \n",
       "33                                       3       0.799134  cb14d_00033  \n",
       "21                                       3       0.744891  cb14d_00021  \n",
       "48                                       3       0.797224  cb14d_00048  \n",
       "15                                       3       0.824747  cb14d_00015  \n",
       "22                                       3       0.718975  cb14d_00022  \n",
       "5                                        3       0.835551  cb14d_00005  \n",
       "11                                       3       0.877805  cb14d_00011  \n",
       "26                                       3       0.605419  cb14d_00026  \n",
       "8                                        3       0.867491  cb14d_00008  \n",
       "4                                        3       0.750204  cb14d_00004  \n",
       "19                                       3       0.749572  cb14d_00019  \n",
       "47                                       3       0.884686  cb14d_00047  \n",
       "40                                       3       0.764836  cb14d_00040  \n",
       "17                                       3       0.811519  cb14d_00017  \n",
       "\n",
       "[50 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_dataframe().sort_values(\"ptl/val_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'nn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m best_result_epoch_dir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      6\u001b[0m     best_result\u001b[38;5;241m.\u001b[39mget_best_checkpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mptl/val_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/checkpoint.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m best_model_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(best_result_epoch_dir)\n\u001b[0;32m----> 9\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mFullyConnectedNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbest_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_loop_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m best_model\u001b[38;5;241m.\u001b[39mload_state_dict(best_model_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m best_model\n",
      "Cell \u001b[0;32mIn[10], line 190\u001b[0m, in \u001b[0;36mFullyConnectedNet.__init__\u001b[0;34m(self, hidden_size, features, output_size, num_resblocks, lr, weight_decay, weight, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mBatchNorm1d(input_size)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(input_size, hidden_size)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresblocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;241m*\u001b[39m[LinearResBlock(hidden_size, hidden_size) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_resblocks)]\n\u001b[1;32m    194\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'nn'"
     ]
    }
   ],
   "source": [
    "# results.get_best_result(\"ptl/val_auc\")\n",
    "\n",
    "best_result = results.get_best_result(\"ptl/val_auc\")\n",
    "best_params = best_result.config\n",
    "best_result_epoch_dir = (\n",
    "    best_result.get_best_checkpoint(\"ptl/val_auc\", \"max\").path + \"/checkpoint.ckpt\"\n",
    ")\n",
    "best_model_state = torch.load(best_result_epoch_dir)\n",
    "best_model = FullyConnectedNet(**best_params[\"train_loop_config\"])\n",
    "best_model.load_state_dict(best_model_state[\"state_dict\"])\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': ['C3',\n",
       "  'KLK7',\n",
       "  'GCHFR',\n",
       "  'NHLRC3',\n",
       "  'APOD',\n",
       "  'GAPDH',\n",
       "  'TP53I3',\n",
       "  'CPA4',\n",
       "  'ANXA2',\n",
       "  'GRSF1',\n",
       "  'IL25',\n",
       "  'HMMR',\n",
       "  'MRPL52',\n",
       "  'PAIP2B',\n",
       "  'THAP12',\n",
       "  'FOS',\n",
       "  'FGF9',\n",
       "  'PITHD1',\n",
       "  'THSD1',\n",
       "  'PTGES2',\n",
       "  'DEFB103A_DEFB103B',\n",
       "  'ATP1B4',\n",
       "  'CYB5A',\n",
       "  'UNC79',\n",
       "  'SLC34A3',\n",
       "  'TAGLN3',\n",
       "  'SLIRP',\n",
       "  'CLASP1',\n",
       "  'PSMC3',\n",
       "  'KIR3DL2',\n",
       "  'BEX3',\n",
       "  'PFDN4',\n",
       "  'BCL7A',\n",
       "  'SMC3',\n",
       "  'SLC28A1',\n",
       "  'CDC123',\n",
       "  'GJA8',\n",
       "  'NMRK2',\n",
       "  'GATA3',\n",
       "  'CPLX2',\n",
       "  'RASGRF1',\n",
       "  'FGF7',\n",
       "  'ANKRA2',\n",
       "  'RBM25',\n",
       "  'LYZL2',\n",
       "  'CDK1',\n",
       "  'CREB3',\n",
       "  'CREBZF',\n",
       "  'IGLON5',\n",
       "  'SHC1',\n",
       "  'ZP4',\n",
       "  'TMOD4',\n",
       "  'CEP152',\n",
       "  'MYH7B',\n",
       "  'CEP350',\n",
       "  'CDC25A',\n",
       "  'TRIM26',\n",
       "  'MANEAL',\n",
       "  'MUCL3',\n",
       "  'GIMAP8',\n",
       "  'CYTH3',\n",
       "  'PDXDC1',\n",
       "  'CLINT1',\n",
       "  'MAPRE3',\n",
       "  'EVI2B',\n",
       "  'STAU1',\n",
       "  'PCNA',\n",
       "  'DNAJA1',\n",
       "  'JMJD1C',\n",
       "  'GAGE2A',\n",
       "  'GAD1',\n",
       "  'IZUMO1',\n",
       "  'PDCL2',\n",
       "  'PDE1C',\n",
       "  'STOML2',\n",
       "  'BSND',\n",
       "  'MAPK13',\n",
       "  'PDIA2',\n",
       "  'BTLA',\n",
       "  'MLLT1',\n",
       "  'TPRKB',\n",
       "  'ARHGAP5',\n",
       "  'BTNL10',\n",
       "  'PHLDB2',\n",
       "  'PDIA5',\n",
       "  'ATF4',\n",
       "  'PRAME',\n",
       "  'TOP1MT',\n",
       "  'KHDC3L',\n",
       "  'DCUN1D2',\n",
       "  'IL3',\n",
       "  'DCLRE1C',\n",
       "  'ERCC1',\n",
       "  'DCDC2C',\n",
       "  'VCPKMT',\n",
       "  'SPRING1',\n",
       "  'MORN4',\n",
       "  'ESPL1',\n",
       "  'H2AP',\n",
       "  'MORF4L2',\n",
       "  'SSH3',\n",
       "  'VWA5A',\n",
       "  'PBK',\n",
       "  'REST',\n",
       "  'SHD',\n",
       "  'TXNL1',\n",
       "  'TPM3',\n",
       "  'NEB',\n",
       "  'ATP1B2',\n",
       "  'CEP112',\n",
       "  'SART1',\n",
       "  'ATP6V1G2',\n",
       "  'ATP2B4',\n",
       "  'SAT1',\n",
       "  'ATP1B1',\n",
       "  'NECAP2',\n",
       "  'ATP5F1D',\n",
       "  'ATP1B3',\n",
       "  'ARNTL',\n",
       "  'ARL2BP',\n",
       "  'SCGB2A2',\n",
       "  'GAMT',\n",
       "  'ASS1',\n",
       "  'NFYA',\n",
       "  'GASK1A',\n",
       "  'MANSC4',\n",
       "  'HMGCS1',\n",
       "  'MMUT',\n",
       "  'CBX2',\n",
       "  'BRD3',\n",
       "  'BRDT',\n",
       "  'MAP1LC3B2',\n",
       "  'CASQ2',\n",
       "  'HIP1',\n",
       "  'GSTM4',\n",
       "  'GUK1',\n",
       "  'CALY',\n",
       "  'C1GALT1C1',\n",
       "  'TEF',\n",
       "  'CACNA1H',\n",
       "  'HADH',\n",
       "  'MEGF11',\n",
       "  'MED21',\n",
       "  'THRAP3',\n",
       "  'SPINK8',\n",
       "  'NAA10',\n",
       "  'MRPL24',\n",
       "  'GBP6',\n",
       "  'MYOM2',\n",
       "  'B3GAT3',\n",
       "  'GCLM',\n",
       "  'MYL1',\n",
       "  'HSD17B3',\n",
       "  'MYH4',\n",
       "  'TMED4',\n",
       "  'TMED10',\n",
       "  'SKIV2L',\n",
       "  'SLC12A2',\n",
       "  'SLC51B',\n",
       "  'MTR',\n",
       "  'CD2',\n",
       "  'BHMT2',\n",
       "  'SNU13',\n",
       "  'GP1BB',\n",
       "  'ARL13B',\n",
       "  'HCG22',\n",
       "  'RYR1',\n",
       "  'FDX2',\n",
       "  'ADRA2A',\n",
       "  'ERVV-1',\n",
       "  'EXOSC10',\n",
       "  'EXTL1',\n",
       "  'CYP24A1',\n",
       "  'KIF1C',\n",
       "  'USP47',\n",
       "  'PRKD2',\n",
       "  'PROCR',\n",
       "  'PACS2',\n",
       "  'KIF22',\n",
       "  'NXPE4',\n",
       "  'RTKN2',\n",
       "  'CSRP3',\n",
       "  'NUDT15',\n",
       "  'UHRF2',\n",
       "  'UGDH',\n",
       "  'CSF2',\n",
       "  'KRT17',\n",
       "  'FDX1',\n",
       "  'PYY',\n",
       "  'UBQLN3',\n",
       "  'CSDE1',\n",
       "  'DDA1',\n",
       "  'PALM3',\n",
       "  'VSIG10L',\n",
       "  'PKD2',\n",
       "  'ABCA2',\n",
       "  'EDEM2',\n",
       "  'ABRAXAS2',\n",
       "  'ECI2',\n",
       "  'PGLYRP4',\n",
       "  'PDZD2',\n",
       "  'EIF2AK3',\n",
       "  'EIF5',\n",
       "  'ELOB',\n",
       "  'ITPA',\n",
       "  'ACSL1',\n",
       "  'DENND2B',\n",
       "  'ZCCHC8',\n",
       "  'ACTN2',\n",
       "  'PDE4D',\n",
       "  'ACY3',\n",
       "  'ENOX2',\n",
       "  'YOD1',\n",
       "  'ENPEP',\n",
       "  'PMCH',\n",
       "  'PMM2',\n",
       "  'DHODH',\n",
       "  'KRT6C',\n",
       "  'NUP50',\n",
       "  'LAMA1',\n",
       "  'COPB2',\n",
       "  'LRCH4',\n",
       "  'TSNAX',\n",
       "  'LPP',\n",
       "  'TRPV3',\n",
       "  'IGHMBP2',\n",
       "  'LILRA4',\n",
       "  'FHIP2A',\n",
       "  'NOP56',\n",
       "  'RIPK4',\n",
       "  'TRAF3IP2',\n",
       "  'IGF2BP3',\n",
       "  'NFKB1',\n",
       "  'NFX1',\n",
       "  'REXO2',\n",
       "  'TSPAN15',\n",
       "  'RBM19',\n",
       "  'FRMD4B',\n",
       "  'NOS2',\n",
       "  'TPR',\n",
       "  'NPR1',\n",
       "  'RAB33A',\n",
       "  'RAB39B',\n",
       "  'RPS10',\n",
       "  'ANK2',\n",
       "  'IFNW1',\n",
       "  'CPTP',\n",
       "  'TTN',\n",
       "  'IL36G',\n",
       "  'IL31RA',\n",
       "  'RNASE4',\n",
       "  'LRIG3',\n",
       "  'CACNA1C',\n",
       "  'SCIN',\n",
       "  'DNLZ',\n",
       "  'STEAP4',\n",
       "  'CBLN1',\n",
       "  'CHP1',\n",
       "  'SAG',\n",
       "  'DOCK9',\n",
       "  'RRP15',\n",
       "  'SYNGAP1',\n",
       "  'CNTF',\n",
       "  'ECSCR',\n",
       "  'ELAVL4',\n",
       "  'FZD8',\n",
       "  'SCN2A',\n",
       "  'CNGB3',\n",
       "  'GABRA4',\n",
       "  'CACNB1',\n",
       "  'DEFB118',\n",
       "  'PNMA2',\n",
       "  'SMS',\n",
       "  'CDH4',\n",
       "  'SH3BGRL2',\n",
       "  'RAB3GAP1',\n",
       "  'RANBP2',\n",
       "  'MYOM1',\n",
       "  'CDKL5',\n",
       "  'CSPG5',\n",
       "  'CTNNA1',\n",
       "  'OMP',\n",
       "  'OTOA',\n",
       "  'GLP1R',\n",
       "  'CEND1',\n",
       "  'SNAP25',\n",
       "  'PCARE',\n",
       "  'FH',\n",
       "  'CORO6',\n",
       "  'SCN3B',\n",
       "  'DCUN1D1',\n",
       "  'NLGN2',\n",
       "  'DEFB104A_DEFB104B',\n",
       "  'DEFB116',\n",
       "  'CRYM',\n",
       "  'SPTBN2',\n",
       "  'GPR101',\n",
       "  'DGCR6',\n",
       "  'GRIN2B',\n",
       "  'ZPR1',\n",
       "  'CD3D',\n",
       "  'HTR1A',\n",
       "  'TFAP2A',\n",
       "  'BLOC1S2',\n",
       "  'IMPG1',\n",
       "  'BRME1',\n",
       "  'KLRC1',\n",
       "  'HTR1B',\n",
       "  'IFNL2',\n",
       "  'VAV3',\n",
       "  'ITPRIP',\n",
       "  'KLF4',\n",
       "  'KIF20B',\n",
       "  'ATXN2',\n",
       "  'TSPAN7',\n",
       "  'BCAT2',\n",
       "  'IGDCC3',\n",
       "  'LELP1',\n",
       "  'TMPRSS11B',\n",
       "  'KCNC4',\n",
       "  'MAP1LC3A',\n",
       "  'BRD2',\n",
       "  'LYPLA2',\n",
       "  'BOLA1',\n",
       "  'ART5',\n",
       "  'AGBL2',\n",
       "  'UPK3A',\n",
       "  'IL13RA2',\n",
       "  'HDAC9',\n",
       "  'ARMCX2',\n",
       "  'KIRREL1',\n",
       "  'TJP3',\n",
       "  'TUBB3',\n",
       "  'ARID3A',\n",
       "  'KRT8',\n",
       "  'BHLHE40',\n",
       "  'ARHGEF5',\n",
       "  'ADGRV1',\n",
       "  'LMOD2',\n",
       "  'GFRAL',\n",
       "  'DNAJB6',\n",
       "  'CD7',\n",
       "  'NAGA',\n",
       "  'PTPN9',\n",
       "  'NDUFA5',\n",
       "  'SCPEP1',\n",
       "  'PRR4',\n",
       "  'CSF3R',\n",
       "  'UNC5D',\n",
       "  'TYRP1',\n",
       "  'SHH',\n",
       "  'GLI2',\n",
       "  'GIPR',\n",
       "  'UBE2Z',\n",
       "  'GAD2',\n",
       "  'SLITRK1',\n",
       "  'BCL2L15',\n",
       "  'TLR1',\n",
       "  'EDNRB',\n",
       "  'NUMB',\n",
       "  'ALPI',\n",
       "  'KLRF1',\n",
       "  'SIRT1',\n",
       "  'HS6ST2',\n",
       "  'GIT1',\n",
       "  'CD36',\n",
       "  'TLR4',\n",
       "  'CSNK1D',\n",
       "  'CSF2RB',\n",
       "  'CD3G',\n",
       "  'RNF168',\n",
       "  'RAP1A',\n",
       "  'FGF12',\n",
       "  'REPS1',\n",
       "  'FOLH1',\n",
       "  'RICTOR',\n",
       "  'TRAF3',\n",
       "  'NFAT5',\n",
       "  'FOXJ3',\n",
       "  'CEBPA',\n",
       "  'TPSG1',\n",
       "  'NEDD9',\n",
       "  'RNF31',\n",
       "  'CEMIP2',\n",
       "  'RPA2',\n",
       "  'CLEC12A',\n",
       "  'NEDD4L',\n",
       "  'S100A13',\n",
       "  'NECTIN1',\n",
       "  'TOP2B',\n",
       "  'TP53BP1',\n",
       "  'SEMA6C',\n",
       "  'RELB',\n",
       "  'FGF16',\n",
       "  'NME1',\n",
       "  'NPHS2',\n",
       "  'NPHS1',\n",
       "  'FGF20',\n",
       "  'RALB',\n",
       "  'FGF3',\n",
       "  'IL12RB2',\n",
       "  'ANKMY2',\n",
       "  'FGF6',\n",
       "  'PTP4A3',\n",
       "  'BAG4',\n",
       "  'CPOX',\n",
       "  'TSPYL1',\n",
       "  'BABAM1',\n",
       "  'LATS1',\n",
       "  'TSC1',\n",
       "  'IGFL4',\n",
       "  'RBPMS',\n",
       "  'CD226',\n",
       "  'NXPH3',\n",
       "  'MTDH',\n",
       "  'DGKA',\n",
       "  'STX7',\n",
       "  'STX5',\n",
       "  'HIF1A',\n",
       "  'EIF4E',\n",
       "  'IL36A',\n",
       "  'CASP9',\n",
       "  'PGR',\n",
       "  'DENR',\n",
       "  'ST8SIA1',\n",
       "  'TGFBR1',\n",
       "  'KDM3A',\n",
       "  'PPL',\n",
       "  'DDX4',\n",
       "  'DDX39A',\n",
       "  'ACP1',\n",
       "  'PDZK1',\n",
       "  'SMPD3',\n",
       "  'MKI67',\n",
       "  'POLR2A',\n",
       "  'POF1B',\n",
       "  'PIKFYVE',\n",
       "  'C1QL2',\n",
       "  'ACRV1',\n",
       "  'ZBP1',\n",
       "  'PLCB1',\n",
       "  'YY1',\n",
       "  'ZNF174',\n",
       "  'ADAM12',\n",
       "  'XIAP',\n",
       "  'EP300',\n",
       "  'TERF1',\n",
       "  'ADAMTS1',\n",
       "  'WASL',\n",
       "  'SUMF1',\n",
       "  'ADAMTS4',\n",
       "  'PPM1B',\n",
       "  'STAT2',\n",
       "  'ERMAP',\n",
       "  'HDAC8',\n",
       "  'DAPK2',\n",
       "  'DAND5',\n",
       "  'IL21R',\n",
       "  'IL31',\n",
       "  'VAMP8',\n",
       "  'IL20RB',\n",
       "  'CCNE1',\n",
       "  'EVI5',\n",
       "  'MRPS16',\n",
       "  'PRR5',\n",
       "  'PRSS22',\n",
       "  'PSMG4',\n",
       "  'AKR7L',\n",
       "  'PER3',\n",
       "  'BLNK',\n",
       "  'CA8',\n",
       "  'DBN1',\n",
       "  'SPRED2',\n",
       "  'PALLD',\n",
       "  'SSBP1',\n",
       "  'BNIP3L',\n",
       "  'VEGFB',\n",
       "  'MCEMP1',\n",
       "  'ITGAL',\n",
       "  'INSR',\n",
       "  'ESR1',\n",
       "  'IFI30',\n",
       "  'CNP',\n",
       "  'NAGK',\n",
       "  'LAMP1',\n",
       "  'TP73',\n",
       "  'PGM2',\n",
       "  'DYNLT1',\n",
       "  'CHM',\n",
       "  'PFDN6',\n",
       "  'TPBGL',\n",
       "  'FZD10',\n",
       "  'CLIC5',\n",
       "  'DTX2',\n",
       "  'CLNS1A',\n",
       "  'RRAS',\n",
       "  'CLGN',\n",
       "  'PDRG1',\n",
       "  'RPGR',\n",
       "  'DUSP29',\n",
       "  'CLEC2L',\n",
       "  'EFNB2',\n",
       "  'CHRM1',\n",
       "  'CIT',\n",
       "  'LRFN2',\n",
       "  'AP2B1',\n",
       "  'FRMD7',\n",
       "  'CRTAP',\n",
       "  'PTH',\n",
       "  'FARSA',\n",
       "  'AKR1B10',\n",
       "  'PSMD5',\n",
       "  'FBN2',\n",
       "  'CUZD1',\n",
       "  'OSTN',\n",
       "  'UROS',\n",
       "  'AIDA',\n",
       "  'PRKAG3',\n",
       "  'NRXN3',\n",
       "  'AMIGO1',\n",
       "  'DCC',\n",
       "  'PPT1',\n",
       "  'ERC2',\n",
       "  'DOC2B',\n",
       "  'RAC3',\n",
       "  'DDX25',\n",
       "  'DDX53',\n",
       "  'TTF2',\n",
       "  'KCNH2',\n",
       "  'DIPK1C',\n",
       "  'RBP1',\n",
       "  'TRIM40',\n",
       "  'NLGN1',\n",
       "  'PMS1',\n",
       "  'COL28A1',\n",
       "  'EPB41L5',\n",
       "  'IFT20',\n",
       "  'CNTNAP4',\n",
       "  'LRP2',\n",
       "  'C2orf69',\n",
       "  'LYSMD3',\n",
       "  'MAG',\n",
       "  'MRI1',\n",
       "  'SCT',\n",
       "  'CASC3',\n",
       "  'LRTM1',\n",
       "  'SLC44A4',\n",
       "  'GTPBP2',\n",
       "  'TDO2',\n",
       "  'SLC1A4',\n",
       "  'SV2A',\n",
       "  'MFAP3L',\n",
       "  'GBA',\n",
       "  'SOX9',\n",
       "  'CAMLG',\n",
       "  'MN1',\n",
       "  'CABP2',\n",
       "  'CCDC28A',\n",
       "  'TMCO5A',\n",
       "  'NAA80',\n",
       "  'TEX101',\n",
       "  'STX1B',\n",
       "  'BATF',\n",
       "  'CADPS',\n",
       "  'LRRC38',\n",
       "  'SEZ6',\n",
       "  'MSLNL',\n",
       "  'MYL6B',\n",
       "  'MDM1',\n",
       "  'SOWAHA',\n",
       "  'LRP2BP',\n",
       "  'SCN2B',\n",
       "  'CD164L2',\n",
       "  'TBR1',\n",
       "  'MYLPF',\n",
       "  'CGN',\n",
       "  'TARM1',\n",
       "  'MICALL2',\n",
       "  'GNGT1',\n",
       "  'SCN3A',\n",
       "  'HNF1A',\n",
       "  'ANXA1',\n",
       "  'SUSD5',\n",
       "  'RBPMS2',\n",
       "  'RANBP1',\n",
       "  'COQ7',\n",
       "  'MYBPC2',\n",
       "  'DMP1',\n",
       "  'ANP32C',\n",
       "  'PRRT3',\n",
       "  'PNMA1',\n",
       "  'HSDL2',\n",
       "  'TMEM132A',\n",
       "  'IGSF21',\n",
       "  'MYL4',\n",
       "  'DLL4',\n",
       "  'DMD',\n",
       "  'MYL3',\n",
       "  'EDN1',\n",
       "  'GIP',\n",
       "  'HSBP1',\n",
       "  'BOLA2_BOLA2B',\n",
       "  'AIF1L',\n",
       "  'OXCT1',\n",
       "  'PAGR1',\n",
       "  'SNED1',\n",
       "  'OPLAH',\n",
       "  'GNPDA1',\n",
       "  'SNX5',\n",
       "  'AHNAK2',\n",
       "  'AHNAK',\n",
       "  'BECN1',\n",
       "  'FAM172A',\n",
       "  'VIPR1',\n",
       "  'HRC',\n",
       "  'KHK',\n",
       "  'POMC',\n",
       "  'HS1BP3',\n",
       "  'NUDT10',\n",
       "  'PYDC1',\n",
       "  'SIL1',\n",
       "  'HMGCL',\n",
       "  'SIGLEC8',\n",
       "  'CRYZL1',\n",
       "  'CCER2',\n",
       "  'LAMB1',\n",
       "  'GRP',\n",
       "  'CBS',\n",
       "  'ADAMTSL4',\n",
       "  'EPPK1',\n",
       "  'LIPF',\n",
       "  'B3GNT7',\n",
       "  'RECK',\n",
       "  'SCRIB',\n",
       "  'SEC31A',\n",
       "  'RNF149',\n",
       "  'COMMD1',\n",
       "  'ATP6V1G1',\n",
       "  'RNF5',\n",
       "  'ROBO4',\n",
       "  'FSHB',\n",
       "  'RPL14',\n",
       "  'CEP170',\n",
       "  'AAMDC',\n",
       "  'EIF2S2',\n",
       "  'SCN4B',\n",
       "  'SEL1L',\n",
       "  'INPP5D',\n",
       "  'FSTL1',\n",
       "  'EHD3',\n",
       "  'PECR',\n",
       "  'ECHS1',\n",
       "  'MECR',\n",
       "  'TOR1AIP1',\n",
       "  'ASRGL1',\n",
       "  'IDO1',\n",
       "  'ZP3',\n",
       "  'GADD45GIP1',\n",
       "  'RNASE10',\n",
       "  'MAN1A2',\n",
       "  'COL2A1',\n",
       "  'NIT1',\n",
       "  'ITPR1',\n",
       "  'ENPP6',\n",
       "  'ENO3',\n",
       "  'LONP1',\n",
       "  'DNAJC6',\n",
       "  'NFE2',\n",
       "  'ENTR1',\n",
       "  'GATD3',\n",
       "  'M6PR',\n",
       "  'CALCOCO2',\n",
       "  'APOBR',\n",
       "  'ECM1',\n",
       "  'ACYP1',\n",
       "  'WFDC1',\n",
       "  'GM2A',\n",
       "  'PLG',\n",
       "  'SH3GL3',\n",
       "  'PCBD1',\n",
       "  'RLN2',\n",
       "  'C1QTNF9',\n",
       "  'SERPINI1',\n",
       "  'GLA',\n",
       "  'CACYBP',\n",
       "  'MARS1',\n",
       "  'HMCN2',\n",
       "  'C7',\n",
       "  'LPA',\n",
       "  'FGA',\n",
       "  'CLEC3B',\n",
       "  'PAXX',\n",
       "  'C1QTNF5',\n",
       "  'MENT',\n",
       "  'ADGRD1',\n",
       "  'VTI1A',\n",
       "  'DAAM1',\n",
       "  'GNPDA2',\n",
       "  'PENK',\n",
       "  'SYAP1',\n",
       "  'ADD1',\n",
       "  'PINLYP',\n",
       "  'JAM3',\n",
       "  'PRKG1',\n",
       "  'ITGA2',\n",
       "  'DNAJB2',\n",
       "  'SNX15',\n",
       "  'DIPK2B',\n",
       "  'TBCA',\n",
       "  'GP5',\n",
       "  'YWHAQ',\n",
       "  'PDE5A',\n",
       "  'DTD1',\n",
       "  'DDI2',\n",
       "  'ADH1B',\n",
       "  'ST13',\n",
       "  'INHBB',\n",
       "  'ERP29',\n",
       "  'PHYKPL',\n",
       "  'MOCS2',\n",
       "  'AFAP1',\n",
       "  'SPART',\n",
       "  'HEG1',\n",
       "  'BMPER',\n",
       "  'PDIA3',\n",
       "  'DCTD',\n",
       "  'MFAP4',\n",
       "  'BMP10',\n",
       "  'SPINK2',\n",
       "  'EPHA4',\n",
       "  'ACHE',\n",
       "  'CHAD',\n",
       "  'UBXN1',\n",
       "  'TNFRSF17',\n",
       "  'SLC9A3R1',\n",
       "  'LZTFL1',\n",
       "  'ARHGAP45',\n",
       "  'AMOT',\n",
       "  'CD72',\n",
       "  'CELSR2',\n",
       "  'GIMAP7',\n",
       "  'SDK2',\n",
       "  'GHR',\n",
       "  'RABEP1',\n",
       "  'CD300A',\n",
       "  'SEMA3G',\n",
       "  'CRELD1',\n",
       "  'RIDA',\n",
       "  'SFRP4',\n",
       "  'MXRA8',\n",
       "  'APPL2',\n",
       "  'MYOM3',\n",
       "  'FGFR4',\n",
       "  'TNFAIP8L2',\n",
       "  'PTRHD1',\n",
       "  'COL5A1',\n",
       "  'FUOM',\n",
       "  'AKAP12',\n",
       "  'CTSE',\n",
       "  'SCGB3A1',\n",
       "  'TPD52L2',\n",
       "  'NAGPA',\n",
       "  'UROD',\n",
       "  'GMPR2',\n",
       "  'SNCA',\n",
       "  'GLRX5',\n",
       "  'KCTD5',\n",
       "  'UPK3BL1',\n",
       "  'TRIM24',\n",
       "  'CTAG1A_CTAG1B',\n",
       "  'FUT1',\n",
       "  'HRAS',\n",
       "  'TET2',\n",
       "  'COL4A4',\n",
       "  'TCN1',\n",
       "  'KLKB1',\n",
       "  'QSOX1',\n",
       "  'CEACAM18',\n",
       "  'EFCAB2',\n",
       "  'NEK7',\n",
       "  'NFKB2',\n",
       "  'CEACAM20',\n",
       "  'RGL2',\n",
       "  'SEPTIN7',\n",
       "  'SAP18',\n",
       "  'ARAF',\n",
       "  'GABARAPL1',\n",
       "  'SAT2',\n",
       "  'ARHGAP30',\n",
       "  'TRDMT1',\n",
       "  'ID4',\n",
       "  'PKN3',\n",
       "  'MAPKAPK2',\n",
       "  'TNPO1',\n",
       "  'TAP1',\n",
       "  'TCP11',\n",
       "  'ITGAX',\n",
       "  'IFIT3',\n",
       "  'ACADM',\n",
       "  'CEP290',\n",
       "  'TAB2',\n",
       "  'GAS2',\n",
       "  'RPE',\n",
       "  'ZNF75D',\n",
       "  'LSM8',\n",
       "  'CENPJ',\n",
       "  'CINP',\n",
       "  'RNF43',\n",
       "  'IFIT1',\n",
       "  'CA7',\n",
       "  'RNF4',\n",
       "  'CENPF',\n",
       "  'TPPP2',\n",
       "  'IL9',\n",
       "  'PAFAH2',\n",
       "  'EPN1',\n",
       "  'COL9A2',\n",
       "  'PPIE',\n",
       "  'TLR2',\n",
       "  'MNAT1',\n",
       "  'ERI1',\n",
       "  'CD3E',\n",
       "  'MAGEA3',\n",
       "  'ALMS1',\n",
       "  'PPP1R12B',\n",
       "  'VPS28',\n",
       "  'PTTG1',\n",
       "  'MORF4L1',\n",
       "  'KIAA1549',\n",
       "  'SPRR1B',\n",
       "  'SLK',\n",
       "  'TK1',\n",
       "  'OFD1',\n",
       "  'KIAA1549L',\n",
       "  'MTHFSD',\n",
       "  'EVPL',\n",
       "  'GADD45B',\n",
       "  'TIGIT',\n",
       "  'CCND2',\n",
       "  'BRD1',\n",
       "  'SHPK',\n",
       "  'VSTM2B',\n",
       "  'TEX33',\n",
       "  'GUCY2C',\n",
       "  'CDH22',\n",
       "  'SERPINH1',\n",
       "  'RAPGEF2',\n",
       "  'PRUNE2',\n",
       "  'MTUS1',\n",
       "  'TMED1',\n",
       "  'GTF2IRD1',\n",
       "  'CASP4',\n",
       "  'OGT',\n",
       "  'RAD51',\n",
       "  'TXK',\n",
       "  'PARD3',\n",
       "  'CD82',\n",
       "  'BCHE',\n",
       "  'SERPINF2',\n",
       "  'SERPINA1',\n",
       "  'SERPINA4',\n",
       "  'SGSH',\n",
       "  'CFB',\n",
       "  'NPC2',\n",
       "  'PRDX2',\n",
       "  'TXN',\n",
       "  'CYB5R2',\n",
       "  'MST1',\n",
       "  'CAT',\n",
       "  'CTBS',\n",
       "  'SERPINF1',\n",
       "  'BRAP',\n",
       "  'HPSE',\n",
       "  'SERPINA5',\n",
       "  'F11',\n",
       "  'MBL2',\n",
       "  'CFHR5',\n",
       "  'IST1',\n",
       "  'PGLYRP2',\n",
       "  'CWC15',\n",
       "  'PALM',\n",
       "  'TTR',\n",
       "  'PSAP',\n",
       "  'ASAH1',\n",
       "  'HGFAC',\n",
       "  'AMOTL2',\n",
       "  'CRISP3',\n",
       "  'NMI',\n",
       "  'EIF2AK2',\n",
       "  'APCS',\n",
       "  'SLURP1',\n",
       "  'DTNB',\n",
       "  'LACRT',\n",
       "  'BTN1A1',\n",
       "  'THTPA',\n",
       "  'MPRIP',\n",
       "  'KLK15',\n",
       "  'RNASE6',\n",
       "  'NAP1L4',\n",
       "  'CDC26',\n",
       "  'LMNB1',\n",
       "  'NUDT16',\n",
       "  'PPBP',\n",
       "  'PF4',\n",
       "  'CFHR2',\n",
       "  'GSR',\n",
       "  'MDH1',\n",
       "  'IL2RG',\n",
       "  'REG3G',\n",
       "  'FNTA',\n",
       "  'RFC4',\n",
       "  'CMIP',\n",
       "  'NUBP1',\n",
       "  'FAM171B',\n",
       "  'NENF',\n",
       "  'AHSA1',\n",
       "  'IL22',\n",
       "  'COMMD9',\n",
       "  'VSIG10',\n",
       "  'KIAA2013',\n",
       "  'RCC1',\n",
       "  'ALDH2',\n",
       "  'UNG',\n",
       "  'VPS4B',\n",
       "  'RALY',\n",
       "  'RAB44',\n",
       "  'PXDNL',\n",
       "  'RAB2B',\n",
       "  'VSIG2',\n",
       "  'KIR2DL2',\n",
       "  'USP25',\n",
       "  'UBE2B',\n",
       "  'LARP1',\n",
       "  'S100A3',\n",
       "  'TDP1',\n",
       "  'CAPN3',\n",
       "  'MINDY1',\n",
       "  'SUSD4',\n",
       "  'TADA3',\n",
       "  'TARS1',\n",
       "  'LRRFIP1',\n",
       "  'TG',\n",
       "  'STAM',\n",
       "  'TGFB2',\n",
       "  'LTB',\n",
       "  'LUZP2',\n",
       "  'MAMDC4',\n",
       "  'HSPA2',\n",
       "  'BCL7B',\n",
       "  'CCDC134',\n",
       "  'GPRC5C',\n",
       "  'LAMTOR5',\n",
       "  'MTSS2',\n",
       "  'NDST1',\n",
       "  'GABARAP',\n",
       "  'CHCHD6',\n",
       "  'NACC1',\n",
       "  'AP1G2',\n",
       "  'TRIM58',\n",
       "  'SLC13A1',\n",
       "  'GPD1',\n",
       "  'SMAD2',\n",
       "  'SMAD3',\n",
       "  'GLYR1',\n",
       "  'SMPDL3B',\n",
       "  'SNX2',\n",
       "  'ARG2',\n",
       "  'SDCCAG8',\n",
       "  'TMEM106A',\n",
       "  'ACRBP',\n",
       "  'DUSP13',\n",
       "  'DYNC1H1',\n",
       "  'EDDM3B',\n",
       "  'DYNLT3',\n",
       "  'WDR46',\n",
       "  'PCDHB15',\n",
       "  'EPGN',\n",
       "  'DHPS',\n",
       "  'IMMT',\n",
       "  'PRC1',\n",
       "  'PPP1CC',\n",
       "  'ERN1',\n",
       "  'ZNRF4',\n",
       "  'ZNF830',\n",
       "  'YJU2',\n",
       "  'PCSK7',\n",
       "  'INSL4',\n",
       "  'ENOPH1',\n",
       "  'ITIH5',\n",
       "  'ENSA',\n",
       "  'TMPRSS11D',\n",
       "  'FTCD',\n",
       "  'PLSCR3',\n",
       "  'SEPTIN8',\n",
       "  'PRKAR2A',\n",
       "  'SMTN',\n",
       "  'NFU1',\n",
       "  'PBXIP1',\n",
       "  'HIP1R',\n",
       "  'ZFYVE19',\n",
       "  ...],\n",
       " 'output_size': 2,\n",
       " 'hidden_size': 256,\n",
       " 'lr': 0.004443650319903527,\n",
       " 'weight_decay': 0.004365535526638243,\n",
       " 'weight': [1, 1],\n",
       " 'batch_size': 256,\n",
       " 'num_resblocks': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[\"train_loop_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input df have NA: 145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>PRS</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BSA</th>\n",
       "      <th>genotype_array</th>\n",
       "      <th>age</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>...</th>\n",
       "      <th>TGFBR3</th>\n",
       "      <th>CRTAC1</th>\n",
       "      <th>IGFBP7</th>\n",
       "      <th>SELE</th>\n",
       "      <th>VWF</th>\n",
       "      <th>NOTCH3</th>\n",
       "      <th>CNTN1</th>\n",
       "      <th>ENG</th>\n",
       "      <th>ICAM2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19409</th>\n",
       "      <td>2883530.0</td>\n",
       "      <td>1.030583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>64.2</td>\n",
       "      <td>1.746282</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>71.3002</td>\n",
       "      <td>-100.66700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>-0.029539</td>\n",
       "      <td>0.022568</td>\n",
       "      <td>-0.027118</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>-0.026825</td>\n",
       "      <td>0.549870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19272</th>\n",
       "      <td>2867444.0</td>\n",
       "      <td>2.192278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>55.8</td>\n",
       "      <td>1.599219</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-12.4815</td>\n",
       "      <td>3.16181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.291950</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>-0.120500</td>\n",
       "      <td>0.597300</td>\n",
       "      <td>0.115700</td>\n",
       "      <td>0.243300</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.520822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49865</th>\n",
       "      <td>5869793.0</td>\n",
       "      <td>0.653794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>77.3</td>\n",
       "      <td>1.916181</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-11.4721</td>\n",
       "      <td>2.20519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.369750</td>\n",
       "      <td>-0.155300</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>-0.276700</td>\n",
       "      <td>-0.043900</td>\n",
       "      <td>0.195500</td>\n",
       "      <td>-0.111000</td>\n",
       "      <td>-0.990800</td>\n",
       "      <td>0.530330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39664</th>\n",
       "      <td>4880838.0</td>\n",
       "      <td>0.664819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>84.4</td>\n",
       "      <td>1.954852</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-11.1640</td>\n",
       "      <td>3.66252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0127</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.873200</td>\n",
       "      <td>0.236600</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.557512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30555</th>\n",
       "      <td>3987428.0</td>\n",
       "      <td>0.826465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>73.1</td>\n",
       "      <td>1.824859</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.4666</td>\n",
       "      <td>2.77498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5216</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>-0.160200</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>1.026700</td>\n",
       "      <td>-0.062150</td>\n",
       "      <td>-0.094500</td>\n",
       "      <td>-0.032700</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.548911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43327</th>\n",
       "      <td>5241912.0</td>\n",
       "      <td>1.085083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.381409</td>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-10.8083</td>\n",
       "      <td>4.46241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2348</td>\n",
       "      <td>-0.919950</td>\n",
       "      <td>0.803300</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.481500</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>-0.226200</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.540284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29129</th>\n",
       "      <td>3851862.0</td>\n",
       "      <td>1.294348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>72.9</td>\n",
       "      <td>1.849932</td>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-12.6549</td>\n",
       "      <td>3.40064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3290</td>\n",
       "      <td>-0.251250</td>\n",
       "      <td>-0.787400</td>\n",
       "      <td>-0.919000</td>\n",
       "      <td>0.212700</td>\n",
       "      <td>-0.617800</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>-0.124100</td>\n",
       "      <td>-0.940500</td>\n",
       "      <td>0.550269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>1144512.0</td>\n",
       "      <td>0.722791</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2.263883</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-12.7237</td>\n",
       "      <td>1.46547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>-0.284750</td>\n",
       "      <td>0.350300</td>\n",
       "      <td>1.608600</td>\n",
       "      <td>-0.341300</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>0.560168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>1177099.0</td>\n",
       "      <td>1.335307</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>75.1</td>\n",
       "      <td>1.910679</td>\n",
       "      <td>2</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-15.1573</td>\n",
       "      <td>7.36690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.172250</td>\n",
       "      <td>0.431300</td>\n",
       "      <td>0.121750</td>\n",
       "      <td>-0.754900</td>\n",
       "      <td>0.530700</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>-0.018900</td>\n",
       "      <td>-0.053400</td>\n",
       "      <td>0.545355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29456</th>\n",
       "      <td>3881441.0</td>\n",
       "      <td>1.055519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>1.614715</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-12.4170</td>\n",
       "      <td>4.44358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.291350</td>\n",
       "      <td>-0.231600</td>\n",
       "      <td>-0.446000</td>\n",
       "      <td>-0.775500</td>\n",
       "      <td>0.385750</td>\n",
       "      <td>0.243300</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.227400</td>\n",
       "      <td>0.549790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15287 rows × 2974 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             eid       PRS  sex  height  weight       BSA  genotype_array  \\\n",
       "19409  2883530.0  1.030583  1.0   171.0    64.2  1.746282               2   \n",
       "19272  2867444.0  2.192278  0.0   165.0    55.8  1.599219               2   \n",
       "49865  5869793.0  0.653794  1.0   171.0    77.3  1.916181               2   \n",
       "39664  4880838.0  0.664819  0.0   163.0    84.4  1.954852               2   \n",
       "30555  3987428.0  0.826465  0.0   164.0    73.1  1.824859               1   \n",
       "...          ...       ...  ...     ...     ...       ...             ...   \n",
       "43327  5241912.0  1.085083  1.0   176.0   116.0  2.381409               2   \n",
       "29129  3851862.0  1.294348  0.0   169.0    72.9  1.849932               2   \n",
       "1550   1144512.0  0.722791  1.0   191.0    96.6  2.263883               1   \n",
       "1888   1177099.0  1.335307  1.0   175.0    75.1  1.910679               2   \n",
       "29456  3881441.0  1.055519  0.0   161.0    58.3  1.614715               2   \n",
       "\n",
       "        age      PC1        PC2  ...  TGFBR3    CRTAC1    IGFBP7      SELE  \\\n",
       "19409  44.0  71.3002 -100.66700  ... -0.0087 -0.029539  0.022568 -0.027118   \n",
       "19272  53.0 -12.4815    3.16181  ...  0.1859  0.291950  0.147400 -0.120500   \n",
       "49865  62.0 -11.4721    2.20519  ...  0.0516  0.369750 -0.155300  0.035500   \n",
       "39664  62.0 -11.1640    3.66252  ... -0.0127  0.393200  0.174500  0.035700   \n",
       "30555  66.0 -11.4666    2.77498  ... -0.5216  0.005050 -0.160200  0.181900   \n",
       "...     ...      ...        ...  ...     ...       ...       ...       ...   \n",
       "43327  45.0 -10.8083    4.46241  ...  0.2348 -0.919950  0.803300  0.131600   \n",
       "29129  40.0 -12.6549    3.40064  ... -0.3290 -0.251250 -0.787400 -0.919000   \n",
       "1550   59.0 -12.7237    1.46547  ...  0.1043 -0.284750  0.350300  1.608600   \n",
       "1888   63.0 -15.1573    7.36690  ...  0.2172  0.172250  0.431300  0.121750   \n",
       "29456  53.0 -12.4170    4.44358  ...  0.1298  0.291350 -0.231600 -0.446000   \n",
       "\n",
       "            VWF    NOTCH3     CNTN1       ENG     ICAM2      pred  \n",
       "19409  0.008048  0.004249  0.000619  0.001707 -0.026825  0.549870  \n",
       "19272  0.597300  0.115700  0.243300  0.127800  0.063400  0.520822  \n",
       "49865 -0.276700 -0.043900  0.195500 -0.111000 -0.990800  0.530330  \n",
       "39664  0.873200  0.236600  0.114200  0.134400  0.008700  0.557512  \n",
       "30555  1.026700 -0.062150 -0.094500 -0.032700  0.213200  0.548911  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "43327  0.481500  0.279800 -0.226200  0.262600  0.239400  0.540284  \n",
       "29129  0.212700 -0.617800  0.123900 -0.124100 -0.940500  0.550269  \n",
       "1550  -0.341300  0.134100 -0.012000  0.226700  0.135200  0.560168  \n",
       "1888  -0.754900  0.530700  0.244000 -0.018900 -0.053400  0.545355  \n",
       "29456 -0.775500  0.385750  0.243300  0.219200  0.227400  0.549790  \n",
       "\n",
       "[15287 rows x 2974 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imputed = best_model.predict_df(test_imputed)\n",
    "test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cal_binary_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcal_binary_metrics\u001b[49m(test_imputed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincident_cad\u001b[39m\u001b[38;5;124m\"\u001b[39m], test_imputed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cal_binary_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "cal_binary_metrics(test_imputed[\"incident_cad\"], test_imputed[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "\n",
    "from tqdm.rich import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "\n",
    "def generate_multipletests_result(df, pvalue_col=\"pvalue\", alpha=0.05, method=\"fdr_bh\"):\n",
    "    df = df.copy()\n",
    "    pvalue_series = df[pvalue_col]\n",
    "    reject, pvals_corrected, _, _ = multipletests(\n",
    "        pvalue_series, alpha=alpha, method=\"fdr_bh\"\n",
    "    )\n",
    "    df[\"pval_corrected\"] = pvals_corrected\n",
    "    df[\"reject\"] = reject\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_best_cutoff(fpr, tpr, thresholds):\n",
    "    diff = tpr - fpr\n",
    "    Youden_index = np.argmax(diff)\n",
    "    optimal_threshold = thresholds[Youden_index]\n",
    "    optimal_FPR, optimal_TPR = fpr[Youden_index], tpr[Youden_index]\n",
    "    return optimal_threshold, optimal_FPR, optimal_TPR\n",
    "\n",
    "\n",
    "def cal_binary_metrics(y, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_pred)\n",
    "    AUC = roc_auc_score(y, y_pred)\n",
    "    # by best youden\n",
    "\n",
    "    optim_threshold, optim_fpr, optim_tpr = find_best_cutoff(fpr, tpr, thresholds)\n",
    "    y_pred_binary = (y_pred > optim_threshold).astype(int)\n",
    "    ACC = accuracy_score(y, y_pred_binary)\n",
    "    macro_f1 = f1_score(y, y_pred_binary, average=\"macro\")\n",
    "    sensitivity = optim_tpr\n",
    "    specificity = 1 - optim_fpr\n",
    "    precision, recall, _ = precision_recall_curve(y, y_pred)\n",
    "    APR = auc(recall, precision)\n",
    "\n",
    "    return {\n",
    "        \"AUC\": AUC,\n",
    "        \"ACC\": ACC,\n",
    "        \"Macro_F1\": macro_f1,\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"APR\": APR,\n",
    "    }\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.rich import tqdm\n",
    "\n",
    "# 定义神经网络模型\n",
    "\n",
    "\n",
    "class LinearResBlock(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearResBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "        self.batch_norm = nn.LayerNorm(output_size)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.fc1.weight, nonlinearity=\"relu\")  # <6>\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)  # <7>\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_resblocks=3):\n",
    "        super(FullyConnectedNet, self).__init__()\n",
    "        self.norm = nn.LayerNorm(input_size)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *[LinearResBlock(hidden_size, hidden_size) for _ in range(num_resblocks)]\n",
    "        )\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        out = torch.relu(self.fc1(x))\n",
    "        out = self.resblocks(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# 定义训练函数\n",
    "def train(model, dataset, criterion, optimizer, num_epochs):\n",
    "    train_loader = dataset.train_dataloader()\n",
    "    val_loader = dataset.test_dataloader()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        auroc = torchmetrics.AUROC(num_classes=2, task=\"multiclass\")\n",
    "        for inputs, labels in tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", total=len(train_loader)\n",
    "        ):\n",
    "            inputs, labels = inputs.to(\"cuda:0\"), labels.to(\"cuda:0\")\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.squeeze(-1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            auroc.update(torch.softmax(outputs, dim=-1), torch.argmax(labels, dim=1))\n",
    "        auc = auroc.compute()\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, AUC: {auc}\"\n",
    "        )\n",
    "        if epoch % 1 == 0:\n",
    "            test_auc = torchmetrics.AUROC(num_classes=2, task=\"multiclass\")\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(\"cuda:0\"), labels.to(\"cuda:0\")\n",
    "                outputs = model(inputs)\n",
    "                test_auc.update(\n",
    "                    torch.softmax(outputs, dim=-1), torch.argmax(labels, dim=1)\n",
    "                )\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Test AUC: {test_auc.compute()}\")\n",
    "    # test_auc = torchmetrics.AUROC(num_classes=2, task=\"multiclass\")\n",
    "    # for inputs, labels in dataset.test_dataloader():\n",
    "    #     inputs, labels = inputs.to(\"cuda:0\"), labels.to(\"cuda:0\")\n",
    "    #     outputs = model(inputs)\n",
    "    #     test_auc.update(torch.softmax(outputs, dim=-1), torch.argmax(labels, dim=1))\n",
    "    # print(f\"Test AUC: {test_auc.compute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置训练参数\n",
    "input_size = len(proteomics)  # 输入特征维度\n",
    "hidden_size = 512  # 隐藏层维度\n",
    "output_size = 2  # 输出类别数\n",
    "learning_rate = 5e-4\n",
    "batch_size = 256\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "# 创建模型实例\n",
    "best_model = FullyConnectedNet(\n",
    "    input_size=len(proteomics), hidden_size=256, output_size=2, num_resblocks=6\n",
    ")\n",
    "best_model.to(\"cuda:0\")\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.Tensor([0.1, 100]).to(\"cuda:0\"))\n",
    "optimizer = optim.NAdam(best_model.parameters(), lr=learning_rate, weight_decay=5e-3)\n",
    "\n",
    "\n",
    "# 开始训练\n",
    "train(best_model, dataset, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_list = []\n",
    "AUC = torchmetrics.AUROC(num_classes=2, task=\"multiclass\")\n",
    "\n",
    "best_model.eval()\n",
    "for x, y in dataset.test_dataloader():\n",
    "    y_pred = best_model(x.to(\"cuda:0\")).cpu().detach()\n",
    "    y_pred_list.append(y_pred)\n",
    "    y_list.append(y)\n",
    "    AUC.update(torch.softmax(y_pred, dim=-1), torch.argmax(y, dim=1))\n",
    "\n",
    "AUC_values = AUC.compute()\n",
    "print(f\"AUC: {AUC_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.softmax(torch.cat(y_pred_list), dim=-1)[:, 1].numpy()\n",
    "y_true = torch.argmax(torch.cat(y_list), dim=1).numpy()\n",
    "\n",
    "test_df = pd.DataFrame(\n",
    "    {\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_true\": y_true,\n",
    "    }\n",
    ")\n",
    "\n",
    "cal_binary_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_binary_metrics(test_df[\"y_true\"], test_df[\"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
