{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xutingfeng/miniforge3/envs/rapids-24.02/lib/python3.10/site-packages/dask/array/chunk_types.py:110: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  CuPy may not function correctly because multiple CuPy packages are installed\n",
      "  in your environment:\n",
      "\n",
      "    cupy, cupy-cuda12x\n",
      "\n",
      "  Follow these steps to resolve this issue:\n",
      "\n",
      "    1. For all packages listed above, run the following command to remove all\n",
      "       existing CuPy installations:\n",
      "\n",
      "         $ pip uninstall <package_name>\n",
      "\n",
      "      If you previously installed CuPy via conda, also run the following:\n",
      "\n",
      "         $ conda uninstall cupy\n",
      "\n",
      "    2. Install the appropriate CuPy package.\n",
      "       Refer to the Installation Guide for detailed instructions.\n",
      "\n",
      "         https://docs.cupy.dev/en/stable/install.html\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ppp_prediction.model_v2.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "from ppp_prediction.model import run_glmnet\n",
    "from ppp_prediction.cox import run_cox\n",
    "from ppp_prediction.metrics import cal_binary_metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from plotnine import *\n",
    "from sklearn.metrics import brier_score_loss, roc_curve, auc\n",
    "from dcurves import dca\n",
    "from functools import reduce, partial\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from scipy.stats import bootstrap\n",
    "\n",
    "\n",
    "def config_dict_to_df(config_dict, index_name):\n",
    "    \"\"\"\n",
    "    1) convert the config_dict to a dataframe\n",
    "    Example1\n",
    "            combination_dict = OrderedDict(\n",
    "        {\n",
    "            (\"PANEL\", \"Lasso\"): {\n",
    "                \"xvar\": [\"Age\", \"Sex\"],\n",
    "                \"model\": run_glmnet,\n",
    "                \"config\": {\"cv\": 6},\n",
    "            },\n",
    "            (\"PANEL\", \"xgboost\"): {\n",
    "                \"xvar\": [\"Age\", \"Sex\"],\n",
    "            },\n",
    "            (\"AgeSex\", \"xgboost\"): {\n",
    "                \"xvar\": [\"Age\", \"Sex\"],\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    config_dict_to_df(combination_dict, (\"combination\", \"model\"))\n",
    "\n",
    "                            xvar                                    model  \\\n",
    "    combination model                                                          \n",
    "    PANEL       Lasso    [Age, Sex]  <function run_glmnet at 0x7ff7aa182f80>   \n",
    "                xgboost  [Age, Sex]                                      NaN   \n",
    "    AgeSex      xgboost  [Age, Sex]                                      NaN   \n",
    "\n",
    "                            config  \n",
    "    combination model               \n",
    "    PANEL       Lasso    {'cv': 6}  \n",
    "                xgboost        NaN  \n",
    "    AgeSex      xgboost        NaN \n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    config_df = pd.DataFrame(config_dict).T\n",
    "    config_df.index.set_names(index_name, inplace=True)\n",
    "    config_df.columns = pd.MultiIndex.from_tuples(\n",
    "        [(\"param\", col) for col in config_df.columns]\n",
    "    )\n",
    "\n",
    "    return config_df\n",
    "\n",
    "\n",
    "def update_concat_df(df1, df2, duplicate_replace=False, show_warning=True):\n",
    "    \"\"\"\n",
    "    update the df1 with df2, if duplicate_replace is True, then replace the duplicate rows\n",
    "\n",
    "    This will copy df1 and df2 to avoid modify the original df1 and df2\n",
    "\n",
    "    Update the df1 with df2, if duplicate_replace is True, then replace the duplicate rows.\n",
    "    This function copies df1 and df2 to avoid modifying the original dataframes.\n",
    "    Parameters:\n",
    "    - df1 (pandas.DataFrame): The first dataframe to be updated.\n",
    "    - df2 (pandas.DataFrame): The second dataframe used for updating df1.\n",
    "    - duplicate_replace (bool, optional): If True, replace duplicate rows in df1 with df2. Default is False.\n",
    "    - show_warning (bool, optional): If True, show warning messages. Default is True.\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): The updated dataframe.\n",
    "    Example:\n",
    "    df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "    df2 = pd.DataFrame({'A': [7, 8, 9], 'B': [10, 11, 12]})\n",
    "    updated_df = update_concat_df(df1, df2, duplicate_replace=True, show_warning=False)\n",
    "\n",
    "    \"\"\"\n",
    "    # WARNING: this will copy the df1 and df2\n",
    "    df1, df2 = df1.copy(), df2.copy()\n",
    "\n",
    "    new_adds = df2.index.difference(df1.index)\n",
    "    inter = df2.index.intersection(df1.index)\n",
    "\n",
    "    if duplicate_replace:\n",
    "        df1.drop(inter, inplace=True)\n",
    "        warning_duplicated = (\n",
    "            f\"Duplicate_replace is True, will replace the model_config with {inter}\"\n",
    "        )\n",
    "    else:\n",
    "        warning_duplicated = (\n",
    "            f\"Duplicate_replace is False, will skip the model_config with {inter}\"\n",
    "        )\n",
    "\n",
    "    if len(new_adds) > 0:\n",
    "        warning_new_add = (\n",
    "            f\"new model_config {new_adds} not in original model_config, will add them\"\n",
    "        )\n",
    "    else:\n",
    "        warning_new_add = \"No new model_config found\"\n",
    "\n",
    "    if show_warning:\n",
    "        logging.warning(warning_new_add) if len(warning_new_add) > 0 else None\n",
    "        logging.warning(warning_duplicated) if len(warning_duplicated) > 0 else None\n",
    "    df = pd.concat([df1, df2])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_risk_strat_df(data=None, y_true=None, y_pred=None, k=10, n_resample=1000):\n",
    "    \"\"\"\n",
    "    TODO: Add iris as an example\n",
    "    \"\"\"\n",
    "    if data is not None:\n",
    "        y_true = data[y_true]\n",
    "        y_pred = data[y_pred]\n",
    "    elif isinstance(y_true, pd.Series) and isinstance(y_pred, pd.Series):\n",
    "        pass\n",
    "    elif isinstance(y_true, np.ndarray) and isinstance(y_pred, np.ndarray):\n",
    "        y_true = pd.Series(y_true)\n",
    "        y_pred = pd.Series(y_pred)\n",
    "    elif isinstance(y_true, list) and isinstance(y_pred, list):\n",
    "        y_true = pd.Series(y_true)\n",
    "        y_pred = pd.Series(y_pred)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"data should be a DataFrame or y_true and y_pred should be Series or list or numpy array\"\n",
    "        )\n",
    "\n",
    "    plt_df = pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred}).dropna()\n",
    "    try:\n",
    "        plt_df[\"y_pred_bins\"] = pd.qcut(\n",
    "            plt_df[\"y_pred\"],\n",
    "            k,\n",
    "            labels=[f\"{i:.0f}%\" for i in (np.linspace(0, 1, k + 1) * 100)[1:]],\n",
    "        )\n",
    "    except ValueError:\n",
    "        raise ValueError(\"input data have many values are same and cannot be binned\")\n",
    "    if not n_resample:\n",
    "        plt_df_group = (\n",
    "            plt_df.groupby(\"y_pred_bins\")\n",
    "            .apply(lambda x: pd.Series({\"mean_true\": x.y_true.mean()}))\n",
    "            .reset_index(drop=False)\n",
    "        )\n",
    "    else:\n",
    "\n",
    "        # 定义一个函数来计算均值\n",
    "        def mean_bootstrap(data):\n",
    "            # 使用bootstrap计算均值的置信区间\n",
    "            res = bootstrap(data=(data,), statistic=np.mean, n_resamples=n_resample)\n",
    "\n",
    "            return (\n",
    "                np.mean(data),\n",
    "                res.confidence_interval.low,\n",
    "                res.confidence_interval.high,\n",
    "            )\n",
    "\n",
    "        # 对每个分位数进行bootstrap抽样\n",
    "\n",
    "        plt_df_group = (\n",
    "            plt_df.groupby(\"y_pred_bins\")\n",
    "            .apply(\n",
    "                lambda x: pd.Series(\n",
    "                    list(mean_bootstrap(x[\"y_true\"])) + [x[\"y_pred\"].mean()],\n",
    "                    index=[\"mean_true\", \"ci_low\", \"ci_high\", \"mean_pred\"],\n",
    "                ).T\n",
    "            )\n",
    "            .reset_index(drop=False)\n",
    "        )\n",
    "\n",
    "    return plt_df_group\n",
    "\n",
    "\n",
    "def get_calibration_df(\n",
    "    data,\n",
    "    obs,\n",
    "    pred,\n",
    "    followup=None,\n",
    "    group=None,\n",
    "    n_bins=10,\n",
    "):\n",
    "    \"\"\"\n",
    "    TODO: Add iris as an example\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "\n",
    "    if followup is None:\n",
    "        followup = \"followup\"\n",
    "        data[followup] = 1\n",
    "\n",
    "    if group is not None:\n",
    "\n",
    "        data = data.groupby(group).apply(\n",
    "            lambda x: x.assign(decile=pd.qcut(x[pred], n_bins, labels=False))\n",
    "        )\n",
    "        data = (\n",
    "            data.groupby([group, \"decile\"])\n",
    "            .apply(\n",
    "                lambda x: pd.Series(\n",
    "                    {\n",
    "                        \"obsRate\": (x[obs] / x[followup]).mean(),\n",
    "                        \"obsRate_SE\": (x[obs] / x[followup]).std() / np.sqrt(len(x)),\n",
    "                        \"obsNo\": x[obs].sum(),\n",
    "                        \"predMean\": x[pred].mean(),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "    else:\n",
    "        data = data.assign(decile=pd.qcut(data[pred], n_bins, labels=False))\n",
    "        data = (\n",
    "            data.groupby(\"decile\")\n",
    "            .apply(\n",
    "                lambda x: pd.Series(\n",
    "                    {\n",
    "                        \"obsRate\": (x[obs] / x[followup]).mean(),\n",
    "                        \"obsRate_SE\": (x[obs] / x[followup]).std() / np.sqrt(len(x)),\n",
    "                        \"obsNo\": x[obs].sum(),\n",
    "                        \"predMean\": x[pred].mean(),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "    data[\"obsRate_UCI\"] = np.clip(\n",
    "        data[\"obsRate\"] + 1.96 * data[\"obsRate_SE\"], a_max=1, a_min=None\n",
    "    )\n",
    "    data[\"obsRate_LCI\"] = np.clip(\n",
    "        data[\"obsRate\"] - 1.96 * data[\"obsRate_SE\"], a_min=0, a_max=None\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "def calibration_score(\n",
    "    raw_train_pred,\n",
    "    raw_test_pred,\n",
    "    train_y,\n",
    "    method=\"isotonic\",\n",
    "    return_model=False,\n",
    "    need_scale=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    TODO: Add iris as an example\n",
    "    \"\"\"\n",
    "    if method == \"isotonic\":\n",
    "        model = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "\n",
    "        if need_scale:\n",
    "            model = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "        else:\n",
    "            model = Pipeline([(\"model\", model)])\n",
    "\n",
    "        model.fit(raw_train_pred, train_y)\n",
    "\n",
    "        pred_train_calibrated = model.predict(raw_train_pred)\n",
    "        pred_test_calibrated = model.predict(raw_test_pred)\n",
    "    elif method == \"logitstic\":\n",
    "        model = LogisticRegression(\n",
    "            # class_weight=\"balanced\",\n",
    "            max_iter=5000,\n",
    "            random_state=1,\n",
    "        )\n",
    "        if need_scale:\n",
    "            model = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "        else:\n",
    "            model = Pipeline([(\"model\", model)])\n",
    "\n",
    "        raw_train_pred = (\n",
    "            raw_train_pred.values\n",
    "            if isinstance(raw_train_pred, pd.Series)\n",
    "            else raw_train_pred\n",
    "        )\n",
    "        raw_test_pred = (\n",
    "            raw_test_pred.values\n",
    "            if isinstance(raw_test_pred, pd.Series)\n",
    "            else raw_test_pred\n",
    "        )\n",
    "        model.fit(raw_train_pred.reshape(-1, 1), train_y)\n",
    "        pred_train_calibrated = model.predict_proba(raw_train_pred.reshape(-1, 1))[:, 1]\n",
    "        pred_test_calibrated = model.predict_proba(raw_test_pred.reshape(-1, 1))[:, 1]\n",
    "    else:\n",
    "        raise ValueError(\"method should be isotonic or logitstic\")\n",
    "    if return_model:\n",
    "        return pred_train_calibrated, pred_test_calibrated, model\n",
    "    else:\n",
    "        return pred_train_calibrated, pred_test_calibrated\n",
    "\n",
    "\n",
    "def get_predict_v2_from_df(\n",
    "    model,\n",
    "    data,\n",
    "    x_var,\n",
    "):\n",
    "    \"\"\"\n",
    "    merge by idx\n",
    "    TODO: Add iris as an example\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    no_na_data = data[x_var].dropna().copy()\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        no_na_data[\"pred\"] = model.predict_proba(no_na_data)[:, 1]\n",
    "    else:\n",
    "        no_na_data[\"pred\"] = model.predict(no_na_data)\n",
    "\n",
    "    return (\n",
    "        data[[]]\n",
    "        .merge(no_na_data[[\"pred\"]], left_index=True, right_index=True, how=\"left\")\n",
    "        .values.flatten()\n",
    "    )\n",
    "\n",
    "\n",
    "class DiseaseScoreModel_V2:\n",
    "    def __init__(\n",
    "        self,\n",
    "        disease_df,\n",
    "        model_table,\n",
    "        label,\n",
    "        disease_name=None,\n",
    "        train_eid=None,\n",
    "        test_eid=None,\n",
    "        eid=\"eid\",\n",
    "        other_keep_cols=None,\n",
    "        E=None,\n",
    "        T=None,\n",
    "        test_size=0.2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "            TODO: Add iris as an example\n",
    "\n",
    "            meta_index_col is the index to record model summary information by a structure of DataFrame\n",
    "\n",
    "                model_config:{\n",
    "                    \"AgeSex\": {\n",
    "                        \"xvar\":[\"age\", \"sex\"]\n",
    "                        }\n",
    "                    \"KidneyImage\": {\n",
    "                        \"xvar\":KidneyImage\n",
    "                        \"model\":a function accept (train= train, test=test,xvar, y, **kwargs) and return (model, *others)\n",
    "                        \"config\":{\n",
    "                            \"cv\":5\n",
    "                            ...\n",
    "                        } # other config\n",
    "                        }\n",
    "        }\n",
    "                }\n",
    "                \n",
    "        model_table:\n",
    "\n",
    "                          param                                           \\\n",
    "                           xvar                                    model   \n",
    "combination model                                                          \n",
    "PANEL       Lasso    [Age, Sex]  <function run_glmnet at 0x7ff7aa182f80>   \n",
    "            xgboost  [Age, Sex]                                      NaN   \n",
    "AgeSex      xgboost  [Age, Sex]                                      NaN   \n",
    "\n",
    "                                \n",
    "                        config  \n",
    "combination model               \n",
    "PANEL       Lasso    {'cv': 6}  \n",
    "            xgboost        NaN  \n",
    "AgeSex      xgboost        NaN  \n",
    "\n",
    "\n",
    "    \n",
    "                other_keep_cols: other columns to keep in the final dataframe\n",
    "                eid : the column name of the unique identifier\n",
    "\n",
    "        \"\"\"\n",
    "        self.disease_df = disease_df\n",
    "\n",
    "        # step1 split data; can be down by train_eid, test_eid or random split or user run train_test_split\n",
    "        if train_eid is not None:\n",
    "            self.train = disease_df.query(f\"{eid} in @train_eid\")\n",
    "        if test_eid is not None:\n",
    "            self.test = disease_df.query(f\"{eid} in @test_eid\")\n",
    "        if train_eid is None and test_eid is None:\n",
    "            logging.warning(f\"Random split data with test_size: {test_size:.2f}\")\n",
    "            self.train, self.test = train_test_split(disease_df, test_size=test_size)\n",
    "\n",
    "        self.train.reset_index(drop=True, inplace=True)\n",
    "        self.test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        self.label = label\n",
    "        self.disease_name = disease_name or label\n",
    "        self.eid = eid\n",
    "\n",
    "        self.other_keep_cols = other_keep_cols if other_keep_cols else []\n",
    "\n",
    "        logging.info(\n",
    "            f\"Loading data with train cases {self.train[label].sum()} and test cases {self.test[label].sum()} of {self.disease_name}, while {len(self.train.columns)} columns\"\n",
    "        )\n",
    "\n",
    "        # E and T for cox model or C-index\n",
    "        self.E = E\n",
    "        self.T = T\n",
    "        if self.E and (self.E != self.label):\n",
    "            self.other_keep_cols.append(self.E)\n",
    "        if self.T:\n",
    "            self.other_keep_cols.append(self.T)\n",
    "        ## drop na by label, E and T\n",
    "        if self.E and self.T:\n",
    "            self.train.dropna(subset=[self.label, self.E, self.T], inplace=True)\n",
    "            self.test.dropna(subset=[self.label, self.E, self.T], inplace=True)\n",
    "        else:\n",
    "            self.train.dropna(subset=[self.label], inplace=True)\n",
    "            self.test.dropna(subset=[self.label], inplace=True)\n",
    "\n",
    "        logging.info(\n",
    "            f\"Drop NA by {self.label} and {self.E} and {self.T} in train and test and left {len(self.train)} and {len(self.test)} with train cases {self.train[self.label].sum()} and test cases {self.test[self.label].sum()}\"\n",
    "        )\n",
    "\n",
    "        # step2 update information to score_dict\n",
    "        # step2 save all infomation on a dataframe\n",
    "\n",
    "        self.model_table = model_table.copy()\n",
    "\n",
    "        self.train_score, self.test_score = (\n",
    "            self.train[[self.eid, self.label, *self.other_keep_cols]].copy(),\n",
    "            self.test[[self.eid, self.label, *self.other_keep_cols]].copy(),\n",
    "        )\n",
    "\n",
    "        # # keep the fitted model\n",
    "        # self.fitted_model_dict = OrderedDict()\n",
    "\n",
    "        # # keep the metrics\n",
    "        # self.metrics_dict = {}\n",
    "\n",
    "    # def get_metrics_df(self):\n",
    "    #     c_index_df_list = []\n",
    "    #     auc_df_list = []\n",
    "\n",
    "    #     for score_name, metrics in self.metrics_dict.items():\n",
    "    #         c_index = metrics.get(\"c_index\", None)\n",
    "    #         auc_metrics = metrics.get(\"auc_metrics\", None)\n",
    "\n",
    "    #         if c_index is not None:\n",
    "    #             c_index_df_list.append(c_index)\n",
    "    #         if auc_metrics is not None:\n",
    "    #             auc_df_list.append(auc_metrics)\n",
    "    #     c_index_df = pd.concat(c_index_df_list)\n",
    "    #     auc_df = pd.DataFrame(auc_df_list)\n",
    "    #     return c_index_df, auc_df\n",
    "\n",
    "    # def re_cal_metrics(self):\n",
    "    #     \"\"\"\n",
    "    #     re-calculate the metrics only AUC and C-Index\n",
    "    #     \"\"\"\n",
    "    #     for combination_name in self.fitted_model_dict.keys():\n",
    "    #         # cal metrics\n",
    "    #         need_cols = [self.label, combination_name]\n",
    "\n",
    "    #         ## E may equal to T\n",
    "    #         if self.E and self.T:\n",
    "    #             if self.E != self.label:\n",
    "    #                 need_cols.append(self.E)\n",
    "    #             need_cols.append(self.T)\n",
    "\n",
    "    #         to_cal_df = self.test_score[need_cols].copy().dropna()\n",
    "\n",
    "    #         c_index = run_cox(\n",
    "    #             to_cal_df, var=combination_name, E=self.E, T=self.T, ci=True\n",
    "    #         )\n",
    "    #         auc_metrics = cal_binary_metrics(\n",
    "    #             to_cal_df[self.label], to_cal_df[combination_name], ci=True\n",
    "    #         )\n",
    "\n",
    "    #         self.metrics_dict[combination_name] = {\n",
    "    #             \"c_index\": c_index,\n",
    "    #             \"auc_metrics\": auc_metrics,\n",
    "    #         }\n",
    "\n",
    "    def update_model(self, new_model_table=None, duplicate_replace=False):\n",
    "        \"\"\"\n",
    "        fit the model with the new model_config, or\n",
    "        \"\"\"\n",
    "        # update the model_config\n",
    "        if new_model_table is not None:\n",
    "            self.model_table = update_concat_df(\n",
    "                self.model_table,\n",
    "                new_model_table,\n",
    "                duplicate_replace=duplicate_replace,\n",
    "            )\n",
    "\n",
    "        # fit model by model_table\n",
    "        # fitted model will add a status to show whether the model is fitted\n",
    "\n",
    "        for name, model_table_row in self.model_table.iterrows():\n",
    "            # unpack the params\n",
    "            params = model_table_row[\"param\"].to_dict()\n",
    "\n",
    "            # get xvar\n",
    "            xvar = params[\"xvar\"]\n",
    "\n",
    "            # get model\n",
    "            if \"model\" in params:\n",
    "                model_fn = params[\"model\"]\n",
    "            else:\n",
    "                logging.warning(\n",
    "                    f\"model function not found in {name}, use default glmnet to run lasso\"\n",
    "                )\n",
    "                model_fn = run_glmnet\n",
    "\n",
    "            # get model config\n",
    "            model_fn_config = params.get(\"config\", {})\n",
    "            if pd.isna(model_fn_config):\n",
    "                model_fn_config = {}\n",
    "\n",
    "            # get score name alias or\n",
    "            score_name = params.get(\n",
    "                \"score_name\", name if isinstance(name, str) else \"_\".join(name)\n",
    "            )\n",
    "\n",
    "            # fit the model\n",
    "            self.fit(\n",
    "                xvar=xvar,\n",
    "                name=name,\n",
    "                score_name=score_name,\n",
    "                model_fn=model_fn,\n",
    "                **model_fn_config,\n",
    "            )\n",
    "\n",
    "    def fit(self, xvar, name, score_name, model_fn=run_glmnet, **model_fn_config):\n",
    "        \"\"\"\n",
    "        fit the model with the combination\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # step1 check whether the model is already fitted by name have (\"status\", \"fitted\") value\n",
    "        try:\n",
    "            status_fitted = self.model_table.loc[name, (\"status\", \"fitted\")]\n",
    "        except KeyError:\n",
    "            status_fitted = False\n",
    "\n",
    "        if status_fitted == 1:\n",
    "            logging.warning(f\"{name} already fitted, will skip it\")\n",
    "            return\n",
    "\n",
    "        # step2 fit the model\n",
    "\n",
    "        model, *_ = model_fn(\n",
    "            train=self.train,\n",
    "            test=self.test,\n",
    "            xvar=xvar,\n",
    "            label=self.label,\n",
    "            **model_fn_config,\n",
    "        )\n",
    "\n",
    "        # TODO: use model.predict(model=model, data=self.train, xvar = combination) to replace the following\n",
    "        self.train_score[score_name] = get_predict_v2_from_df(model, self.train, xvar)\n",
    "        self.test_score[score_name] = get_predict_v2_from_df(model, self.test, xvar)\n",
    "        ## add the score into train_score\n",
    "        self.train[score_name] = get_predict_v2_from_df(model, self.train, xvar)\n",
    "        self.test[score_name] = get_predict_v2_from_df(model, self.test, xvar)\n",
    "\n",
    "        # cal metrics\n",
    "        need_cols = [self.label, score_name]\n",
    "\n",
    "        ## E may equal to T\n",
    "        if self.E and self.T:\n",
    "            if self.E != self.label:\n",
    "                need_cols.append(self.E)\n",
    "            need_cols.append(self.T)\n",
    "\n",
    "        to_cal_df = self.test_score[need_cols].copy().dropna()\n",
    "\n",
    "        # zscore for correct OR and HR\n",
    "        to_cal_df_train = self.train_score[need_cols].copy().dropna()\n",
    "        train_mean = to_cal_df_train[score_name].mean()\n",
    "        train_std = to_cal_df_train[score_name].std()\n",
    "\n",
    "        to_cal_df[score_name] = (to_cal_df[score_name] - train_mean) / train_std\n",
    "\n",
    "        # cal c\n",
    "        if self.E and self.T:\n",
    "            c_index_df = run_cox(to_cal_df, var=score_name, E=self.E, T=self.T, ci=True)\n",
    "            c_index_dict = c_index_df.iloc[0].T.to_dict()\n",
    "            for metric_name, metric_value in c_index_dict.items():\n",
    "                self.model_table.loc[name, (\"c_index\", metric_name)] = metric_value\n",
    "\n",
    "        # cal auc\n",
    "        auc_metrics_dict = cal_binary_metrics(\n",
    "            to_cal_df[self.label], to_cal_df[score_name], ci=True\n",
    "        )\n",
    "        for metric_name, metric_value in auc_metrics_dict.items():\n",
    "            self.model_table.loc[name, (\"auc\", metric_name)] = metric_value\n",
    "\n",
    "        # update model into model_table\n",
    "        self.model_table.loc[name, (\"status\", \"fitted\")] = 1\n",
    "\n",
    "        self.model_table.loc[name, (\"model\", \"model\")] = model\n",
    "        self.model_table.loc[name, (\"basic\", \"score_name\")] = score_name\n",
    "\n",
    "    def calibrate(self, method=\"logitstic\"):\n",
    "        \"\"\"\n",
    "        calibrate the score\n",
    "\n",
    "        \"\"\"\n",
    "        # check fitted status\n",
    "        self._check_status()\n",
    "\n",
    "        self.train_score_calibrated, self.test_score_calibrated = (\n",
    "            self.train[[self.eid, self.label, *self.other_keep_cols]].copy(),\n",
    "            self.test[[self.eid, self.label, *self.other_keep_cols]].copy(),\n",
    "        )\n",
    "\n",
    "        # for score_name, score_model_config in self.model_config.items():\n",
    "        for name, score_name in self.model_table[(\"basic\", \"score_name\")].items():\n",
    "\n",
    "            from ppp_prediction.calibration import calibrate\n",
    "\n",
    "            raw_train_score = self.train_score[[self.label, score_name]].dropna()\n",
    "            raw_test_score = self.test_score[[self.label, score_name]].dropna()\n",
    "\n",
    "            calibrated_object = calibrate(\n",
    "                X_train=raw_train_score[score_name],\n",
    "                X_test=raw_test_score[score_name],\n",
    "                y_train=raw_train_score[self.label],\n",
    "                y_test=raw_test_score[self.label],\n",
    "                n_bins=10,\n",
    "                need_scale=True,\n",
    "            )\n",
    "\n",
    "            calibration_model = calibrated_object[\"best_clf\"]\n",
    "\n",
    "            # TODO: use model.predict(model=model, data=self.train, xvar = combination) to replace the following\n",
    "            self.train_score_calibrated[score_name] = get_predict_v2_from_df(\n",
    "                calibration_model, self.train_score, [score_name]\n",
    "            )\n",
    "            self.test_score_calibrated[score_name] = get_predict_v2_from_df(\n",
    "                calibration_model, self.test_score, [score_name]\n",
    "            )\n",
    "\n",
    "            self.model_table.loc[name, (\"model\", \"calibrated_model\")] = (\n",
    "                calibration_model\n",
    "            )\n",
    "\n",
    "    def get_score_names(self):\n",
    "        # return list(self.fitted_model_dict.keys())\n",
    "        return self.model_table[(\"basic\", \"score_name\")].values.tolist()\n",
    "\n",
    "    def get_score_names_df(self):\n",
    "\n",
    "        # TODO: if level is more than 2, may have problem\n",
    "        return (\n",
    "            self.model_table[[(\"basic\", \"score_name\")]]\n",
    "            .copy()\n",
    "            .droplevel(0, axis=1)\n",
    "            .reset_index()\n",
    "        )  #\n",
    "\n",
    "    def set_color_set(self, colorset=None):\n",
    "        # self.color\n",
    "        if colorset is None:\n",
    "            colorset = list(sns.color_palette(\"tab20\").as_hex())\n",
    "\n",
    "        self.method_colorset = {k: v for k, v in zip(self.get_score_names(), colorset)}\n",
    "\n",
    "    @property\n",
    "    def color_set(self):\n",
    "        if not hasattr(self, \"method_colorset\"):\n",
    "            self.set_color_set()\n",
    "        return self.method_colorset\n",
    "\n",
    "    def get_metrics_by_user_multi(\n",
    "        self, metrics_dict=None, use_calibrate=False, **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        metrics_dict: a dict with key as the metrics_name and value as the metrics_fn\n",
    "        \"\"\"\n",
    "        metrics_list = []\n",
    "        for metrics_name, metrics_fn in metrics_dict.items():\n",
    "            metrics_df = self.get_metrics_by_user(\n",
    "                metrics_fn,\n",
    "                metrics_name=metrics_name,\n",
    "                use_calibrate=use_calibrate,\n",
    "                **kwargs,\n",
    "            )\n",
    "            metrics_list.append(metrics_df)\n",
    "\n",
    "        return reduce(lambda x, y: pd.merge(x, y), metrics_list)\n",
    "\n",
    "    def get_metrics_by_user(\n",
    "        self, metrics_fn, metrics_name=None, use_calibrate=False, **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        metrics_fn: a function accept (y_true, y_prob, other_kwargs) and return a dict; note the first pos will be the label and the second pos will be the score\n",
    "        \"\"\"\n",
    "        metrics_name = metrics_name or metrics_fn.__name__\n",
    "\n",
    "        metrics_list = []\n",
    "        for row_idx, row in self.get_score_names_df().iterrows():\n",
    "            row_dict = row.to_dict()\n",
    "            score_name = row_dict[\"score_name\"]\n",
    "\n",
    "            if use_calibrate:\n",
    "\n",
    "                to_cal_df = self.test_score_calibrated[\n",
    "                    [self.label, score_name]\n",
    "                ].dropna()\n",
    "\n",
    "            else:\n",
    "                to_cal_df = self.test_score[[self.label, score_name]].dropna()\n",
    "\n",
    "            metrics_score = metrics_fn(\n",
    "                to_cal_df[self.label],\n",
    "                to_cal_df[score_name],\n",
    "                **kwargs,\n",
    "            )\n",
    "            if isinstance(metrics_score, dict):\n",
    "                metrics_list.append(\n",
    "                    {\n",
    "                        **row_dict,\n",
    "                        **metrics_score,\n",
    "                    }\n",
    "                )\n",
    "                logging.info(\n",
    "                    f\"metrics {metrics_name} return a dict, will unpack it to the dataframe\"\n",
    "                )\n",
    "            else:\n",
    "                metrics_list.append(\n",
    "                    {\n",
    "                        **row_dict,\n",
    "                        metrics_name: metrics_score,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        return pd.DataFrame(metrics_list)\n",
    "\n",
    "    def _check_status(\n",
    "        self,\n",
    "    ):\n",
    "        if \"status\" in self.model_table.columns.get_level_values(0):\n",
    "\n",
    "            if self.model_table[(\"status\", \"fitted\")].isna().any():\n",
    "                error_flag = True\n",
    "            else:\n",
    "                error_flag = False\n",
    "\n",
    "        else:\n",
    "            error_flag = False\n",
    "\n",
    "        if error_flag:\n",
    "            raise ValueError(f\"model not fitted, run update_model first\")\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    @property\n",
    "    def brier_score(self):\n",
    "        if not hasattr(self, \"train_score_calibrated\"):\n",
    "            logging.warning(\"No calibrated model fitted, run calibrate first\")\n",
    "            return\n",
    "        return self.get_metrics_by_user(\n",
    "            brier_score_loss, use_calibrate=True, metrics_name=\"brier_score\"\n",
    "        )\n",
    "\n",
    "    # TODO：画图呈现逻辑，现在默认不用分面，全部都以score_name做\n",
    "\n",
    "    def calibration_plot(self, n_bins=10, return_df=False, by=\"test\", facet_fn=None):\n",
    "\n",
    "        # check fitted status\n",
    "        self._check_status()\n",
    "\n",
    "        if not hasattr(self, \"train_score_calibrated\"):\n",
    "            logging.warning(\"No calibrated model fitted, run calibrate first\")\n",
    "            return\n",
    "        if by == \"test\":\n",
    "            by_data = self.test_score_calibrated\n",
    "        elif by == \"train\":\n",
    "            by_data = self.train_score_calibrated\n",
    "        elif by == \"all\":\n",
    "            by_data = pd.concat(\n",
    "                [self.test_score_calibrated, self.train_score_calibrated]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"by should be test, train or all\")\n",
    "        # get calibration plot raw df\n",
    "        calibration_df_list = []\n",
    "\n",
    "        for row_idx, row in self.get_score_names_df().iterrows():\n",
    "            row_dict = row.to_dict()\n",
    "            score_name = row_dict[\"score_name\"]\n",
    "\n",
    "            score_calibrated = by_data[[self.label, score_name]].dropna().copy()\n",
    "\n",
    "            c_calibration_df = get_calibration_df(\n",
    "                data=score_calibrated,  # use train to test\n",
    "                obs=self.label,\n",
    "                pred=score_name,\n",
    "                n_bins=n_bins,\n",
    "            )\n",
    "\n",
    "            # assign others\n",
    "            for k, v in row_dict.items():\n",
    "                c_calibration_df[k] = v\n",
    "\n",
    "            c_calibration_df = c_calibration_df.set_index(\n",
    "                list(row_dict.keys())\n",
    "            ).reset_index()\n",
    "\n",
    "            calibration_df_list.append(c_calibration_df)\n",
    "\n",
    "        calibration_df = pd.concat(calibration_df_list)\n",
    "\n",
    "        lim_bound = max(\n",
    "            calibration_df[\"obsRate\"].max(), calibration_df[\"predMean\"].max()\n",
    "        )\n",
    "\n",
    "        # TODO: 统一绘图风格 theme\n",
    "        p = ggplot(\n",
    "            data=calibration_df,\n",
    "            mapping=aes(x=\"predMean\", y=\"obsRate\", color=\"score_name\"),\n",
    "        )\n",
    "        if facet_fn:\n",
    "            p = p + facet_fn\n",
    "\n",
    "        p = (\n",
    "            p\n",
    "            + geom_point(alpha=0.8, size=3)\n",
    "            + geom_line(alpha=0.8)\n",
    "            # + geom_line()\n",
    "            + geom_abline(intercept=0, slope=1, linetype=\"dashed\")\n",
    "            + theme_classic(base_family=\"Calibri\", base_size=12)  # 使用Tufte主题\n",
    "            + theme(axis_line=element_line())\n",
    "            + theme(\n",
    "                figure_size=(12, 12),\n",
    "                legend_position=\"top\",\n",
    "                axis_text_x=element_text(angle=90),\n",
    "                strip_background=element_blank(),\n",
    "                axis_text=element_text(size=12),  # 调整轴文字大小\n",
    "                axis_title=element_text(size=14),  # 调整轴标题大小和样式\n",
    "                legend_title=element_text(size=14),  # 调整图例标题大小和样式\n",
    "                legend_text=element_text(),  # 调整图例文字大小\n",
    "                strip_text=element_text(size=14),  # 调整分面标签的大小和样式\n",
    "                plot_title=element_text(size=16, hjust=0.5),  # 添加图表标题并居中\n",
    "                # plot_margin = margin(10, 10, 10, 10)  # 设置图表边距\n",
    "            )\n",
    "            + scale_color_manual(values=self.color_set)\n",
    "            + labs(\n",
    "                x=\"Predicted risk\",\n",
    "                y=\"Observed risk\",\n",
    "                title=\"Calibration plot\",\n",
    "                color=\"Score\",\n",
    "            )\n",
    "            + coord_cartesian(xlim=(0, lim_bound), ylim=(0, lim_bound))\n",
    "        )\n",
    "        if return_df:\n",
    "            return p, calibration_df\n",
    "        else:\n",
    "            return p\n",
    "\n",
    "    # TODO:接口统一\n",
    "    def plot_dca(self, return_df=False, by=\"test\"):\n",
    "\n",
    "        self._check_status()\n",
    "\n",
    "        if not hasattr(self, \"train_score_calibrated\"):\n",
    "            logging.warning(\"No calibrated model fitted, run calibrate first\")\n",
    "            return\n",
    "\n",
    "        if by == \"test\":\n",
    "            by_data = self.test_score_calibrated\n",
    "        elif by == \"train\":\n",
    "            by_data = self.train_score_calibrated\n",
    "        elif by == \"all\":\n",
    "            by_data = pd.concat(\n",
    "                [self.test_score_calibrated, self.train_score_calibrated]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"by should be test, train or all\")\n",
    "        # TODO: update to new code of get_dca_df\n",
    "        test = by_data[[self.label, *self.get_score_names()]].dropna().copy()\n",
    "        event_rate = test[self.label].sum() / len(test)\n",
    "        dca_df = dca(\n",
    "            data=test,\n",
    "            outcome=self.label,\n",
    "            modelnames=self.get_score_names(),\n",
    "            thresholds=np.linspace(0, event_rate, 1000),\n",
    "        )\n",
    "        dca_df[\"st_net_benefit\"] = dca_df[\"net_benefit\"] / event_rate\n",
    "        dca_df[\"disease\"] = self.disease_name\n",
    "\n",
    "        # TODO: 统一绘图风格 theme; by another function\n",
    "        # from dca_df\n",
    "        p = (\n",
    "            ggplot(\n",
    "                data=dca_df,\n",
    "                mapping=aes(x=\"threshold\", y=\"st_net_benefit\", color=\"score_name\"),\n",
    "            )\n",
    "            # + facet_wrap(\"disease\", scales=\"free\")\n",
    "            + geom_line()\n",
    "            + ylim(0, 1)\n",
    "            + theme_classic(base_family=\"Calibri\", base_size=12)  # 使用Tufte主题\n",
    "            + theme(axis_line=element_line())\n",
    "            + theme(\n",
    "                figure_size=(12, 12),\n",
    "                legend_position=\"top\",\n",
    "                axis_text_x=element_text(angle=90),\n",
    "                strip_background=element_blank(),\n",
    "                axis_text=element_text(size=12),  # 调整轴文字大小\n",
    "                axis_title=element_text(size=14),  # 调整轴标题大小和样式\n",
    "                legend_title=element_text(size=14),  # 调整图例标题大小和样式\n",
    "                legend_text=element_text(),  # 调整图例文字大小\n",
    "                strip_text=element_text(size=14),  # 调整分面标签的大小和样式\n",
    "                plot_title=element_text(size=16, hjust=0.5),  # 添加图表标题并居中\n",
    "                # plot_margin = margin(10, 10, 10, 10)  # 设置图表边距\n",
    "            )\n",
    "            # + scale_color_manual(values=c_color_dict)\n",
    "        )\n",
    "\n",
    "        if return_df:\n",
    "            return p, dca_df\n",
    "        else:\n",
    "            return p\n",
    "\n",
    "    def plot_auc(\n",
    "        self,\n",
    "        return_df=False,\n",
    "        by=\"test\",\n",
    "    ):\n",
    "        self._check_status()\n",
    "\n",
    "        if by == \"test\":\n",
    "            by_data = self.test_score\n",
    "        elif by == \"train\":\n",
    "            by_data = self.train_score\n",
    "        elif by == \"all\":\n",
    "            by_data = pd.concat([self.test_score, self.train_score])\n",
    "        else:\n",
    "            raise ValueError(\"by should be test, train or all\")\n",
    "\n",
    "        # get auc famhistory_df_list\n",
    "        auc_df_list = []\n",
    "\n",
    "        for row_idx, row in self.get_score_names_df().iterrows():\n",
    "            row_dict = row.to_dict()\n",
    "            score_name = row_dict[\"score_name\"]\n",
    "\n",
    "            to_cal_df = by_data[[self.label, score_name]].dropna()\n",
    "            fpr, tpr, _ = roc_curve(to_cal_df[self.label], to_cal_df[score_name])\n",
    "            roc_current_df = pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"fpr\": fpr_,\n",
    "                        \"tpr\": tpr_,\n",
    "                    }\n",
    "                    for fpr_, tpr_ in zip(fpr, tpr)\n",
    "                ]\n",
    "            )\n",
    "            for k, v in row_dict.items():\n",
    "                roc_current_df[k] = v\n",
    "            roc_current_df = roc_current_df.set_index(\n",
    "                list(row_dict.keys())\n",
    "            ).reset_index()\n",
    "\n",
    "            auc_df_list.append(roc_current_df)\n",
    "        auc_df = pd.concat(auc_df_list)\n",
    "\n",
    "        # TODO: 统一绘图风格 theme\n",
    "        # from auc_df\n",
    "\n",
    "        p = (\n",
    "            ggplot(\n",
    "                data=auc_df,\n",
    "                mapping=aes(x=\"fpr\", y=\"tpr\", color=\"score_name\"),\n",
    "            )\n",
    "            + geom_line()\n",
    "            + geom_abline(intercept=0, slope=1, linetype=\"dashed\")\n",
    "            + theme_classic(base_family=\"Calibri\", base_size=12)  # 使用Tufte主题\n",
    "            + theme(axis_line=element_line())\n",
    "            + theme(\n",
    "                figure_size=(12, 12),\n",
    "                legend_position=\"top\",\n",
    "                axis_text_x=element_text(angle=90),\n",
    "                strip_background=element_blank(),\n",
    "                axis_text=element_text(size=12),  # 调整轴文字大小\n",
    "                axis_title=element_text(size=14),  # 调整轴标题大小和样式\n",
    "                legend_title=element_text(size=14),  # 调整图例标题大小和样式\n",
    "                legend_text=element_text(),  # 调整图例文字大小\n",
    "                strip_text=element_text(size=14),  # 调整分面标签的大小和样式\n",
    "                plot_title=element_text(size=16, hjust=0.5),  # 添加图表标题并居中\n",
    "                # plot_margin = margin(10, 10, 10, 10)  # 设置图表边距\n",
    "            )\n",
    "            + scale_color_manual(values=self.color_set)\n",
    "            + labs(\n",
    "                x=\"1 - Specificity\",\n",
    "                y=\"Sensitivity\",\n",
    "                title=\"ROC curve\",\n",
    "                color=\"score_name\",\n",
    "            )\n",
    "        )\n",
    "        if return_df:\n",
    "            return p, auc_df\n",
    "        else:\n",
    "            return p\n",
    "\n",
    "    def plot_risk_strat(\n",
    "        self,\n",
    "        return_df=False,\n",
    "        by=\"test\",\n",
    "        facet=False,\n",
    "        k=10,\n",
    "        show_ci=True,\n",
    "        n_resample=100,\n",
    "    ):\n",
    "        self._check_status()\n",
    "\n",
    "        if by == \"test\":\n",
    "            by_data = self.test_score\n",
    "        elif by == \"train\":\n",
    "            by_data = self.train_score\n",
    "        elif by == \"all\":\n",
    "            by_data = pd.concat([self.test_score, self.train_score])\n",
    "        else:\n",
    "            raise ValueError(\"by should be test, train or all\")\n",
    "\n",
    "        # get risk_strat_df\n",
    "        risk_strat_df_list = []\n",
    "        # for score_name in self.get_score_names():\n",
    "        for row_idx, row in self.get_score_names_df().iterrows():\n",
    "            row_dict = row.to_dict()\n",
    "            score_name = row_dict[\"score_name\"]\n",
    "\n",
    "            risk_strat_df = get_risk_strat_df(\n",
    "                data=by_data.copy(),\n",
    "                y_true=self.label,\n",
    "                y_pred=score_name,\n",
    "                k=k,\n",
    "                n_resample=n_resample,\n",
    "            )\n",
    "\n",
    "            for k, v in row_dict.items():\n",
    "                risk_strat_df[k] = v\n",
    "            risk_strat_df = risk_strat_df.set_index(list(row_dict.keys())).reset_index()\n",
    "\n",
    "            # risk_strat_df[\"model\"] = score_name\n",
    "            # risk_strat_df[\"disease\"] = self.disease_name\n",
    "            risk_strat_df_list.append(risk_strat_df)\n",
    "        risk_strat_df = pd.concat(risk_strat_df_list)\n",
    "\n",
    "        # TODO: 统一绘图风格 theme\n",
    "        # from risk_strat_df\n",
    "\n",
    "        dodge_width = 0.6\n",
    "        p = ggplot(\n",
    "            data=risk_strat_df,\n",
    "            mapping=aes(x=\"y_pred_bins\", y=\"mean_true\", color=\"score_name\"),\n",
    "        )\n",
    "        if facet:\n",
    "            p = p + facet_wrap(\"model\", scales=\"free_y\")\n",
    "\n",
    "        p = p + geom_point(\n",
    "            alpha=0.8,\n",
    "            size=2,\n",
    "            position=position_dodge(width=dodge_width),\n",
    "            na_rm=True,\n",
    "        )\n",
    "\n",
    "        if show_ci:\n",
    "            p = p + geom_linerange(\n",
    "                mapping=aes(ymin=\"ci_low\", ymax=\"ci_high\"),\n",
    "                size=1,\n",
    "                alpha=0.8,\n",
    "                position=position_dodge(width=dodge_width),\n",
    "                na_rm=True,\n",
    "            )\n",
    "\n",
    "        p = (\n",
    "            p\n",
    "            + theme_classic(base_family=\"Calibri\", base_size=12)  # 使用Tufte主题\n",
    "            + theme(axis_line=element_line())\n",
    "            + theme(\n",
    "                figure_size=(10, 5),\n",
    "                legend_position=\"top\",\n",
    "                axis_text_x=element_text(angle=90),\n",
    "                strip_background=element_blank(),\n",
    "                axis_text=element_text(size=12),  # 调整轴文字大小\n",
    "                axis_title=element_text(size=14),  # 调整轴标题大小和样式\n",
    "                legend_title=element_text(size=14),  # 调整图例标题大小和样式\n",
    "                legend_text=element_text(),  # 调整图例文字大小\n",
    "                strip_text=element_text(size=14),  # 调整分面标签的大小和样式\n",
    "                plot_title=element_text(size=16, hjust=0.5),  # 添加图表标题并居中\n",
    "                # plot_margin = margin(10, 10, 10, 10)  # 设置图表边距\n",
    "            )\n",
    "            + guides(color=guide_legend(nrow=1, title=\"\"))\n",
    "            + scale_color_manual(values=self.color_set)\n",
    "            + labs(\n",
    "                x=\"Risk Decile\",  # 设置X轴标签\n",
    "                y=\"Observed Events Rate\",  # 设置Y轴标签\n",
    "                # color=\"group\",  # 设置图例标题\n",
    "                # title=\"\",  # 添加图表标题\n",
    "            )\n",
    "            # + coord_flip()\n",
    "        )\n",
    "\n",
    "        if return_df:\n",
    "            return p, risk_strat_df\n",
    "        else:\n",
    "            return p\n",
    "\n",
    "    def compare_model(self, compare_list, by=\"test\", ci=True, n_resample=100):\n",
    "        \"\"\"\n",
    "        [\n",
    "        (ref1, new1)\n",
    "        (ref2, new2)\n",
    "        ]\n",
    "        \"\"\"\n",
    "        if by == \"test\":\n",
    "            by_data = self.test_score\n",
    "        elif by == \"train\":\n",
    "            by_data = self.train_score\n",
    "        elif by == \"all\":\n",
    "            by_data = pd.concat([self.test_score, self.train_score])\n",
    "        else:\n",
    "            raise ValueError(\"by should be test, train or all\")\n",
    "\n",
    "        compare_result_list = []\n",
    "        for ref, new in compare_list:\n",
    "            to_cal_df = by_data[[self.label, ref, new]].dropna().copy()\n",
    "\n",
    "            total = {}\n",
    "\n",
    "            total[\"ref\"] = ref\n",
    "            total[\"new\"] = new\n",
    "            total[\"disease\"] = self.disease_name\n",
    "\n",
    "            # NRI\n",
    "            NRI_res = NRI(\n",
    "                to_cal_df[self.label],\n",
    "                to_cal_df[ref],\n",
    "                to_cal_df[new],\n",
    "                ci=ci,\n",
    "                n_resamples=n_resample,\n",
    "            )\n",
    "            total.update(NRI_res)\n",
    "\n",
    "            # IDI\n",
    "            IDI_res = IDI(\n",
    "                to_cal_df[self.label],\n",
    "                to_cal_df[ref],\n",
    "                to_cal_df[new],\n",
    "                ci=ci,\n",
    "                n_resamples=n_resample,\n",
    "            )\n",
    "            total.update(IDI_res)\n",
    "\n",
    "            # AUC diff\n",
    "            auc_diff_res = roc_test(\n",
    "                to_cal_df[self.label], to_cal_df[ref], to_cal_df[new]\n",
    "            )\n",
    "            total.update(auc_diff_res)\n",
    "\n",
    "            # C diff\n",
    "            if self.E and self.T:\n",
    "                c_diff_res = compareC(\n",
    "                    to_cal_df[self.T],\n",
    "                    to_cal_df[self.label],\n",
    "                    to_cal_df[ref],\n",
    "                    to_cal_df[new],\n",
    "                )\n",
    "                total.update(c_diff_res)\n",
    "\n",
    "            compare_result_list.append(total)\n",
    "        return pd.DataFrame(compare_result_list)\n",
    "\n",
    "    def plot_performance(\n",
    "        self,\n",
    "        metric=\"auc\",\n",
    "        # or\n",
    "        metrics_fn=None,\n",
    "        metrics_name=None,\n",
    "        # return\n",
    "        return_df=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        if metric is a function, then use it to calculate the metrics; works like `get_metrics_by_user`\n",
    "        \"\"\"\n",
    "        # get metrics_df\n",
    "\n",
    "        if metric == \"c_index\":\n",
    "            plt_data = (\n",
    "                self.model_table[[\"basic\", metric]]\n",
    "                .copy()\n",
    "                .droplevel(0, axis=1)\n",
    "                .reset_index()\n",
    "            )\n",
    "            y = \"c_index\"\n",
    "            y_LCI = \"c_index_LCI\"\n",
    "            y_UCI = \"c_index_UCI\"\n",
    "            y_name = \"C-index\"\n",
    "\n",
    "        elif metric == \"auc\":\n",
    "            plt_data = (\n",
    "                self.model_table[[\"basic\", metric]]\n",
    "                .copy()\n",
    "                .droplevel(0, axis=1)\n",
    "                .reset_index()\n",
    "            )\n",
    "            y = \"AUC\"\n",
    "            y_LCI = \"AUC_LCI\"\n",
    "            y_UCI = \"AUC_UCI\"\n",
    "            y_name = \"AUC\"\n",
    "\n",
    "        elif metric == \"brier_score\":\n",
    "            plt_data = (\n",
    "                self.model_table[[\"basic\", metric]]\n",
    "                .copy()\n",
    "                .droplevel(0, axis=1)\n",
    "                .reset_index()\n",
    "            )\n",
    "            y = \"brier_score\"\n",
    "            y_LCI = None\n",
    "            y_UCI = None\n",
    "\n",
    "            y_name = \"Brier Score\"\n",
    "        elif metric is None and metrics_fn is not None:\n",
    "            if metrics_name is None:\n",
    "                if isinstance(metrics_fn, partial):\n",
    "                    raise ValueError(\n",
    "                        \"metrics_name should be provided when metrics_fn is a functools.partial\"\n",
    "                    )\n",
    "                metrics_name = metrics_fn.__name__\n",
    "\n",
    "            use_calibrate = kwargs.pop(\"use_calibrate\", False)\n",
    "            plt_data = self.get_metrics_by_user(\n",
    "                metrics_fn, metrics_name=metrics_name, use_calibrate=use_calibrate\n",
    "            )\n",
    "            y = metrics_name\n",
    "            if y not in plt_data.columns:\n",
    "                raise ValueError(\n",
    "                    f\"metrics_name {metrics_name} not found in the metrics_df, there are {plt_data.columns}\"\n",
    "                )\n",
    "            if f\"{y}_LCI\" in plt_data.columns:\n",
    "                y_LCI = f\"{y}_LCI\"\n",
    "                y_UCI = f\"{y}_UCI\"\n",
    "            else:\n",
    "                y_LCI = y_UCI = None\n",
    "            y_name = metrics_name\n",
    "        else:\n",
    "            raise ValueError(\"metric should be c_index or auc\")\n",
    "        p = (\n",
    "            ggplot(\n",
    "                data=plt_data,\n",
    "                mapping=aes(x=\"score_name\", y=y, color=\"score_name\"),\n",
    "            )\n",
    "            # + facet_wrap(\"disease\", scales=\"free_y\")\n",
    "            + geom_point(alpha=0.8, size=3, position=position_dodge(width=0.5))\n",
    "        )\n",
    "        if y_LCI is not None:\n",
    "            p = p + geom_linerange(\n",
    "                mapping=aes(ymin=y_LCI, ymax=y_UCI),\n",
    "                size=1,\n",
    "                alpha=0.8,\n",
    "                position=position_dodge(width=0.5),\n",
    "            )\n",
    "        p = (\n",
    "            p\n",
    "            + theme_classic(base_family=\"Calibri\", base_size=12)  # 使用Tufte主题\n",
    "            + theme(axis_line=element_line())\n",
    "            + theme(\n",
    "                figure_size=(12, 6),\n",
    "                legend_position=\"none\",\n",
    "                axis_text_x=element_text(angle=90),\n",
    "                strip_background=element_blank(),\n",
    "                axis_text=element_text(size=12),  # 调整轴文字大小\n",
    "                axis_title=element_text(size=14),  # 调整轴标题大小和样式\n",
    "                legend_title=element_text(size=14),  # 调整图例标题大小和样式\n",
    "                legend_text=element_text(),  # 调整图例文字大小\n",
    "                strip_text=element_text(size=14),  # 调整分面标签的大小和样式\n",
    "                plot_title=element_text(size=16, hjust=0.5),  # 添加图表标题并居中\n",
    "                # plot_margin = margin(10, 10, 10, 10)  # 设置图表边距\n",
    "            )\n",
    "            # + guides(color=False)\n",
    "            # + scale_color_manual(values=colorset)\n",
    "            + scale_color_manual(values=self.color_set)\n",
    "            + labs(\n",
    "                x=\"Method\",  # 设置X轴标签\n",
    "                # y=\"C-index\",  # 设置Y轴标签\n",
    "                y=y_name,\n",
    "                # color=\"Method\",  # 设置图例标题\n",
    "                title=\"Comparison of Methods\",  # 添加图表标题\n",
    "            )\n",
    "            # + coord_flip()\n",
    "        )\n",
    "        if return_df:\n",
    "            return p, plt_data\n",
    "        else:\n",
    "            return p\n",
    "\n",
    "\n",
    "# save_fig("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>564</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>565</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>566</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>567</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>568</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eid  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "0      0        17.99         10.38          122.80     1001.0   \n",
       "1      1        20.57         17.77          132.90     1326.0   \n",
       "2      2        19.69         21.25          130.00     1203.0   \n",
       "3      3        11.42         20.38           77.58      386.1   \n",
       "4      4        20.29         14.34          135.10     1297.0   \n",
       "..   ...          ...           ...             ...        ...   \n",
       "564  564        21.56         22.39          142.00     1479.0   \n",
       "565  565        20.13         28.25          131.20     1261.0   \n",
       "566  566        16.60         28.08          108.30      858.1   \n",
       "567  567        20.60         29.33          140.10     1265.0   \n",
       "568  568         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     mean symmetry  ...  worst texture  worst perimeter  worst area  \\\n",
       "0           0.2419  ...          17.33           184.60      2019.0   \n",
       "1           0.1812  ...          23.41           158.80      1956.0   \n",
       "2           0.2069  ...          25.53           152.50      1709.0   \n",
       "3           0.2597  ...          26.50            98.87       567.7   \n",
       "4           0.1809  ...          16.67           152.20      1575.0   \n",
       "..             ...  ...            ...              ...         ...   \n",
       "564         0.1726  ...          26.40           166.10      2027.0   \n",
       "565         0.1752  ...          38.25           155.00      1731.0   \n",
       "566         0.1590  ...          34.12           126.70      1124.0   \n",
       "567         0.2397  ...          39.42           184.60      1821.0   \n",
       "568         0.1587  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test dataset\n",
    "\n",
    "import sklearn\n",
    "\n",
    "# return dataframe\n",
    "X_df = sklearn.datasets.load_breast_cancer(as_frame=True)[\"data\"]\n",
    "y_df = sklearn.datasets.load_breast_cancer(as_frame=True)[\"target\"]\n",
    "\n",
    "df = X_df.join(y_df).reset_index(drop=False, names=[\"eid\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">param</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>xvar</th>\n",
       "      <th>model</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>[mean radius, mean texture, mean perimeter, me...</td>\n",
       "      <td>&lt;function fit_best_model_v2 at 0x7f76c04b0430&gt;</td>\n",
       "      <td>{'cv': 10, 'engine': 'sklearn'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>[mean radius, mean texture, mean perimeter, me...</td>\n",
       "      <td>&lt;function fit_xgboost at 0x7f76b04a0a60&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightGBM</th>\n",
       "      <td>[mean radius, mean texture, mean perimeter, me...</td>\n",
       "      <td>&lt;function fit_lightgbm at 0x7f76b04a0b80&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TabPFN</th>\n",
       "      <td>[mean radius, mean texture, mean perimeter, me...</td>\n",
       "      <td>&lt;function fit_tabpfn at 0x7f76b04a0ee0&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      param  \\\n",
       "                                                       xvar   \n",
       "model                                                         \n",
       "Lasso     [mean radius, mean texture, mean perimeter, me...   \n",
       "xgboost   [mean radius, mean texture, mean perimeter, me...   \n",
       "lightGBM  [mean radius, mean texture, mean perimeter, me...   \n",
       "TabPFN    [mean radius, mean texture, mean perimeter, me...   \n",
       "\n",
       "                                                          \\\n",
       "                                                   model   \n",
       "model                                                      \n",
       "Lasso     <function fit_best_model_v2 at 0x7f76c04b0430>   \n",
       "xgboost         <function fit_xgboost at 0x7f76b04a0a60>   \n",
       "lightGBM       <function fit_lightgbm at 0x7f76b04a0b80>   \n",
       "TabPFN           <function fit_tabpfn at 0x7f76b04a0ee0>   \n",
       "\n",
       "                                           \n",
       "                                   config  \n",
       "model                                      \n",
       "Lasso     {'cv': 10, 'engine': 'sklearn'}  \n",
       "xgboost                               NaN  \n",
       "lightGBM                              NaN  \n",
       "TabPFN                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.columns[1:-1].tolist()\n",
    "combination_dict = OrderedDict(\n",
    "    {\n",
    "        (\"Lasso\"): {\n",
    "            \"xvar\": features,\n",
    "            \"model\": fit_best_model_v2,\n",
    "            \"config\": {\"cv\": 10, \"engine\": \"sklearn\"},\n",
    "        },\n",
    "        (\"xgboost\"): {\n",
    "            \"xvar\": features,\n",
    "            \"model\": fit_xgboost,\n",
    "        },\n",
    "        (\"lightGBM\"): {\n",
    "            \"xvar\": features,\n",
    "            \"model\": fit_lightgbm,\n",
    "        },\n",
    "        (\"TabPFN\"): {\n",
    "            \"xvar\": features,\n",
    "            \"model\": fit_tabpfn,\n",
    "        },\n",
    "        (\"TabNet\"): {\n",
    "            \"xvar\": features,\n",
    "            \"model\": fit_tabnet,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "model_table = config_dict_to_df(combination_dict, (\"model\"))\n",
    "model_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eid\n",
       "204  204\n",
       "70    70\n",
       "131  131\n",
       "431  431\n",
       "540  540\n",
       "..   ...\n",
       "486  486\n",
       "75    75\n",
       "249  249\n",
       "238  238\n",
       "265  265\n",
       "\n",
       "[114 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eid, test_eid = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_eid = train_eid[[\"eid\"]]\n",
    "test_eid = test_eid[[\"eid\"]]\n",
    "test_eid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data with train cases 286 and test cases 71 of target, while 32 columns\n",
      "/tmp/ipykernel_16585/4173160079.py:420: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/tmp/ipykernel_16585/4173160079.py:421: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "INFO:root:Drop NA by target and None and None in train and test and left 455 and 114 with train cases 286 and test cases 71\n"
     ]
    }
   ],
   "source": [
    "targetModel = DiseaseScoreModel_V2(\n",
    "    disease_df=df,\n",
    "    model_table=model_table,\n",
    "    label=\"target\",\n",
    "    disease_name=\"target\",\n",
    "    # test_size=0.5,\n",
    "    train_eid=train_eid.eid,\n",
    "    test_eid=test_eid.eid,\n",
    "    other_keep_cols=[col for col in df.columns if col not in [\"target\", \"eid\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'targetModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[248], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtargetModel\u001b[49m\u001b[38;5;241m.\u001b[39mupdate_model()\n\u001b[1;32m      2\u001b[0m targetModel\u001b[38;5;241m.\u001b[39mmodel_table\n",
      "\u001b[0;31mNameError\u001b[0m: name 'targetModel' is not defined"
     ]
    }
   ],
   "source": [
    "targetModel.update_model()\n",
    "targetModel.model_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'targetModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[249], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtargetModel\u001b[49m\u001b[38;5;241m.\u001b[39mmodel_table\n",
      "\u001b[0;31mNameError\u001b[0m: name 'targetModel' is not defined"
     ]
    }
   ],
   "source": [
    "targetModel.model_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import Linear, Module, ModuleList\n",
    "\n",
    "from torch_frame import TensorFrame, stype\n",
    "from torch_frame.nn.conv import TabTransformerConv\n",
    "from torch_frame.nn.encoder import (\n",
    "    EmbeddingEncoder,\n",
    "    LinearEncoder,\n",
    "    StypeWiseFeatureEncoder,\n",
    ")\n",
    "\n",
    "\n",
    "class ExampleTransformer(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        out_channels,\n",
    "        num_layers,\n",
    "        num_heads,\n",
    "        col_stats,\n",
    "        col_names_dict,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = StypeWiseFeatureEncoder(\n",
    "            out_channels=channels,\n",
    "            col_stats=col_stats,\n",
    "            col_names_dict=col_names_dict,\n",
    "            stype_encoder_dict={\n",
    "                stype.categorical: EmbeddingEncoder(),\n",
    "                stype.numerical: LinearEncoder(),\n",
    "            },\n",
    "        )\n",
    "        self.convs = ModuleList(\n",
    "            [\n",
    "                TabTransformerConv(\n",
    "                    channels=channels,\n",
    "                    num_heads=num_heads,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.decoder = Linear(channels, out_channels)\n",
    "\n",
    "    def forward(self, tf: TensorFrame) -> Tensor:\n",
    "        x, _ = self.encoder(tf)\n",
    "        for conv in self.convs:\n",
    "            x = conv(x)\n",
    "        out = self.decoder(x.mean(dim=1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_feather(\n",
    "    \"/mnt/d/桌面/work/AAA_lifeStyle/V3/output/raw_data/score_df.feather\"\n",
    ")\n",
    "lifeStyle_cols = [\n",
    "    \"PhysicalActivity\",\n",
    "    \"HealthyDiet\",\n",
    "    \"Alcohol_consumption\",\n",
    "    \"Sedentary_behaviour\",\n",
    "    \"BMI\",\n",
    "    \"SleepPattern\",\n",
    "    \"SmokingStatus\",\n",
    "]\n",
    "to_dummpy_cols = []\n",
    "for col in total_data.columns:\n",
    "    if total_data[col].dtype == \"category\":\n",
    "        to_dummpy_cols.append(col)\n",
    "\n",
    "to_dummpy_cols\n",
    "# dummpy used the first category as the base category\n",
    "# so we need to drop the first category to avoid multicollinearity\n",
    "tmp = pd.DataFrame()\n",
    "dummpy_cols = []\n",
    "# for col in [\n",
    "#     \"Sex(M)\",\n",
    "#     \"Ethnicity\",\n",
    "#     # \"Educational_attainment\",\n",
    "#     # \"Family_income\",\n",
    "#     # \"Empolyment\",\n",
    "#     \"antihypertensives\",\n",
    "#     \"antihyperglycemic\",\n",
    "#     \"lipid_lowering\",\n",
    "#     \"History_of_Hypertension\",\n",
    "#     \"History_of_Diabetes\",\n",
    "#     \"familiy_history_heart_disease\",\n",
    "# ]:\n",
    "lifeStyleDummyCols = []\n",
    "\n",
    "for col in to_dummpy_cols:\n",
    "    # dummy variable\n",
    "    dummy = pd.get_dummies(\n",
    "        total_data[col], prefix=col, drop_first=True\n",
    "    )  # default version is True, False for test at 20250305\n",
    "    for i in dummy.columns:\n",
    "        dummy[i] = dummy[i].astype(\"int\")\n",
    "    dummpy_cols.extend(dummy.columns)\n",
    "    if col in lifeStyle_cols:\n",
    "        lifeStyleDummyCols.extend(dummy.columns)\n",
    "    tmp = pd.concat([tmp, dummy], axis=1)\n",
    "total_data = pd.concat([total_data, tmp], axis=1)\n",
    "total_data\n",
    "for col in dummpy_cols:\n",
    "    total_data[col] = total_data[col].astype(float)\n",
    "total_data[\"PRS\"] = (total_data[\"PRS\"] - total_data[\"PRS\"].mean()) / total_data[\n",
    "    \"PRS\"\n",
    "].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = [\n",
    "    \"Age_at_recruitment\",\n",
    "    \"Sex_M\",\n",
    "    \"HbA1C\",\n",
    "    \"LDL_cholesterol\",\n",
    "    \"HDL_cholesterol\",\n",
    "    \"Cholesterol\",\n",
    "    \"Triglycerides\",\n",
    "    \"SBP\",\n",
    "    \"eGFR\",\n",
    "    \"antihypertensives\",\n",
    "    \"antihyperglycemic\",\n",
    "    \"lipid_lowering\",\n",
    "]\n",
    "lifeStyle_cols\n",
    "features = lifeStyle_cols + RF + [\"PRS\"]\n",
    "\n",
    "cat_cols = [\n",
    "    *lifeStyle_cols,\n",
    "    \"Sex_M\",\n",
    "    \"antihypertensives\",\n",
    "    \"antihyperglycemic\",\n",
    "    \"lipid_lowering\",\n",
    "    \"incident\",\n",
    "]\n",
    "qt_cols = [\n",
    "    \"Age_at_recruitment\",\n",
    "    \"HbA1C\",\n",
    "    \"LDL_cholesterol\",\n",
    "    \"HDL_cholesterol\",\n",
    "    \"Cholesterol\",\n",
    "    \"Triglycerides\",\n",
    "    \"SBP\",\n",
    "    \"eGFR\",\n",
    "    \"PRS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Control\n",
       "1         Control\n",
       "2         Control\n",
       "3         Control\n",
       "4         Control\n",
       "           ...   \n",
       "435991    Control\n",
       "435992    Control\n",
       "435993        AAA\n",
       "435994    Control\n",
       "435995    Control\n",
       "Name: AAA, Length: 435996, dtype: category\n",
       "Categories (2, object): ['Control', 'AAA']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data[\"AAA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame.data import Dataset\n",
    "from torch_frame import TensorFrame, stype\n",
    "\n",
    "# train_df = df.query(\"eid in @train_eid.eid\")\n",
    "# test_df = df.query(\"eid in @test_eid.eid\")\n",
    "# train_df\n",
    "\n",
    "# split train, val and tes\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.3, random_state=42)\n",
    "train_df = total_data[total_data[\"Type\"] == \"Train\"]\n",
    "test_df = total_data[total_data[\"Type\"] == \"Test\"]\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.groupby(\"AAA\").sample(n=3000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# import math\n",
    "# import os\n",
    "# import os.path as osp\n",
    "# import time\n",
    "# from typing import Any, Optional\n",
    "\n",
    "# import numpy as np\n",
    "# import optuna\n",
    "# import torch\n",
    "# from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, Module, MSELoss\n",
    "# from torch.optim.lr_scheduler import ExponentialLR\n",
    "# from torchmetrics import AUROC, Accuracy, MeanSquaredError\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# from torch_frame import stype\n",
    "# from torch_frame.data import DataLoader\n",
    "# from torch_frame.datasets import DataFrameBenchmark\n",
    "# from torch_frame.gbdt import CatBoost, LightGBM, XGBoost\n",
    "# from torch_frame.nn.encoder import EmbeddingEncoder, LinearBucketEncoder\n",
    "# from torch_frame.nn.models import (\n",
    "#     MLP,\n",
    "#     ExcelFormer,\n",
    "#     FTTransformer,\n",
    "#     ResNet,\n",
    "#     TabNet,\n",
    "#     TabTransformer,\n",
    "#     Trompt,\n",
    "# )\n",
    "# from torch_frame.typing import TaskType\n",
    "\n",
    "# # class Args:\n",
    "# #     def __init__(self, **kwargs):\n",
    "# #         # 使用字典存储键值对\n",
    "# #         self.__dict__.update(kwargs)\n",
    "\n",
    "# # # 创建 Args 对象\n",
    "\n",
    "# # args = Args(\n",
    "# #     model_type = \"TabNet\", # TabNet, TabTransformer, ExcelFormer, MLP, ResNet, Trompt, LightGBM, CatBoost, XGBoost\n",
    "# #     task_type = \"binary_classification\", # binary_classification, multiclass_classification, regression\n",
    "# #     scale = \"small\",\n",
    "# #     idx = 0,\n",
    "# # )\n",
    "\n",
    "# model_type = \"TabNet\"\n",
    "# train_dataset = TrainDataSet\n",
    "# test_dataset = TestDataSet\n",
    "# val_dataset = ValDataSet\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# TRAIN_CONFIG_KEYS = [\"batch_size\", \"gamma_rate\", \"base_lr\"]\n",
    "# task_type = \"binary_classification\"  # binary_classification, multiclass_classification, regression\n",
    "# sacle = \"small\"  # small, medium, large\n",
    "# epochs = 50\n",
    "# num_trials = 20  # Number of Optuna-based hyper-parameter tuning.\n",
    "# num_repeats = 5  # Number of repeated training and eval on the best config\n",
    "# seed = 42\n",
    "# result_path = \"./test\"\n",
    "\n",
    "\n",
    "# def fit_tabular_dl(\n",
    "#     model_type=\"TabNet\",\n",
    "#     train_dataset=TrainDataSet,\n",
    "#     test_dataset=TestDataSet,\n",
    "#     val_dataset=ValDataSet,\n",
    "#     device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "#     TRAIN_CONFIG_KEYS=[\"batch_size\", \"gamma_rate\", \"base_lr\"],\n",
    "#     # task_type = \"binary_classification\",  # binary_classification, multiclass_classification, regression\n",
    "#     # sacle = \"small\" , # small, medium, large\n",
    "#     epochs=50,\n",
    "#     num_trials=20,  # Number of Optuna-based hyper-parameter tuning.\n",
    "#     num_repeats=5,  # Number of repeated training and eval on the best config\n",
    "#     seed=42,\n",
    "#     result_path=\"./test\",\n",
    "# ):\n",
    "\n",
    "#     torch.manual_seed(seed)\n",
    "\n",
    "#     train_tensor_frame = train_dataset.tensor_frame\n",
    "#     val_tensor_frame = val_dataset.tensor_frame\n",
    "#     test_tensor_frame = test_dataset.tensor_frame\n",
    "\n",
    "#     if train_dataset.task_type == TaskType.BINARY_CLASSIFICATION:\n",
    "#         out_channels = 1\n",
    "#         loss_fun = BCEWithLogitsLoss()\n",
    "#         metric_computer = AUROC(task=\"binary\").to(device)\n",
    "#         higher_is_better = True\n",
    "#     elif train_dataset.task_type == TaskType.MULTICLASS_CLASSIFICATION:\n",
    "#         out_channels = train_dataset.num_classes\n",
    "#         loss_fun = CrossEntropyLoss()\n",
    "#         metric_computer = Accuracy(\n",
    "#             task=\"multiclass\", num_classes=train_dataset.num_classes\n",
    "#         ).to(device)\n",
    "#         higher_is_better = True\n",
    "#     elif train_dataset.task_type == TaskType.REGRESSION:\n",
    "#         out_channels = 1\n",
    "#         loss_fun = MSELoss()\n",
    "#         metric_computer = MeanSquaredError(squared=False).to(device)\n",
    "#         higher_is_better = False\n",
    "\n",
    "#     # To be set for each model\n",
    "#     model_cls = None\n",
    "#     col_stats = None\n",
    "\n",
    "#     # Set up model specific search space\n",
    "#     if model_type == \"TabNet\":\n",
    "#         model_search_space = {\n",
    "#             \"split_attn_channels\": [64, 128, 256],\n",
    "#             \"split_feat_channels\": [64, 128, 256],\n",
    "#             \"gamma\": [1.0, 1.2, 1.5],\n",
    "#             \"num_layers\": [4, 6, 8],\n",
    "#         }\n",
    "#         train_search_space = {\n",
    "#             \"batch_size\": [2048, 4096],\n",
    "#             \"base_lr\": [0.001, 0.01],\n",
    "#             \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "#         }\n",
    "#         model_cls = TabNet\n",
    "#         col_stats = train_dataset.col_stats\n",
    "#     elif model_type == \"FTTransformer\":\n",
    "#         model_search_space = {\n",
    "#             \"channels\": [64, 128, 256],\n",
    "#             \"num_layers\": [4, 6, 8],\n",
    "#         }\n",
    "#         train_search_space = {\n",
    "#             \"batch_size\": [256, 512],\n",
    "#             \"base_lr\": [0.0001, 0.001],\n",
    "#             \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "#         }\n",
    "#         model_cls = FTTransformer\n",
    "#         col_stats = train_dataset.col_stats\n",
    "#     elif model_type == \"FTTransformerBucket\":\n",
    "#         model_search_space = {\n",
    "#             \"channels\": [64, 128, 256],\n",
    "#             \"num_layers\": [4, 6, 8],\n",
    "#         }\n",
    "#         train_search_space = {\n",
    "#             \"batch_size\": [256, 512],\n",
    "#             \"base_lr\": [0.0001, 0.001],\n",
    "#             \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "#         }\n",
    "#         model_cls = FTTransformer\n",
    "\n",
    "#         col_stats = train_dataset.col_stats\n",
    "#     elif model_type == \"ResNet\":\n",
    "#         model_search_space = {\n",
    "#             \"channels\": [64, 128, 256],\n",
    "#             \"num_layers\": [4, 6, 8],\n",
    "#         }\n",
    "#         train_search_space = {\n",
    "#             \"batch_size\": [256, 512],\n",
    "#             \"base_lr\": [0.0001, 0.001],\n",
    "#             \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "#         }\n",
    "#         model_cls = ResNet\n",
    "#         col_stats = train_dataset.col_stats\n",
    "#     elif model_type == \"MLP\":\n",
    "#         model_search_space = {\n",
    "#             \"channels\": [64, 128, 256],\n",
    "#             \"num_layers\": [1, 2, 4],\n",
    "#         }\n",
    "#         train_search_space = {\n",
    "#             \"batch_size\": [256, 512],\n",
    "#             \"base_lr\": [0.0001, 0.001],\n",
    "#             \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "#         }\n",
    "#         model_cls = MLP\n",
    "#         col_stats = train_dataset.col_stats\n",
    "#     elif model_type == \"TabTransformer\":\n",
    "#         model_search_space = {\n",
    "#             \"channels\": [16, 32, 64, 128],\n",
    "#             \"num_layers\": [4, 6, 8],\n",
    "#             \"num_heads\": [4, 8],\n",
    "#             \"encoder_pad_size\": [2, 4],\n",
    "#             \"attn_dropout\": [0, 0.2],\n",
    "#             \"ffn_dropout\": [0, 0.2],\n",
    "#         }\n",
    "#         train_search_space = {\n",
    "#             \"batch_size\": [128, 256],\n",
    "#             \"base_lr\": [0.0001, 0.001],\n",
    "#             \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "#         }\n",
    "#         model_cls = TabTransformer\n",
    "#         col_stats = train_dataset.col_stats\n",
    "#     elif model_type == \"Trompt\":\n",
    "#         model_search_space = {\n",
    "#             \"channels\": [64, 128, 192],\n",
    "#             \"num_layers\": [4, 6, 8],\n",
    "#             \"num_prompts\": [64, 128, 192],\n",
    "#         }\n",
    "#         train_search_space = {\n",
    "#             \"batch_size\": [128, 256],\n",
    "#             \"base_lr\": [0.01, 0.001],\n",
    "#             \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "#         }\n",
    "#         if train_tensor_frame.num_cols > 20:\n",
    "#             # Reducing the model size to avoid GPU OOM\n",
    "#             model_search_space[\"channels\"] = [64, 128]\n",
    "#             model_search_space[\"num_prompts\"] = [64, 128]\n",
    "#         elif train_tensor_frame.num_cols > 50:\n",
    "#             model_search_space[\"channels\"] = [64]\n",
    "#             model_search_space[\"num_prompts\"] = [64]\n",
    "#         model_cls = Trompt\n",
    "#         col_stats = train_dataset.col_stats\n",
    "#     elif model_type == \"ExcelFormer\":\n",
    "#         from torch_frame.transforms import (\n",
    "#             CatToNumTransform,\n",
    "#             MutualInformationSort,\n",
    "#         )\n",
    "\n",
    "#         categorical_transform = CatToNumTransform()\n",
    "#         categorical_transform.fit(train_dataset.tensor_frame, train_dataset.col_stats)\n",
    "#         train_tensor_frame = categorical_transform(train_tensor_frame)\n",
    "#         # val_tensor_frame = categorical_transform(val_tensor_frame)\n",
    "#         # test_tensor_frame = categorical_transform(test_tensor_frame)\n",
    "#         col_stats = categorical_transform.transformed_stats\n",
    "\n",
    "#         mutual_info_sort = MutualInformationSort(task_type=train_dataset.task_type)\n",
    "#         mutual_info_sort.fit(train_tensor_frame, col_stats)\n",
    "#         train_tensor_frame = mutual_info_sort(train_tensor_frame)\n",
    "#         # val_tensor_frame = mutual_info_sort(val_tensor_frame)\n",
    "#         # test_tensor_frame = mutual_info_sort(test_tensor_frame)\n",
    "\n",
    "#         model_search_space = {\n",
    "#             \"in_channels\": [128, 256],\n",
    "#             \"num_heads\": [8, 16, 32],\n",
    "#             \"num_layers\": [4, 6, 8],\n",
    "#             \"diam_dropout\": [0, 0.2],\n",
    "#             \"residual_dropout\": [0, 0.2],\n",
    "#             \"aium_dropout\": [0, 0.2],\n",
    "#             \"mixup\": [None, \"feature\", \"hidden\"],\n",
    "#             \"beta\": [0.5],\n",
    "#             \"num_cols\": [train_tensor_frame.num_cols],\n",
    "#         }\n",
    "#         train_search_space = {\n",
    "#             \"batch_size\": [256, 512],\n",
    "#             \"base_lr\": [0.001],\n",
    "#             \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "#         }\n",
    "#         model_cls = ExcelFormer\n",
    "\n",
    "#     assert model_cls is not None\n",
    "#     assert col_stats is not None\n",
    "#     assert set(train_search_space.keys()) == set(TRAIN_CONFIG_KEYS)\n",
    "#     col_names_dict = train_tensor_frame.col_names_dict\n",
    "\n",
    "#     def train(\n",
    "#         model: Module,\n",
    "#         loader: DataLoader,\n",
    "#         optimizer: torch.optim.Optimizer,\n",
    "#         epoch: int,\n",
    "#     ) -> float:\n",
    "#         model.train()\n",
    "#         loss_accum = total_count = 0\n",
    "\n",
    "#         for tf in tqdm(loader, desc=f\"Epoch: {epoch}\"):\n",
    "#             tf = tf.to(device)\n",
    "#             y = tf.y\n",
    "#             if isinstance(model, ExcelFormer):\n",
    "#                 # Train with FEAT-MIX or HIDDEN-MIX\n",
    "#                 pred, y = model(tf, mixup_encoded=True)\n",
    "#             elif isinstance(model, Trompt):\n",
    "#                 # Trompt uses the layer-wise loss\n",
    "#                 pred = model(tf)\n",
    "#                 num_layers = pred.size(1)\n",
    "#                 # [batch_size * num_layers, num_classes]\n",
    "#                 pred = pred.view(-1, out_channels)\n",
    "#                 y = tf.y.repeat_interleave(num_layers)\n",
    "#             else:\n",
    "#                 pred = model(tf)\n",
    "\n",
    "#             if pred.size(1) == 1:\n",
    "#                 pred = pred.view(\n",
    "#                     -1,\n",
    "#                 )\n",
    "#             if train_dataset.task_type == TaskType.BINARY_CLASSIFICATION:\n",
    "#                 y = y.to(torch.float)\n",
    "#             loss = loss_fun(pred, y)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             loss_accum += float(loss) * len(tf.y)\n",
    "#             print(tf.y)\n",
    "#             total_count += len(tf.y)\n",
    "#             optimizer.step()\n",
    "#         return loss_accum / total_count\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def test(\n",
    "#         model: Module,\n",
    "#         loader: DataLoader,\n",
    "#     ) -> float:\n",
    "#         model.eval()\n",
    "#         metric_computer.reset()\n",
    "#         for tf in loader:\n",
    "#             tf = tf.to(device)\n",
    "#             pred = model(tf)\n",
    "#             if isinstance(model, Trompt):\n",
    "#                 pred = pred.mean(dim=1)\n",
    "#             if train_dataset.task_type == TaskType.MULTICLASS_CLASSIFICATION:\n",
    "#                 pred = pred.argmax(dim=-1)\n",
    "#             elif train_dataset.task_type == TaskType.REGRESSION:\n",
    "#                 pred = pred.view(\n",
    "#                     -1,\n",
    "#                 )\n",
    "#             metric_computer.update(pred, tf.y)\n",
    "#         return metric_computer.compute().item()\n",
    "\n",
    "#     def train_and_eval_with_cfg(\n",
    "#         model_cfg: dict[str, Any],\n",
    "#         train_cfg: dict[str, Any],\n",
    "#         trial: Optional[optuna.trial.Trial] = None,\n",
    "#     ) -> tuple[float, float]:\n",
    "#         # Use model_cfg to set up training procedure\n",
    "#         if model_type == \"FTTransformerBucket\":\n",
    "#             # Use LinearBucketEncoder instead\n",
    "#             stype_encoder_dict = {\n",
    "#                 stype.categorical: EmbeddingEncoder(),\n",
    "#                 stype.numerical: LinearBucketEncoder(),\n",
    "#             }\n",
    "#             model_cfg[\"stype_encoder_dict\"] = stype_encoder_dict\n",
    "#         model = model_cls(\n",
    "#             **model_cfg,\n",
    "#             out_channels=out_channels,\n",
    "#             col_stats=col_stats,\n",
    "#             col_names_dict=col_names_dict,\n",
    "#         ).to(device)\n",
    "#         model.reset_parameters()\n",
    "#         # Use train_cfg to set up training procedure\n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=train_cfg[\"base_lr\"])\n",
    "#         lr_scheduler = ExponentialLR(optimizer, gamma=train_cfg[\"gamma_rate\"])\n",
    "#         train_loader = DataLoader(\n",
    "#             train_tensor_frame,\n",
    "#             batch_size=train_cfg[\"batch_size\"],\n",
    "#             shuffle=True,\n",
    "#             drop_last=True,\n",
    "#         )\n",
    "#         val_loader = DataLoader(val_tensor_frame, batch_size=train_cfg[\"batch_size\"])\n",
    "#         test_loader = DataLoader(test_tensor_frame, batch_size=train_cfg[\"batch_size\"])\n",
    "\n",
    "#         if higher_is_better:\n",
    "#             best_val_metric = 0\n",
    "#         else:\n",
    "#             best_val_metric = math.inf\n",
    "\n",
    "#         for epoch in range(1, epochs + 1):\n",
    "#             train_loss = train(model, train_loader, optimizer, epoch)\n",
    "#             val_metric = test(model, val_loader)\n",
    "\n",
    "#             if higher_is_better:\n",
    "#                 if val_metric > best_val_metric:\n",
    "#                     best_val_metric = val_metric\n",
    "#                     best_test_metric = test(model, test_loader)\n",
    "#             else:\n",
    "#                 if val_metric < best_val_metric:\n",
    "#                     best_val_metric = val_metric\n",
    "#                     best_test_metric = test(model, test_loader)\n",
    "#             lr_scheduler.step()\n",
    "#             print(f\"Train Loss: {train_loss:.4f}, Val: {val_metric:.4f}\")\n",
    "\n",
    "#             if trial is not None:\n",
    "#                 trial.report(val_metric, epoch)\n",
    "#                 if trial.should_prune():\n",
    "#                     raise optuna.TrialPruned()\n",
    "\n",
    "#         print(f\"Best val: {best_val_metric:.4f}, Best test: {best_test_metric:.4f}\")\n",
    "#         return best_val_metric, best_test_metric\n",
    "\n",
    "#     def objective(trial: optuna.trial.Trial) -> float:\n",
    "#         model_cfg = {}\n",
    "#         for name, search_list in model_search_space.items():\n",
    "#             model_cfg[name] = trial.suggest_categorical(name, search_list)\n",
    "#         train_cfg = {}\n",
    "#         for name, search_list in train_search_space.items():\n",
    "#             train_cfg[name] = trial.suggest_categorical(name, search_list)\n",
    "\n",
    "#         best_val_metric, _ = train_and_eval_with_cfg(\n",
    "#             model_cfg=model_cfg, train_cfg=train_cfg, trial=trial\n",
    "#         )\n",
    "#         return best_val_metric\n",
    "\n",
    "\n",
    "#     # Hyper-parameter optimization with Optuna\n",
    "#     print(\"Hyper-parameter search via Optuna\")\n",
    "#     start_time = time.time()\n",
    "#     study = optuna.create_study(\n",
    "#         pruner=optuna.pruners.MedianPruner(),\n",
    "#         direction=\"maximize\" if higher_is_better else \"minimize\",\n",
    "#     )\n",
    "#     study.optimize(objective, n_trials=num_trials)\n",
    "#     end_time = time.time()\n",
    "#     search_time = end_time - start_time\n",
    "#     print(\"Hyper-parameter search done. Found the best config.\")\n",
    "#     params = study.best_params\n",
    "#     best_train_cfg = {}\n",
    "#     for train_cfg_key in TRAIN_CONFIG_KEYS:\n",
    "#         best_train_cfg[train_cfg_key] = params.pop(train_cfg_key)\n",
    "#     best_model_cfg = params\n",
    "\n",
    "#     print(\n",
    "#         f\"Repeat experiments {num_repeats} times with the best train \"\n",
    "#         f\"config {best_train_cfg} and model config {best_model_cfg}.\"\n",
    "#     )\n",
    "#     start_time = time.time()\n",
    "#     best_val_metrics = []\n",
    "#     best_test_metrics = []\n",
    "#     for _ in range(num_repeats):\n",
    "#         best_val_metric, best_test_metric = train_and_eval_with_cfg(\n",
    "#             best_model_cfg, best_train_cfg\n",
    "#         )\n",
    "#         best_val_metrics.append(best_val_metric)\n",
    "#         best_test_metrics.append(best_test_metric)\n",
    "#     end_time = time.time()\n",
    "#     final_model_time = (end_time - start_time) / num_repeats\n",
    "#     best_val_metrics = np.array(best_val_metrics)\n",
    "#     best_test_metrics = np.array(best_test_metrics)\n",
    "\n",
    "#     result_dict = {\n",
    "#         # 'args': __dict__,\n",
    "#         \"best_val_metrics\": best_val_metrics,\n",
    "#         \"best_test_metrics\": best_test_metrics,\n",
    "#         \"best_val_metric\": best_val_metrics.mean(),\n",
    "#         \"best_test_metric\": best_test_metrics.mean(),\n",
    "#         \"best_train_cfg\": best_train_cfg,\n",
    "#         \"best_model_cfg\": best_model_cfg,\n",
    "#         \"search_time\": search_time,\n",
    "#         \"final_model_time\": final_model_time,\n",
    "#         \"total_time\": search_time + final_model_time,\n",
    "#     }\n",
    "#     print(result_dict)\n",
    "#     # Save results\n",
    "#     if result_path != \"\":\n",
    "#         os.makedirs(os.path.dirname(result_path), exist_ok=True)\n",
    "#         torch.save(result_dict, result_path)\n",
    "#     return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_to_stype = {\n",
    "#     **{k: stype.numerical for k in train_df.columns if k not in [\"eid\", \"target\"]},\n",
    "#     **{\"target\": stype.categorical},\n",
    "# }\n",
    "\n",
    "col_to_stype = {\n",
    "    **{k: stype.numerical for k in qt_cols},\n",
    "    **{k: stype.categorical for k in cat_cols},\n",
    "}\n",
    "\n",
    "TrainDataSet = Dataset(\n",
    "    df=train_df,\n",
    "    col_to_stype=col_to_stype,\n",
    "    target_col=\"incident\",\n",
    ")\n",
    "TrainDataSet.materialize()\n",
    "\n",
    "ValDataSet = Dataset(\n",
    "    df=val_df,\n",
    "    col_to_stype=col_to_stype,\n",
    "    target_col=\"incident\",\n",
    ")\n",
    "ValDataSet.materialize()\n",
    "\n",
    "TestDataSet = Dataset(\n",
    "    df=test_df,\n",
    "    col_to_stype=col_to_stype,\n",
    "    target_col=\"incident\",\n",
    ")\n",
    "TestDataSet.materialize()\n",
    "from torch_frame.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(TrainDataSet.tensor_frame, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(ValDataSet.tensor_frame, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(TestDataSet.tensor_frame, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TaskType.BINARY_CLASSIFICATION: 'binary_classification'>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.task_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "from typing import Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, Module, MSELoss\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torchmetrics import AUROC, Accuracy, MeanSquaredError\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_frame import stype\n",
    "from torch_frame.data import DataLoader\n",
    "from torch_frame.datasets import DataFrameBenchmark\n",
    "from torch_frame.gbdt import CatBoost, LightGBM, XGBoost\n",
    "from torch_frame.nn.encoder import EmbeddingEncoder, LinearBucketEncoder\n",
    "from torch_frame.nn.models import (\n",
    "    MLP,\n",
    "    ExcelFormer,\n",
    "    FTTransformer,\n",
    "    ResNet,\n",
    "    TabNet,\n",
    "    TabTransformer,\n",
    "    Trompt,\n",
    ")\n",
    "from torch_frame.typing import TaskType\n",
    "\n",
    "# class Args:\n",
    "#     def __init__(self, **kwargs):\n",
    "#         # 使用字典存储键值对\n",
    "#         self.__dict__.update(kwargs)\n",
    "\n",
    "# # 创建 Args 对象\n",
    "\n",
    "# args = Args(\n",
    "#     model_type = \"TabNet\", # TabNet, TabTransformer, ExcelFormer, MLP, ResNet, Trompt, LightGBM, CatBoost, XGBoost\n",
    "#     task_type = \"binary_classification\", # binary_classification, multiclass_classification, regression\n",
    "#     scale = \"small\",\n",
    "#     idx = 0,\n",
    "# )\n",
    "\n",
    "model_type = \"MLP\"\n",
    "train_dataset = TrainDataSet\n",
    "test_dataset = TestDataSet\n",
    "val_dataset = ValDataSet\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRAIN_CONFIG_KEYS = [\"batch_size\", \"gamma_rate\", \"base_lr\"]\n",
    "task_type = \"binary_classification\"  # binary_classification, multiclass_classification, regression\n",
    "sacle = \"small\"  # small, medium, large\n",
    "epochs = 10\n",
    "num_trials = 3  # Number of Optuna-based hyper-parameter tuning.\n",
    "num_repeats = 5  # Number of repeated training and eval on the best config\n",
    "seed = 42\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "\n",
    "if train_dataset.task_type == TaskType.BINARY_CLASSIFICATION:\n",
    "    out_channels = 1\n",
    "    loss_fun = BCEWithLogitsLoss()\n",
    "    metric_computer = AUROC(task=\"binary\").to(device)\n",
    "    higher_is_better = True\n",
    "elif train_dataset.task_type == TaskType.MULTICLASS_CLASSIFICATION:\n",
    "    out_channels = train_dataset.num_classes\n",
    "    loss_fun = CrossEntropyLoss()\n",
    "    metric_computer = Accuracy(\n",
    "        task=\"multiclass\", num_classes=train_dataset.num_classes\n",
    "    ).to(device)\n",
    "    higher_is_better = True\n",
    "elif train_dataset.task_type == TaskType.REGRESSION:\n",
    "    out_channels = 1\n",
    "    loss_fun = MSELoss()\n",
    "    metric_computer = MeanSquaredError(squared=False).to(device)\n",
    "    higher_is_better = False\n",
    "\n",
    "# To be set for each model\n",
    "model_cls = None\n",
    "col_stats = None\n",
    "\n",
    "# Set up model specific search space\n",
    "if model_type == \"TabNet\":\n",
    "    model_search_space = {\n",
    "        \"split_attn_channels\": [64, 128, 256],\n",
    "        \"split_feat_channels\": [64, 128, 256],\n",
    "        \"gamma\": [1.0, 1.2, 1.5],\n",
    "        \"num_layers\": [4, 6, 8],\n",
    "    }\n",
    "    train_search_space = {\n",
    "        \"batch_size\": [\n",
    "            2048,\n",
    "            4096,\n",
    "        ],  # Note if you have a small data, you may want to reduce it, also low gpu memory\n",
    "        # \"batch_size\": [128, 256],\n",
    "        \"base_lr\": [0.001, 0.01],\n",
    "        \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "    }\n",
    "    model_cls = TabNet\n",
    "    col_stats = train_dataset.col_stats\n",
    "elif model_type == \"FTTransformer\":\n",
    "    model_search_space = {\n",
    "        \"channels\": [64, 128, 256],\n",
    "        \"num_layers\": [4, 6, 8],\n",
    "    }\n",
    "    train_search_space = {\n",
    "        \"batch_size\": [256, 512],\n",
    "        \"base_lr\": [0.0001, 0.001],\n",
    "        \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "    }\n",
    "    model_cls = FTTransformer\n",
    "    col_stats = train_dataset.col_stats\n",
    "elif model_type == \"FTTransformerBucket\":\n",
    "    model_search_space = {\n",
    "        \"channels\": [64, 128, 256],\n",
    "        \"num_layers\": [4, 6, 8],\n",
    "    }\n",
    "    train_search_space = {\n",
    "        \"batch_size\": [256, 512],\n",
    "        \"base_lr\": [0.0001, 0.001],\n",
    "        \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "    }\n",
    "    model_cls = FTTransformer\n",
    "\n",
    "    col_stats = train_dataset.col_stats\n",
    "elif model_type == \"ResNet\":\n",
    "    model_search_space = {\n",
    "        \"channels\": [64, 128, 256],\n",
    "        \"num_layers\": [4, 6, 8],\n",
    "    }\n",
    "    train_search_space = {\n",
    "        \"batch_size\": [256, 512],\n",
    "        \"base_lr\": [0.0001, 0.001],\n",
    "        \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "    }\n",
    "    model_cls = ResNet\n",
    "    col_stats = train_dataset.col_stats\n",
    "elif model_type == \"MLP\":\n",
    "    model_search_space = {\n",
    "        \"channels\": [64, 128, 256],\n",
    "        \"num_layers\": [1, 2, 4],\n",
    "    }\n",
    "    train_search_space = {\n",
    "        \"batch_size\": [256, 512],\n",
    "        \"base_lr\": [0.0001, 0.001],\n",
    "        \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "    }\n",
    "    model_cls = MLP\n",
    "    col_stats = train_dataset.col_stats\n",
    "elif model_type == \"TabTransformer\":\n",
    "    model_search_space = {\n",
    "        \"channels\": [16, 32, 64, 128],\n",
    "        \"num_layers\": [4, 6, 8],\n",
    "        \"num_heads\": [4, 8],\n",
    "        \"encoder_pad_size\": [2, 4],\n",
    "        \"attn_dropout\": [0, 0.2],\n",
    "        \"ffn_dropout\": [0, 0.2],\n",
    "    }\n",
    "    train_search_space = {\n",
    "        \"batch_size\": [128, 256],\n",
    "        \"base_lr\": [0.0001, 0.001],\n",
    "        \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "    }\n",
    "    model_cls = TabTransformer\n",
    "    col_stats = train_dataset.col_stats\n",
    "elif model_type == \"Trompt\":\n",
    "    model_search_space = {\n",
    "        \"channels\": [64, 128, 192],\n",
    "        \"num_layers\": [4, 6, 8],\n",
    "        \"num_prompts\": [64, 128, 192],\n",
    "    }\n",
    "    train_search_space = {\n",
    "        \"batch_size\": [128, 256],\n",
    "        \"base_lr\": [0.01, 0.001],\n",
    "        \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "    }\n",
    "    if train_tensor_frame.num_cols > 20:\n",
    "        # Reducing the model size to avoid GPU OOM\n",
    "        model_search_space[\"channels\"] = [64, 128]\n",
    "        model_search_space[\"num_prompts\"] = [64, 128]\n",
    "    elif train_tensor_frame.num_cols > 50:\n",
    "        model_search_space[\"channels\"] = [64]\n",
    "        model_search_space[\"num_prompts\"] = [64]\n",
    "    model_cls = Trompt\n",
    "    col_stats = train_dataset.col_stats\n",
    "elif model_type == \"ExcelFormer\":\n",
    "    from torch_frame.transforms import (\n",
    "        CatToNumTransform,\n",
    "        MutualInformationSort,\n",
    "    )\n",
    "\n",
    "    categorical_transform = CatToNumTransform()\n",
    "    categorical_transform.fit(train_dataset.tensor_frame, train_dataset.col_stats)\n",
    "    train_tensor_frame = categorical_transform(train_tensor_frame)\n",
    "    # val_tensor_frame = categorical_transform(val_tensor_frame)\n",
    "    # test_tensor_frame = categorical_transform(test_tensor_frame)\n",
    "    col_stats = categorical_transform.transformed_stats\n",
    "\n",
    "    mutual_info_sort = MutualInformationSort(task_type=train_dataset.task_type)\n",
    "    mutual_info_sort.fit(train_tensor_frame, col_stats)\n",
    "    train_tensor_frame = mutual_info_sort(train_tensor_frame)\n",
    "    # val_tensor_frame = mutual_info_sort(val_tensor_frame)\n",
    "    # test_tensor_frame = mutual_info_sort(test_tensor_frame)\n",
    "\n",
    "    model_search_space = {\n",
    "        \"in_channels\": [128, 256],\n",
    "        \"num_heads\": [8, 16, 32],\n",
    "        \"num_layers\": [4, 6, 8],\n",
    "        \"diam_dropout\": [0, 0.2],\n",
    "        \"residual_dropout\": [0, 0.2],\n",
    "        \"aium_dropout\": [0, 0.2],\n",
    "        \"mixup\": [None, \"feature\", \"hidden\"],\n",
    "        \"beta\": [0.5],\n",
    "        \"num_cols\": [train_tensor_frame.num_cols],\n",
    "    }\n",
    "    train_search_space = {\n",
    "        \"batch_size\": [256, 512],\n",
    "        \"base_lr\": [0.001],\n",
    "        \"gamma_rate\": [0.9, 0.95, 1.0],\n",
    "    }\n",
    "    model_cls = ExcelFormer\n",
    "\n",
    "assert model_cls is not None\n",
    "assert col_stats is not None\n",
    "assert set(train_search_space.keys()) == set(TRAIN_CONFIG_KEYS)\n",
    "col_names_dict = train_tensor_frame.col_names_dict\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: Module,\n",
    "    loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    loss_accum = total_count = 0\n",
    "\n",
    "    for tf in tqdm(loader, desc=f\"Epoch: {epoch}\"):\n",
    "        tf = tf.to(device)\n",
    "        y = tf.y\n",
    "        if isinstance(model, ExcelFormer):\n",
    "            # Train with FEAT-MIX or HIDDEN-MIX\n",
    "            pred, y = model(tf, mixup_encoded=True)\n",
    "        elif isinstance(model, Trompt):\n",
    "            # Trompt uses the layer-wise loss\n",
    "            pred = model(tf)\n",
    "            num_layers = pred.size(1)\n",
    "            # [batch_size * num_layers, num_classes]\n",
    "            pred = pred.view(-1, out_channels)\n",
    "            y = tf.y.repeat_interleave(num_layers)\n",
    "        else:\n",
    "            pred = model(tf)\n",
    "\n",
    "        if pred.size(1) == 1:\n",
    "            pred = pred.view(\n",
    "                -1,\n",
    "            )\n",
    "        if train_dataset.task_type == TaskType.BINARY_CLASSIFICATION:\n",
    "            y = y.to(torch.float)\n",
    "        loss = loss_fun(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_accum += float(loss) * len(tf.y)\n",
    "        total_count += len(tf.y)\n",
    "        optimizer.step()\n",
    "    return loss_accum / total_count\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(\n",
    "    model: Module,\n",
    "    loader: DataLoader,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    metric_computer.reset()\n",
    "    for tf in loader:\n",
    "        tf = tf.to(device)\n",
    "        pred = model(tf)\n",
    "        if isinstance(model, Trompt):\n",
    "            pred = pred.mean(dim=1)\n",
    "        if train_dataset.task_type == TaskType.MULTICLASS_CLASSIFICATION:\n",
    "            pred = pred.argmax(dim=-1)\n",
    "        elif train_dataset.task_type == TaskType.REGRESSION:\n",
    "            pred = pred.view(\n",
    "                -1,\n",
    "            )\n",
    "        metric_computer.update(pred, tf.y)\n",
    "    return metric_computer.compute().item()\n",
    "\n",
    "\n",
    "def train_and_eval_with_cfg(\n",
    "    model_cfg: dict[str, Any],\n",
    "    train_cfg: dict[str, Any],\n",
    "    trial: Optional[optuna.trial.Trial] = None,\n",
    ") -> tuple[float, float]:\n",
    "    # Use model_cfg to set up training procedure\n",
    "    if model_type == \"FTTransformerBucket\":\n",
    "        # Use LinearBucketEncoder instead\n",
    "        stype_encoder_dict = {\n",
    "            stype.categorical: EmbeddingEncoder(),\n",
    "            stype.numerical: LinearBucketEncoder(),\n",
    "        }\n",
    "        model_cfg[\"stype_encoder_dict\"] = stype_encoder_dict\n",
    "    model = model_cls(\n",
    "        **model_cfg,\n",
    "        out_channels=out_channels,\n",
    "        col_stats=col_stats,\n",
    "        col_names_dict=col_names_dict,\n",
    "    ).to(device)\n",
    "    model.reset_parameters()\n",
    "    # Use train_cfg to set up training procedure\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=train_cfg[\"base_lr\"])\n",
    "    lr_scheduler = ExponentialLR(optimizer, gamma=train_cfg[\"gamma_rate\"])\n",
    "    train_loader = DataLoader(\n",
    "        train_tensor_frame,\n",
    "        batch_size=train_cfg[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_loader = DataLoader(val_tensor_frame, batch_size=train_cfg[\"batch_size\"])\n",
    "    test_loader = DataLoader(test_tensor_frame, batch_size=train_cfg[\"batch_size\"])\n",
    "\n",
    "    if higher_is_better:\n",
    "        best_val_metric = 0\n",
    "    else:\n",
    "        best_val_metric = math.inf\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, train_loader, optimizer, epoch)\n",
    "        val_metric = test(model, val_loader)\n",
    "\n",
    "        if higher_is_better:\n",
    "            if val_metric > best_val_metric:\n",
    "                best_val_metric = val_metric\n",
    "                best_test_metric = test(model, test_loader)\n",
    "        else:\n",
    "            if val_metric < best_val_metric:\n",
    "                best_val_metric = val_metric\n",
    "                best_test_metric = test(model, test_loader)\n",
    "        lr_scheduler.step()\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val: {val_metric:.4f}\")\n",
    "\n",
    "        if trial is not None:\n",
    "            trial.report(val_metric, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    print(f\"Best val: {best_val_metric:.4f}, Best test: {best_test_metric:.4f}\")\n",
    "    return best_val_metric, best_test_metric\n",
    "\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    model_cfg = {}\n",
    "    for name, search_list in model_search_space.items():\n",
    "        model_cfg[name] = trial.suggest_categorical(name, search_list)\n",
    "    train_cfg = {}\n",
    "    for name, search_list in train_search_space.items():\n",
    "        train_cfg[name] = trial.suggest_categorical(name, search_list)\n",
    "\n",
    "    best_val_metric, _ = train_and_eval_with_cfg(\n",
    "        model_cfg=model_cfg, train_cfg=train_cfg, trial=trial\n",
    "    )\n",
    "    return best_val_metric\n",
    "\n",
    "\n",
    "def main_deep_models():\n",
    "    # Hyper-parameter optimization with Optuna\n",
    "    print(\"Hyper-parameter search via Optuna\")\n",
    "    start_time = time.time()\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(),\n",
    "        direction=\"maximize\" if higher_is_better else \"minimize\",\n",
    "    )\n",
    "    study.optimize(objective, n_trials=num_trials)\n",
    "    end_time = time.time()\n",
    "    search_time = end_time - start_time\n",
    "    print(\"Hyper-parameter search done. Found the best config.\")\n",
    "    params = study.best_params\n",
    "    best_train_cfg = {}\n",
    "    for train_cfg_key in TRAIN_CONFIG_KEYS:\n",
    "        best_train_cfg[train_cfg_key] = params.pop(train_cfg_key)\n",
    "    best_model_cfg = params\n",
    "\n",
    "    print(\n",
    "        f\"Repeat experiments {num_repeats} times with the best train \"\n",
    "        f\"config {best_train_cfg} and model config {best_model_cfg}.\"\n",
    "    )\n",
    "\n",
    "    # retrain model\n",
    "    if model_type == \"FTTransformerBucket\":\n",
    "        # Use LinearBucketEncoder instead\n",
    "        stype_encoder_dict = {\n",
    "            stype.categorical: EmbeddingEncoder(),\n",
    "            stype.numerical: LinearBucketEncoder(),\n",
    "        }\n",
    "        best_model_cfg[\"stype_encoder_dict\"] = stype_encoder_dict\n",
    "\n",
    "    model = model_cls(\n",
    "        **best_model_cfg,\n",
    "        out_channels=out_channels,\n",
    "        col_stats=col_stats,\n",
    "        col_names_dict=col_names_dict,\n",
    "    ).to(device)\n",
    "    model.reset_parameters()\n",
    "    # Use train_cfg to set up training procedure\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=best_train_cfg[\"base_lr\"])\n",
    "    lr_scheduler = ExponentialLR(optimizer, gamma=best_train_cfg[\"gamma_rate\"])\n",
    "    train_loader = DataLoader(\n",
    "        train_tensor_frame,\n",
    "        batch_size=best_train_cfg[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_loader = DataLoader(val_tensor_frame, batch_size=best_train_cfg[\"batch_size\"])\n",
    "    test_loader = DataLoader(test_tensor_frame, batch_size=best_train_cfg[\"batch_size\"])\n",
    "\n",
    "    if higher_is_better:\n",
    "        best_val_metric = 0\n",
    "    else:\n",
    "        best_val_metric = math.inf\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, train_loader, optimizer, epoch)\n",
    "        val_metric = test(model, val_loader)\n",
    "\n",
    "        if higher_is_better:\n",
    "            if val_metric > best_val_metric:\n",
    "                best_val_metric = val_metric\n",
    "                best_test_metric = test(model, test_loader)\n",
    "        else:\n",
    "            if val_metric < best_val_metric:\n",
    "                best_val_metric = val_metric\n",
    "                best_test_metric = test(model, test_loader)\n",
    "        lr_scheduler.step()\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val: {val_metric:.4f}\")\n",
    "\n",
    "    result_dict = {\n",
    "        # 'args': __dict__,\n",
    "        \"model\": model,\n",
    "        \"best_val_metric\": best_val_metric,\n",
    "        \"best_test_metric\": best_test_metric,\n",
    "        \"best_train_cfg\": best_train_cfg,\n",
    "        \"best_model_cfg\": best_model_cfg,\n",
    "        \"search_time\": search_time,\n",
    "    }\n",
    "    return result_dict\n",
    "\n",
    "    start_time = time.time()\n",
    "    best_val_metrics = []\n",
    "    best_test_metrics = []\n",
    "    for _ in range(num_repeats):\n",
    "        best_val_metric, best_test_metric = train_and_eval_with_cfg(\n",
    "            best_model_cfg, best_train_cfg\n",
    "        )\n",
    "        best_val_metrics.append(best_val_metric)\n",
    "        best_test_metrics.append(best_test_metric)\n",
    "    # end_time = time.time()\n",
    "    # final_model_time = (end_time - start_time) / num_repeats\n",
    "    # best_val_metrics = np.array(best_val_metrics)\n",
    "    # best_test_metrics = np.array(best_test_metrics)\n",
    "\n",
    "    # result_dict = {\n",
    "    #     # 'args': __dict__,\n",
    "    #     \"best_val_metrics\": best_val_metrics,\n",
    "    #     \"best_test_metrics\": best_test_metrics,\n",
    "    #     \"best_val_metric\": best_val_metrics.mean(),\n",
    "    #     \"best_test_metric\": best_test_metrics.mean(),\n",
    "    #     \"best_train_cfg\": best_train_cfg,\n",
    "    #     \"best_model_cfg\": best_model_cfg,\n",
    "    #     \"search_time\": search_time,\n",
    "    #     \"final_model_time\": final_model_time,\n",
    "    #     \"total_time\": search_time + final_model_time,\n",
    "    # }\n",
    "    # print(result_dict)\n",
    "    # # Save results\n",
    "    # if result_path != \"\":\n",
    "    #     os.makedirs(os.path.dirname(result_path), exist_ok=True)\n",
    "    #     torch.save(result_dict, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_cls(\n",
    "#     **model_cfg,\n",
    "#     out_channels=out_channels,\n",
    "#     col_stats=col_stats,\n",
    "#     col_names_dict=col_names_dict,\n",
    "# )\n",
    "# model.to(device)\n",
    "# train(\n",
    "#     model,\n",
    "#     train_loader,\n",
    "#     optimizer,\n",
    "#     epoch,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 13:54:23,596] A new study created in memory with name: no-name-20fbe0fa-3088-409e-a763-1f3f3d3c0cd7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper-parameter search via Optuna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 198/198 [00:02<00:00, 95.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0695, Val: 0.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 198/198 [00:01<00:00, 147.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0370, Val: 0.7563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 198/198 [00:01<00:00, 147.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0347, Val: 0.8210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 198/198 [00:01<00:00, 140.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0324, Val: 0.8389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 198/198 [00:01<00:00, 125.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0314, Val: 0.8445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 198/198 [00:00<00:00, 202.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0313, Val: 0.8489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 198/198 [00:00<00:00, 240.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0307, Val: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 198/198 [00:01<00:00, 147.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0307, Val: 0.8511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 198/198 [00:00<00:00, 259.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0303, Val: 0.8526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|██████████| 198/198 [00:01<00:00, 175.67it/s]\n",
      "[I 2025-03-24 13:54:48,946] Trial 0 finished with value: 0.8525776267051697 and parameters: {'channels': 64, 'num_layers': 4, 'batch_size': 512, 'base_lr': 0.001, 'gamma_rate': 0.9}. Best is trial 0 with value: 0.8525776267051697.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0302, Val: 0.8525\n",
      "Best val: 0.8526, Best test: 0.8585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 397/397 [00:01<00:00, 372.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0423, Val: 0.7774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 397/397 [00:01<00:00, 394.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0325, Val: 0.7924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 397/397 [00:01<00:00, 353.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0319, Val: 0.7951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 397/397 [00:01<00:00, 355.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0316, Val: 0.8024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 397/397 [00:01<00:00, 349.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0311, Val: 0.8102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 397/397 [00:01<00:00, 354.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0311, Val: 0.8117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 397/397 [00:01<00:00, 359.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0305, Val: 0.8194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 397/397 [00:01<00:00, 367.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0304, Val: 0.8220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 397/397 [00:01<00:00, 370.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0302, Val: 0.8248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|██████████| 397/397 [00:01<00:00, 356.14it/s]\n",
      "[I 2025-03-24 13:55:11,225] Trial 1 finished with value: 0.8301591873168945 and parameters: {'channels': 256, 'num_layers': 4, 'batch_size': 256, 'base_lr': 0.0001, 'gamma_rate': 0.9}. Best is trial 0 with value: 0.8525776267051697.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0298, Val: 0.8302\n",
      "Best val: 0.8302, Best test: 0.8372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 198/198 [00:00<00:00, 411.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3212, Val: 0.6582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 198/198 [00:01<00:00, 182.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0498, Val: 0.7611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 198/198 [00:01<00:00, 169.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0353, Val: 0.8012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 198/198 [00:01<00:00, 172.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0331, Val: 0.8143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 198/198 [00:01<00:00, 162.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0323, Val: 0.8223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 198/198 [00:01<00:00, 169.11it/s]\n"
     ]
    }
   ],
   "source": [
    "res = main_deep_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predict\n",
    "model = res[\"model\"]\n",
    "pred_array = []\n",
    "for tf in test_loader:\n",
    "    tf = tf.to(device)\n",
    "    pred = model(tf).cpu().detach().flatten().tolist()\n",
    "\n",
    "    # proba = torch.softmax(pred, dim=1)[:, 1].cpu().detach().numpy().tolist()\n",
    "    pred_array.extend(pred)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29921/1739847205.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUC': 0.8304221064354074,\n",
       " 'ACC': 0.7796975201607355,\n",
       " 'Macro_F1': 0.45684945991264686,\n",
       " 'Sensitivity': 0.7434094903339191,\n",
       " 'Specificity': 0.7799153507269247,\n",
       " 'APR': 0.046981357128616584}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestDataSet.df[\"pred\"] = pred_array\n",
    "from ppp_prediction.metrics import cal_binary_metrics\n",
    "\n",
    "cal_binary_metrics(TestDataSet.df[\"incident\"], TestDataSet.df[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "0.1027328372001648\n",
      "Epoch 1\n",
      "0.0993896871805191\n",
      "Epoch 2\n",
      "0.06829185783863068\n",
      "Epoch 3\n",
      "0.1154552698135376\n",
      "Epoch 4\n",
      "0.08367930352687836\n",
      "Epoch 5\n",
      "0.02228795550763607\n",
      "Epoch 6\n",
      "0.052397169172763824\n",
      "Epoch 7\n",
      "0.18704631924629211\n",
      "Epoch 8\n",
      "0.011632421053946018\n",
      "Epoch 9\n",
      "0.0033353206235915422\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ExampleTransformer(\n",
    "    channels=32,\n",
    "    out_channels=TrainDataSet.num_classes,\n",
    "    num_layers=2,\n",
    "    num_heads=8,\n",
    "    col_stats=TrainDataSet.col_stats,\n",
    "    col_names_dict=TrainDataSet.tensor_frame.col_names_dict,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for tf in train_loader:\n",
    "        tf = tf.to(device)\n",
    "        pred = model.forward(tf)\n",
    "        loss = F.cross_entropy(pred, tf.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predict\n",
    "pred_array = []\n",
    "for tf in test_loader:\n",
    "    tf = tf.to(device)\n",
    "    pred = model(tf)\n",
    "\n",
    "    proba = torch.softmax(pred, dim=1)[:, 1].cpu().detach().numpy().tolist()\n",
    "    pred_array.extend(proba)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29921/995162998.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "TestDataSet.df[\"pred\"] = pred_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUC': 0.99737962659679,\n",
       " 'ACC': 0.9736842105263158,\n",
       " 'Macro_F1': 0.9721203228173148,\n",
       " 'Sensitivity': 0.9859154929577465,\n",
       " 'Specificity': 0.9767441860465116,\n",
       " 'APR': 0.9983678405804648}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestDataSet.df[\"pred\"] = pred_array\n",
    "from ppp_prediction.metrics import cal_binary_metrics\n",
    "\n",
    "cal_binary_metrics(TestDataSet.df[\"target\"], TestDataSet.df[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame.datasets import Yandex\n",
    "from torch_frame.data import DataLoader\n",
    "\n",
    "train_dataset = Yandex(root=\"/tmp/adult\", name=\"adult\")\n",
    "train_dataset.materialize()\n",
    "train_dataset = train_dataset[:0.8]\n",
    "train_loader = DataLoader(train_dataset.tensor_frame, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'target_col'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "from typing import Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, Module, MSELoss\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torchmetrics import AUROC, Accuracy, MeanSquaredError\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_frame import stype\n",
    "from torch_frame.data import DataLoader\n",
    "from torch_frame.datasets import DataFrameBenchmark\n",
    "from torch_frame.gbdt import CatBoost, LightGBM, XGBoost\n",
    "from torch_frame.nn.encoder import EmbeddingEncoder, LinearBucketEncoder\n",
    "from torch_frame.nn.models import (\n",
    "    MLP,\n",
    "    ExcelFormer,\n",
    "    FTTransformer,\n",
    "    ResNet,\n",
    "    TabNet,\n",
    "    TabTransformer,\n",
    "    Trompt,\n",
    ")\n",
    "from torch_frame.typing import TaskType\n",
    "\n",
    "TRAIN_CONFIG_KEYS = [\"batch_size\", \"gamma_rate\", \"base_lr\"]\n",
    "GBDT_MODELS = [\"XGBoost\", \"CatBoost\", \"LightGBM\"]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--task_type', type=str, choices=[\n",
    "        'binary_classification',\n",
    "        'multiclass_classification',\n",
    "        'regression',\n",
    "    ], default='binary_classification')\n",
    "parser.add_argument('--scale', type=str, choices=['small', 'medium', 'large'],\n",
    "                    default='small')\n",
    "parser.add_argument('--idx', type=int, default=0,\n",
    "                    help='The index of the dataset within DataFrameBenchmark')\n",
    "parser.add_argument('--epochs', type=int, default=50)\n",
    "parser.add_argument('--num_trials', type=int, default=20,\n",
    "                    help='Number of Optuna-based hyper-parameter tuning.')\n",
    "parser.add_argument(\n",
    "    '--num_repeats', type=int, default=5,\n",
    "    help='Number of repeated training and eval on the best config.')\n",
    "parser.add_argument(\n",
    "    '--model_type', type=str, default='TabNet', choices=[\n",
    "        'TabNet', 'FTTransformer', 'ResNet', 'MLP', 'TabTransformer', 'Trompt',\n",
    "        'ExcelFormer', 'FTTransformerBucket', 'XGBoost', 'CatBoost', 'LightGBM'\n",
    "    ])\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--result_path', type=str, default='')\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Prepare datasets\n",
    "path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data')\n",
    "train_dataset = DataFrameBenchmark(root=path, task_type=TaskType(args.task_type),\n",
    "                             scale=args.scale, idx=args.idx)\n",
    "train_dataset.materialize()\n",
    "train_dataset = train_dataset.shuffle()\n",
    "train_dataset, val_dataset, test_dataset = train_dataset.split()\n",
    "\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "\n",
    "if args.model_type in GBDT_MODELS:\n",
    "    gbdt_cls_dict = {\n",
    "        'XGBoost': XGBoost,\n",
    "        'CatBoost': CatBoost,\n",
    "        'LightGBM': LightGBM\n",
    "    }\n",
    "    model_cls = gbdt_cls_dict[args.model_type]\n",
    "else:\n",
    "    if train_dataset.task_type == TaskType.BINARY_CLASSIFICATION:\n",
    "        out_channels = 1\n",
    "        loss_fun = BCEWithLogitsLoss()\n",
    "        metric_computer = AUROC(task='binary').to(device)\n",
    "        higher_is_better = True\n",
    "    elif train_dataset.task_type == TaskType.MULTICLASS_CLASSIFICATION:\n",
    "        out_channels = train_dataset.num_classes\n",
    "        loss_fun = CrossEntropyLoss()\n",
    "        metric_computer = Accuracy(task='multiclass',\n",
    "                                   num_classes=train_dataset.num_classes).to(device)\n",
    "        higher_is_better = True\n",
    "    elif train_dataset.task_type == TaskType.REGRESSION:\n",
    "        out_channels = 1\n",
    "        loss_fun = MSELoss()\n",
    "        metric_computer = MeanSquaredError(squared=False).to(device)\n",
    "        higher_is_better = False\n",
    "\n",
    "    # To be set for each model\n",
    "    model_cls = None\n",
    "    col_stats = None\n",
    "\n",
    "    # Set up model specific search space\n",
    "    if args.model_type == 'TabNet':\n",
    "        model_search_space = {\n",
    "            'split_attn_channels': [64, 128, 256],\n",
    "            'split_feat_channels': [64, 128, 256],\n",
    "            'gamma': [1., 1.2, 1.5],\n",
    "            'num_layers': [4, 6, 8],\n",
    "        }\n",
    "        train_search_space = {\n",
    "            'batch_size': [2048, 4096],\n",
    "            'base_lr': [0.001, 0.01],\n",
    "            'gamma_rate': [0.9, 0.95, 1.],\n",
    "        }\n",
    "        model_cls = TabNet\n",
    "        col_stats = train_dataset.col_stats\n",
    "    elif args.model_type == 'FTTransformer':\n",
    "        model_search_space = {\n",
    "            'channels': [64, 128, 256],\n",
    "            'num_layers': [4, 6, 8],\n",
    "        }\n",
    "        train_search_space = {\n",
    "            'batch_size': [256, 512],\n",
    "            'base_lr': [0.0001, 0.001],\n",
    "            'gamma_rate': [0.9, 0.95, 1.],\n",
    "        }\n",
    "        model_cls = FTTransformer\n",
    "        col_stats = train_dataset.col_stats\n",
    "    elif args.model_type == 'FTTransformerBucket':\n",
    "        model_search_space = {\n",
    "            'channels': [64, 128, 256],\n",
    "            'num_layers': [4, 6, 8],\n",
    "        }\n",
    "        train_search_space = {\n",
    "            'batch_size': [256, 512],\n",
    "            'base_lr': [0.0001, 0.001],\n",
    "            'gamma_rate': [0.9, 0.95, 1.],\n",
    "        }\n",
    "        model_cls = FTTransformer\n",
    "\n",
    "        col_stats = train_dataset.col_stats\n",
    "    elif args.model_type == 'ResNet':\n",
    "        model_search_space = {\n",
    "            'channels': [64, 128, 256],\n",
    "            'num_layers': [4, 6, 8],\n",
    "        }\n",
    "        train_search_space = {\n",
    "            'batch_size': [256, 512],\n",
    "            'base_lr': [0.0001, 0.001],\n",
    "            'gamma_rate': [0.9, 0.95, 1.],\n",
    "        }\n",
    "        model_cls = ResNet\n",
    "        col_stats = train_dataset.col_stats\n",
    "    elif args.model_type == 'MLP':\n",
    "        model_search_space = {\n",
    "            'channels': [64, 128, 256],\n",
    "            'num_layers': [1, 2, 4],\n",
    "        }\n",
    "        train_search_space = {\n",
    "            'batch_size': [256, 512],\n",
    "            'base_lr': [0.0001, 0.001],\n",
    "            'gamma_rate': [0.9, 0.95, 1.],\n",
    "        }\n",
    "        model_cls = MLP\n",
    "        col_stats = train_dataset.col_stats\n",
    "    elif args.model_type == 'TabTransformer':\n",
    "        model_search_space = {\n",
    "            'channels': [16, 32, 64, 128],\n",
    "            'num_layers': [4, 6, 8],\n",
    "            'num_heads': [4, 8],\n",
    "            'encoder_pad_size': [2, 4],\n",
    "            'attn_dropout': [0, 0.2],\n",
    "            'ffn_dropout': [0, 0.2],\n",
    "        }\n",
    "        train_search_space = {\n",
    "            'batch_size': [128, 256],\n",
    "            'base_lr': [0.0001, 0.001],\n",
    "            'gamma_rate': [0.9, 0.95, 1.],\n",
    "        }\n",
    "        model_cls = TabTransformer\n",
    "        col_stats = train_dataset.col_stats\n",
    "    elif args.model_type == 'Trompt':\n",
    "        model_search_space = {\n",
    "            'channels': [64, 128, 192],\n",
    "            'num_layers': [4, 6, 8],\n",
    "            'num_prompts': [64, 128, 192],\n",
    "        }\n",
    "        train_search_space = {\n",
    "            'batch_size': [128, 256],\n",
    "            'base_lr': [0.01, 0.001],\n",
    "            'gamma_rate': [0.9, 0.95, 1.],\n",
    "        }\n",
    "        if train_tensor_frame.num_cols > 20:\n",
    "            # Reducing the model size to avoid GPU OOM\n",
    "            model_search_space['channels'] = [64, 128]\n",
    "            model_search_space['num_prompts'] = [64, 128]\n",
    "        elif train_tensor_frame.num_cols > 50:\n",
    "            model_search_space['channels'] = [64]\n",
    "            model_search_space['num_prompts'] = [64]\n",
    "        model_cls = Trompt\n",
    "        col_stats = train_dataset.col_stats\n",
    "    elif args.model_type == 'ExcelFormer':\n",
    "        from torch_frame.transforms import (\n",
    "            CatToNumTransform,\n",
    "            MutualInformationSort,\n",
    "        )\n",
    "\n",
    "        categorical_transform = CatToNumTransform()\n",
    "        categorical_transform.fit(train_dataset.tensor_frame,\n",
    "                                  train_dataset.col_stats)\n",
    "        train_tensor_frame = categorical_transform(train_tensor_frame)\n",
    "        val_tensor_frame = categorical_transform(val_tensor_frame)\n",
    "        test_tensor_frame = categorical_transform(test_tensor_frame)\n",
    "        col_stats = categorical_transform.transformed_stats\n",
    "\n",
    "        mutual_info_sort = MutualInformationSort(task_type=train_dataset.task_type)\n",
    "        mutual_info_sort.fit(train_tensor_frame, col_stats)\n",
    "        train_tensor_frame = mutual_info_sort(train_tensor_frame)\n",
    "        val_tensor_frame = mutual_info_sort(val_tensor_frame)\n",
    "        test_tensor_frame = mutual_info_sort(test_tensor_frame)\n",
    "\n",
    "        model_search_space = {\n",
    "            'in_channels': [128, 256],\n",
    "            'num_heads': [8, 16, 32],\n",
    "            'num_layers': [4, 6, 8],\n",
    "            'diam_dropout': [0, 0.2],\n",
    "            'residual_dropout': [0, 0.2],\n",
    "            'aium_dropout': [0, 0.2],\n",
    "            'mixup': [None, 'feature', 'hidden'],\n",
    "            'beta': [0.5],\n",
    "            'num_cols': [train_tensor_frame.num_cols],\n",
    "        }\n",
    "        train_search_space = {\n",
    "            'batch_size': [256, 512],\n",
    "            'base_lr': [0.001],\n",
    "            'gamma_rate': [0.9, 0.95, 1.],\n",
    "        }\n",
    "        model_cls = ExcelFormer\n",
    "\n",
    "    assert model_cls is not None\n",
    "    assert col_stats is not None\n",
    "    assert set(train_search_space.keys()) == set(TRAIN_CONFIG_KEYS)\n",
    "    col_names_dict = train_tensor_frame.col_names_dict\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: Module,\n",
    "    loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    loss_accum = total_count = 0\n",
    "\n",
    "    for tf in tqdm(loader, desc=f'Epoch: {epoch}'):\n",
    "        tf = tf.to(device)\n",
    "        y = tf.y\n",
    "        if isinstance(model, ExcelFormer):\n",
    "            # Train with FEAT-MIX or HIDDEN-MIX\n",
    "            pred, y = model(tf, mixup_encoded=True)\n",
    "        elif isinstance(model, Trompt):\n",
    "            # Trompt uses the layer-wise loss\n",
    "            pred = model(tf)\n",
    "            num_layers = pred.size(1)\n",
    "            # [batch_size * num_layers, num_classes]\n",
    "            pred = pred.view(-1, out_channels)\n",
    "            y = tf.y.repeat_interleave(num_layers)\n",
    "        else:\n",
    "            pred = model(tf)\n",
    "\n",
    "        if pred.size(1) == 1:\n",
    "            pred = pred.view(-1, )\n",
    "        if train_dataset.task_type == TaskType.BINARY_CLASSIFICATION:\n",
    "            y = y.to(torch.float)\n",
    "        loss = loss_fun(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_accum += float(loss) * len(tf.y)\n",
    "        total_count += len(tf.y)\n",
    "        optimizer.step()\n",
    "    return loss_accum / total_count\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(\n",
    "    model: Module,\n",
    "    loader: DataLoader,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    metric_computer.reset()\n",
    "    for tf in loader:\n",
    "        tf = tf.to(device)\n",
    "        pred = model(tf)\n",
    "        if isinstance(model, Trompt):\n",
    "            pred = pred.mean(dim=1)\n",
    "        if train_dataset.task_type == TaskType.MULTICLASS_CLASSIFICATION:\n",
    "            pred = pred.argmax(dim=-1)\n",
    "        elif train_dataset.task_type == TaskType.REGRESSION:\n",
    "            pred = pred.view(-1, )\n",
    "        metric_computer.update(pred, tf.y)\n",
    "    return metric_computer.compute().item()\n",
    "\n",
    "\n",
    "def train_and_eval_with_cfg(\n",
    "    model_cfg: dict[str, Any],\n",
    "    train_cfg: dict[str, Any],\n",
    "    trial: Optional[optuna.trial.Trial] = None,\n",
    ") -> tuple[float, float]:\n",
    "    # Use model_cfg to set up training procedure\n",
    "    if args.model_type == 'FTTransformerBucket':\n",
    "        # Use LinearBucketEncoder instead\n",
    "        stype_encoder_dict = {\n",
    "            stype.categorical: EmbeddingEncoder(),\n",
    "            stype.numerical: LinearBucketEncoder(),\n",
    "        }\n",
    "        model_cfg['stype_encoder_dict'] = stype_encoder_dict\n",
    "    model = model_cls(\n",
    "        **model_cfg,\n",
    "        out_channels=out_channels,\n",
    "        col_stats=col_stats,\n",
    "        col_names_dict=col_names_dict,\n",
    "    ).to(device)\n",
    "    model.reset_parameters()\n",
    "    # Use train_cfg to set up training procedure\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=train_cfg['base_lr'])\n",
    "    lr_scheduler = ExponentialLR(optimizer, gamma=train_cfg['gamma_rate'])\n",
    "    train_loader = DataLoader(train_tensor_frame,\n",
    "                              batch_size=train_cfg['batch_size'], shuffle=True,\n",
    "                              drop_last=True)\n",
    "    val_loader = DataLoader(val_tensor_frame,\n",
    "                            batch_size=train_cfg['batch_size'])\n",
    "    test_loader = DataLoader(test_tensor_frame,\n",
    "                             batch_size=train_cfg['batch_size'])\n",
    "\n",
    "    if higher_is_better:\n",
    "        best_val_metric = 0\n",
    "    else:\n",
    "        best_val_metric = math.inf\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train_loss = train(model, train_loader, optimizer, epoch)\n",
    "        val_metric = test(model, val_loader)\n",
    "\n",
    "        if higher_is_better:\n",
    "            if val_metric > best_val_metric:\n",
    "                best_val_metric = val_metric\n",
    "                best_test_metric = test(model, test_loader)\n",
    "        else:\n",
    "            if val_metric < best_val_metric:\n",
    "                best_val_metric = val_metric\n",
    "                best_test_metric = test(model, test_loader)\n",
    "        lr_scheduler.step()\n",
    "        print(f'Train Loss: {train_loss:.4f}, Val: {val_metric:.4f}')\n",
    "\n",
    "        if trial is not None:\n",
    "            trial.report(val_metric, epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    print(\n",
    "        f'Best val: {best_val_metric:.4f}, Best test: {best_test_metric:.4f}')\n",
    "    return best_val_metric, best_test_metric\n",
    "\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    model_cfg = {}\n",
    "    for name, search_list in model_search_space.items():\n",
    "        model_cfg[name] = trial.suggest_categorical(name, search_list)\n",
    "    train_cfg = {}\n",
    "    for name, search_list in train_search_space.items():\n",
    "        train_cfg[name] = trial.suggest_categorical(name, search_list)\n",
    "\n",
    "    best_val_metric, _ = train_and_eval_with_cfg(model_cfg=model_cfg,\n",
    "                                                 train_cfg=train_cfg,\n",
    "                                                 trial=trial)\n",
    "    return best_val_metric\n",
    "\n",
    "\n",
    "def main_deep_models():\n",
    "    # Hyper-parameter optimization with Optuna\n",
    "    print(\"Hyper-parameter search via Optuna\")\n",
    "    start_time = time.time()\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(),\n",
    "        direction=\"maximize\" if higher_is_better else \"minimize\",\n",
    "    )\n",
    "    study.optimize(objective, n_trials=args.num_trials)\n",
    "    end_time = time.time()\n",
    "    search_time = end_time - start_time\n",
    "    print(\"Hyper-parameter search done. Found the best config.\")\n",
    "    params = study.best_params\n",
    "    best_train_cfg = {}\n",
    "    for train_cfg_key in TRAIN_CONFIG_KEYS:\n",
    "        best_train_cfg[train_cfg_key] = params.pop(train_cfg_key)\n",
    "    best_model_cfg = params\n",
    "\n",
    "    print(f\"Repeat experiments {args.num_repeats} times with the best train \"\n",
    "          f\"config {best_train_cfg} and model config {best_model_cfg}.\")\n",
    "    start_time = time.time()\n",
    "    best_val_metrics = []\n",
    "    best_test_metrics = []\n",
    "    for _ in range(args.num_repeats):\n",
    "        best_val_metric, best_test_metric = train_and_eval_with_cfg(\n",
    "            best_model_cfg, best_train_cfg)\n",
    "        best_val_metrics.append(best_val_metric)\n",
    "        best_test_metrics.append(best_test_metric)\n",
    "    end_time = time.time()\n",
    "    final_model_time = (end_time - start_time) / args.num_repeats\n",
    "    best_val_metrics = np.array(best_val_metrics)\n",
    "    best_test_metrics = np.array(best_test_metrics)\n",
    "\n",
    "    result_dict = {\n",
    "        'args': args.__dict__,\n",
    "        'best_val_metrics': best_val_metrics,\n",
    "        'best_test_metrics': best_test_metrics,\n",
    "        'best_val_metric': best_val_metrics.mean(),\n",
    "        'best_test_metric': best_test_metrics.mean(),\n",
    "        'best_train_cfg': best_train_cfg,\n",
    "        'best_model_cfg': best_model_cfg,\n",
    "        'search_time': search_time,\n",
    "        'final_model_time': final_model_time,\n",
    "        'total_time': search_time + final_model_time,\n",
    "    }\n",
    "    print(result_dict)\n",
    "    # Save results\n",
    "    if args.result_path != '':\n",
    "        os.makedirs(os.path.dirname(args.result_path), exist_ok=True)\n",
    "        torch.save(result_dict, args.result_path)\n",
    "\n",
    "\n",
    "def main_gbdt():\n",
    "    if train_dataset.task_type.is_classification:\n",
    "        num_classes = train_dataset.num_classes\n",
    "    else:\n",
    "        num_classes = None\n",
    "    model = model_cls(task_type=train_dataset.task_type, num_classes=num_classes)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    model.tune(tf_train=train_dataset.tensor_frame,\n",
    "               tf_val=val_dataset.tensor_frame, num_trials=args.num_trials)\n",
    "    val_pred = model.predict(tf_test=val_dataset.tensor_frame)\n",
    "    val_metric = model.compute_metric(val_dataset.tensor_frame.y, val_pred)\n",
    "    test_pred = model.predict(tf_test=test_dataset.tensor_frame)\n",
    "    test_metric = model.compute_metric(test_dataset.tensor_frame.y, test_pred)\n",
    "    end_time = time.time()\n",
    "    result_dict = {\n",
    "        'args': args.__dict__,\n",
    "        'best_val_metric': val_metric,\n",
    "        'best_test_metric': test_metric,\n",
    "        'best_cfg': model.params,\n",
    "        'total_time': end_time - start_time,\n",
    "    }\n",
    "    print(result_dict)\n",
    "    # Save results\n",
    "    if args.result_path != '':\n",
    "        os.makedirs(os.path.dirname(args.result_path), exist_ok=True)\n",
    "        torch.save(result_dict, args.result_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(args)\n",
    "    if os.path.exists(args.result_path):\n",
    "        exit(-1)\n",
    "    if args.model_type in [\"XGBoost\", \"CatBoost\", \"LightGBM\"]:\n",
    "        main_gbdt()\n",
    "    else:\n",
    "        main_deep_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ExampleTransformer(\n",
    "    channels=32,\n",
    "    out_channels=train_dataset.num_classes,\n",
    "    num_layers=2,\n",
    "    num_heads=8,\n",
    "    col_stats=train_dataset.col_stats,\n",
    "    col_names_dict=train_dataset.tensor_frame.col_names_dict,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for tf in train_loader:\n",
    "        tf = tf.to(device)\n",
    "        pred = model.forward(tf)\n",
    "        loss = F.cross_entropy(pred, tf.y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6940, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
