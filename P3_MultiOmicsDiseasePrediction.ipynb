{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiOmicsDiseasePrediction\n",
    "\n",
    "数据维度\n",
    "\n",
    "- Meta\n",
    "- Prot\n",
    "- RF | PANNEL | AS \n",
    "- PRS\n",
    "- LTL + CHIP \n",
    "\n",
    "流程：\n",
    "1. Meta 和 Prot 交集 作为 held-out 数据 \n",
    "2. 排除held-out数据作为所有维度数据的单独模型的训练集\n",
    "2. 定义研究的疾病或者表型数据（输出所有数据集中的case|control的比例；如有时间则列出随访信息等）\n",
    "3. 对每个数据定义机器学习方法（xxx.py）\n",
    "4. 整合全部组学的预测分数\n",
    "5. 下游分析（calibration，netbenifit，重分类，分数的百分比风险图，疾病生存分析（如有随访））\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "# %config InlineBackend.figure_format = \"svg\"\n",
    "# %config InlineBackend.print_figure_kwargs = {\"dpi\" : 300}\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# from cadFace.vis import percentiles_plot\n",
    "import sci_palettes\n",
    "\n",
    "try:\n",
    "    sci_palettes.register_cmap()\n",
    "except:\n",
    "    pass\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use([\"nature\", \"no-latex\"])\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_palette(\"nejm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(x):\n",
    "    # if isinstance(x, Path.)\n",
    "    x = str(x)\n",
    "    if \".csv\" in x:\n",
    "        return pd.read_csv(x)\n",
    "    elif x.endswith(\".feather\"):\n",
    "        return pd.read_feather(x)\n",
    "    elif x.endswith(\".pkl\"):\n",
    "        return pd.read_pickle(x)\n",
    "    elif \".tsv\" in x:\n",
    "        return pd.read_csv(x, sep=\"\\t\")\n",
    "    else:\n",
    "        raise ValueError(f\"File format: {x} not supported\")\n",
    "\n",
    "\n",
    "class DataConfig(object):\n",
    "    def __init__(self, path, name=None, **kwargs):\n",
    "        self.name = name if name else Path(path).stem\n",
    "        self.path = path\n",
    "        # self.kwargs = kwargs\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def __load_data__(self):\n",
    "        print(f\"Loading data: {self.name}\")\n",
    "        self.data = load_data(self.path)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.name\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.name\n",
    "\n",
    "\n",
    "# class ModelConfig(object):\n",
    "#     def __init__(self, name, model, feature, cov, **kwargs):\n",
    "#         self.name = name\n",
    "#         self.model = model\n",
    "#         self.feature = feature\n",
    "#         self.cov = cov\n",
    "#         for key, value in kwargs.items():\n",
    "#             setattr(self, key, value)\n",
    "\n",
    "\n",
    "class ModelConfig(dict):\n",
    "    def __init__(self, name=None, model=None, feature=None, cov=None, **kwargs):\n",
    "        kwargs[\"name\"] = name\n",
    "        kwargs[\"model\"] = model\n",
    "        kwargs[\"feature\"] = feature\n",
    "        kwargs[\"cov\"] = cov\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "\n",
    "def check_disease_dist(Config):\n",
    "    # to_check_list = Config\n",
    "    diseaseData = Config[\"diseaseData\"].data\n",
    "    disease = Config[\"diseaseData\"].name\n",
    "    disease_event_col = Config[\"diseaseData\"].label\n",
    "\n",
    "    dist = {}\n",
    "    for dataconfig in Config[\"omicsData\"].values():\n",
    "        data_eids = dataconfig.data[[\"eid\"]].copy()\n",
    "        dataname = dataconfig.name\n",
    "\n",
    "        if data_eids.eid.dtype != diseaseData.eid.dtype:\n",
    "            data_eids.eid = data_eids.eid.astype(diseaseData.eid.dtype)\n",
    "\n",
    "        inner_data = diseaseData.merge(data_eids, on=\"eid\", how=\"inner\")[\n",
    "            [disease_event_col]\n",
    "        ]\n",
    "\n",
    "        inner_data = inner_data.value_counts().to_dict()\n",
    "\n",
    "        dist[dataname] = inner_data\n",
    "\n",
    "    dataconfig = Config[\"heldOutData\"]\n",
    "    data_eids = dataconfig.data[[\"eid\"]].copy()\n",
    "    dataname = dataconfig.name\n",
    "\n",
    "    if data_eids.eid.dtype != diseaseData.eid.dtype:\n",
    "        data_eids.eid = data_eids.eid.astype(diseaseData.eid.dtype)\n",
    "\n",
    "    inner_data = diseaseData.merge(data_eids, on=\"eid\", how=\"inner\")[\n",
    "        [disease_event_col]\n",
    "    ]\n",
    "\n",
    "    inner_data = inner_data.value_counts().to_dict()\n",
    "\n",
    "    dist[dataname] = inner_data\n",
    "\n",
    "    dist_df = pd.DataFrame(dist)\n",
    "\n",
    "    return dist_df\n",
    "\n",
    "class LassoConfig(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature,\n",
    "        label,\n",
    "        cov,\n",
    "        name=\"lasso\",\n",
    "        family=\"binomial\",\n",
    "        lambda_=None,\n",
    "        type_measure=\"auc\",\n",
    "        cv=10,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        assert isinstance(label, str), \"label should be a string\"\n",
    "        if cov is not None:\n",
    "            if isinstance(cov, str):\n",
    "                cov = [cov]\n",
    "            elif isinstance(cov, list):\n",
    "                if len(cov) == 0:\n",
    "                    cov = None\n",
    "\n",
    "        assert isinstance(feature, str) or isinstance(\n",
    "            feature, list\n",
    "        ), \"feature should be a string or a list\"\n",
    "        self.config = {\n",
    "            name: {\n",
    "                \"feature\": feature if isinstance(feature, list) else [feature],\n",
    "                \"label\": label,\n",
    "                \"time\": None,\n",
    "                \"cov\": cov,\n",
    "                \"family\": family,\n",
    "                \"lambda\": lambda_,\n",
    "                \"type_measure\": type_measure,\n",
    "                \"cv\": cv,\n",
    "            }\n",
    "        }\n",
    "        if kwargs:\n",
    "            # export them and warning not used\n",
    "            print(f\"Warning: {kwargs} not used\")\n",
    "\n",
    "    def to_json(self):\n",
    "        return self.config\n",
    "\n",
    "\n",
    "def plot_coef_scatter(data, coef, feature, k=6, ax=None, cmap=\"nejm\"):\n",
    "    data = (\n",
    "        data[[coef, feature]].copy().rename(columns={coef: \"coef\", feature: \"feature\"})\n",
    "    )\n",
    "    plt_data = (\n",
    "        data.query(\"coef !=0\")\n",
    "        .sort_values(\"coef\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "        .reset_index(drop=False, names=[\"idx\"])\n",
    "    )\n",
    "\n",
    "    from adjustText import adjust_text\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "    hue = \"coef\"\n",
    "    y = \"coef\"\n",
    "    name = \"feature\"\n",
    "    plt_data = plt_data.query(\"feature != 'sex' & feature != 'age' \")\n",
    "\n",
    "    # 计算每个点的颜色\n",
    "    colors = plt_data[hue]\n",
    "    min_value = max(abs(colors.min()), abs(colors.max()))\n",
    "    norm = plt.Normalize(-min_value, min_value)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    sc = ax.scatter(\n",
    "        plt_data.index,\n",
    "        plt_data[y],\n",
    "        c=colors,\n",
    "        cmap=cmap,\n",
    "        s=30,\n",
    "        # edgecolor=\"k\",\n",
    "        zorder=3,\n",
    "    )\n",
    "    # cb = plt.colorbar(sm, ax=ax)\n",
    "\n",
    "    # 设置标题和轴标签\n",
    "    ax.set_title(\n",
    "        f\"Mean Coefficient of {name} bootstrap model\", fontsize=16, fontweight=\"bold\"\n",
    "    )\n",
    "    ax.set_xlabel(\n",
    "        \"\",\n",
    "    )\n",
    "    ax.set_ylabel(\"Mean Coefficient\", fontsize=14)\n",
    "    ax.set_yticks([-min_value / 2, 0, min_value / 2])\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    # 增加网格线\n",
    "    ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    texts = [\n",
    "        ax.text(\n",
    "            idx,\n",
    "            row[y],\n",
    "            f\"{row[name]}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "        for idx, row in plt_data.head(k).iterrows()\n",
    "    ] + [\n",
    "        ax.text(\n",
    "            idx,\n",
    "            row[y],\n",
    "            f\"{row[name]}\",\n",
    "            ha=\"center\",\n",
    "            va=\"top\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "        for idx, row in plt_data.tail(k).iterrows()\n",
    "    ]\n",
    "    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle=\"->\", lw=0.5))\n",
    "\n",
    "\n",
    "class GLMNETBootsrapResult(object):\n",
    "    def __init__(self, bootstrap_coef_df):\n",
    "        self.coef = bootstrap_coef_df\n",
    "        self.features = self.coef.index.tolist()\n",
    "        self._init_weights_dist()\n",
    "\n",
    "    def _init_weights_dist(self):\n",
    "\n",
    "        res = self.coef\n",
    "\n",
    "        percent_of_nonZero_coefficients = (\n",
    "            (res != 0).sum(axis=1) * 100 / len(res.columns)\n",
    "        )\n",
    "        mean_coefficients = res.mean(axis=1)\n",
    "        weights_dist_df = pd.DataFrame(\n",
    "            [percent_of_nonZero_coefficients, mean_coefficients],\n",
    "            index=[\"percent_of_nonZero_coefficients\", \"mean_coefficients\"],\n",
    "        ).T\n",
    "        weights_dist_df[\"abs_mean_coefficients\"] = weights_dist_df[\n",
    "            \"mean_coefficients\"\n",
    "        ].abs()\n",
    "        self.weights_dist_df = weights_dist_df\n",
    "\n",
    "    def _plot_top_k_features(self, k=10, pallete=\"viridis\", ax=None, exclude=None):\n",
    "        \"\"\"\n",
    "        plot top k features\n",
    "        \"\"\"\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, k))\n",
    "\n",
    "        if isinstance(exclude, str):\n",
    "            exclude = [exclude]\n",
    "\n",
    "        if exclude is not None:\n",
    "            plt_data = self.coef.loc[self.coef.index.difference(exclude), :]\n",
    "\n",
    "            top_k_features = self.weights_dist_df\n",
    "            top_k_features = top_k_features.loc[\n",
    "                top_k_features.index.difference(exclude), :\n",
    "            ].sort_values(\n",
    "                by=[\"mean_coefficients\"],\n",
    "                ascending=False,\n",
    "            )\n",
    "        else:\n",
    "            plt_data = self.coef\n",
    "            top_k_features = self.weights_dist_df.sort_values(\n",
    "                by=[\"mean_coefficients\"],\n",
    "                ascending=False,\n",
    "            )\n",
    "\n",
    "        plt_data = plt_data.loc[\n",
    "            [*top_k_features.index[:k], *top_k_features.index[-k:]], :\n",
    "        ]\n",
    "        idx_name = plt_data.index.name\n",
    "        plt_data = plt_data.reset_index(drop=False).melt(id_vars=idx_name)\n",
    "\n",
    "        sns.boxplot(\n",
    "            data=plt_data,\n",
    "            y=idx_name,\n",
    "            x=\"value\",\n",
    "            showfliers=False,\n",
    "            ax=ax,\n",
    "            palette=pallete,\n",
    "        )\n",
    "        ax.set_xticks([0.0])\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=10)\n",
    "\n",
    "        ax.grid(axis=\"x\", linestyle=\"--\", alpha=1, linewidth=2, color=\"red\")\n",
    "        ax.set_xlabel(\"Mean of Coefficients\")\n",
    "        ax.set_ylabel(\"Features\")\n",
    "        ax.set_title(f\"Top {k} Features\")\n",
    "        return ax\n",
    "\n",
    "    def _show_models_coeffients(self, axes=None, color=\"#d67b7f\", top=5, exclude=None):\n",
    "        \"\"\"\n",
    "        res:\n",
    "            model1 model2\n",
    "        SOST xx yy\n",
    "        BGN xx yy\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        if self.coef is None:\n",
    "            self.coef = self._init_coeffeients_df()\n",
    "        res = self.coef\n",
    "\n",
    "        # exclude = self.cov if exclude is None else exclude + self.cov\n",
    "        if exclude:\n",
    "            if isinstance(exclude, str):\n",
    "                exclude = [exclude]\n",
    "            res = res.loc[res.index.difference(exclude), :]\n",
    "\n",
    "        if axes is None:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        else:\n",
    "            assert len(axes) == 2, \"axes should be a list of length 2\"\n",
    "            ax1, ax2 = axes\n",
    "\n",
    "        percent_of_nonZero_coefficients = (\n",
    "            (res != 0).sum(axis=1) * 100 / len(res.columns)\n",
    "        )\n",
    "        mean_coefficients = res.mean(axis=1)\n",
    "        plt_data = pd.DataFrame(\n",
    "            [percent_of_nonZero_coefficients, mean_coefficients],\n",
    "            index=[\"percent_of_nonZero_coefficients\", \"mean_coefficients\"],\n",
    "        ).T\n",
    "        plt_data[\"abs_mean_coefficients\"] = plt_data[\"mean_coefficients\"].abs()\n",
    "\n",
    "        # ax1\n",
    "        sns.scatterplot(\n",
    "            x=percent_of_nonZero_coefficients,\n",
    "            y=mean_coefficients,\n",
    "            size=mean_coefficients,\n",
    "            sizes=(20, 400),\n",
    "            legend=False,\n",
    "            edgecolor=\"black\",\n",
    "            ax=ax1,\n",
    "            color=color,\n",
    "        )\n",
    "        ax1.plot([0, 100], [0, 0], \"k--\", lw=3, color=\"grey\")\n",
    "        ax1.set_xlim(-1, 105)\n",
    "        ax1.set_xlabel(\"percent of non-zero coefficients\")\n",
    "        ax1.set_ylabel(\"mean nonzero coefficients\")\n",
    "        sorted_plt_data = (\n",
    "            plt_data.sort_values(\n",
    "                by=[\"percent_of_nonZero_coefficients\", \"abs_mean_coefficients\"],\n",
    "                ascending=False,\n",
    "            )\n",
    "            .iloc[:top, :]\n",
    "            .index\n",
    "        )\n",
    "        for i, txt in enumerate(sorted_plt_data):\n",
    "            # ax1.annotate(txt, (sorted_plt_data.iloc[i, 0], sorted_plt_data.iloc[i, 1]))\n",
    "            ax1.text(\n",
    "                plt_data.loc[txt, \"percent_of_nonZero_coefficients\"],\n",
    "                plt_data.loc[txt, \"mean_coefficients\"],\n",
    "                txt,\n",
    "                ha=\"right\",\n",
    "                fontsize=8,\n",
    "                color=\"black\",\n",
    "            )\n",
    "\n",
    "        # ax2\n",
    "        absolute_mean_coefficients = mean_coefficients.abs().sort_values(ascending=True)\n",
    "        sns.barplot(\n",
    "            y=absolute_mean_coefficients,\n",
    "            x=absolute_mean_coefficients.index,\n",
    "            ax=ax2,\n",
    "            color=color,\n",
    "        )\n",
    "        ax2.set_ylabel(\"absolute mean coefficients\")\n",
    "        ax2.set_xlabel(\"\")\n",
    "        xticks = ax2.get_xticklabels()\n",
    "        if len(xticks) > 100:\n",
    "            ax2.set_xticks([\"\"] * len(xticks))\n",
    "        else:\n",
    "            ax2.set_xticklabels(ax2.get_xticklabels(), rotation=90)\n",
    "        if axes is None:\n",
    "            # fig.tight_layout()\n",
    "            return ax1, ax2\n",
    "\n",
    "    def coef_barplot(\n",
    "        self,\n",
    "        cmap=\"RdBu_r\",\n",
    "        k=10,\n",
    "        ax=None,\n",
    "        errorbar_kwargs=None,\n",
    "        scatter_kwargs=None,\n",
    "        exclude=[\"age\", \"sex\"],\n",
    "    ):\n",
    "        from adjustText import adjust_text\n",
    "        from scipy import stats\n",
    "\n",
    "        if errorbar_kwargs is None:\n",
    "            errorbar_kwargs = {}\n",
    "        if scatter_kwargs is None:\n",
    "            scatter_kwargs = {}\n",
    "\n",
    "        plt_data = self.coef.copy()\n",
    "\n",
    "        def cal_ci(x):\n",
    "            mean_x = x.mean()\n",
    "            scale = stats.sem(x)\n",
    "            ci_low, ci_high = stats.t.interval(\n",
    "                0.95, len(x) - 1, loc=mean_x, scale=scale\n",
    "            )\n",
    "            return {\"mean\": mean_x, \"ci_low\": ci_low, \"ci_high\": ci_high}\n",
    "\n",
    "        # drop age sex\n",
    "\n",
    "        # exclude = self.cov if exclude is None else exclude + self.cov\n",
    "        if isinstance(exclude, str):\n",
    "            exclude = [exclude]\n",
    "\n",
    "        plt_data = plt_data.loc[[i not in exclude for i in plt_data.index.tolist()]]\n",
    "\n",
    "        plt_data = plt_data.apply(\n",
    "            lambda x: pd.Series(cal_ci(x)),\n",
    "            axis=1,\n",
    "        )\n",
    "        plt_data = plt_data.sort_values(\"mean\", ascending=False).reset_index(\n",
    "            drop=False, names=\"feature\"\n",
    "        )\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(12, 4))\n",
    "        plt_data[\"error_low\"] = plt_data[\"mean\"] - plt_data[\"ci_low\"]\n",
    "        plt_data[\"error_high\"] = plt_data[\"ci_high\"] - plt_data[\"mean\"]\n",
    "\n",
    "        # 绘制误差线\n",
    "\n",
    "        ax.errorbar(\n",
    "            x=plt_data.index,\n",
    "            y=plt_data[\"mean\"],\n",
    "            yerr=[\n",
    "                plt_data[\"mean\"] - plt_data.ci_low,\n",
    "                plt_data.ci_high - plt_data[\"mean\"],\n",
    "            ],\n",
    "            fmt=errorbar_kwargs.pop(\"fmt\", \"none\"),  # 不使用标记\n",
    "            lw=errorbar_kwargs.pop(\"lw\", 1),\n",
    "            capsize=errorbar_kwargs.pop(\"capsize\", 2),\n",
    "            ecolor=errorbar_kwargs.pop(\"ecolor\", \"lightgrey\"),  # 将误差线设置为浅灰色\n",
    "            **errorbar_kwargs,\n",
    "        )\n",
    "\n",
    "        # 使用scatter添加颜色渐变的散点\n",
    "        # 计算每个点的颜色\n",
    "        colors = plt_data[\"mean\"]\n",
    "        min_value = max(abs(colors.min()), abs(colors.max()))\n",
    "        norm = plt.Normalize(-min_value, min_value)\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "\n",
    "        sc = ax.scatter(\n",
    "            plt_data.index,\n",
    "            plt_data[\"mean\"],\n",
    "            c=colors,\n",
    "            cmap=cmap,\n",
    "            s=scatter_kwargs.pop(\"s\", 5),\n",
    "            # edgecolor=\"k\",\n",
    "            zorder=scatter_kwargs.pop(\"zorder\", 3),\n",
    "            **scatter_kwargs,\n",
    "        )\n",
    "        cb = plt.colorbar(sm, ax=ax)\n",
    "\n",
    "        # 设置标题和轴标签\n",
    "        ax.set_title(\n",
    "            \"Mean Coefficient of bootstrap model\", fontsize=16, fontweight=\"bold\"\n",
    "        )\n",
    "        ax.set_xlabel(\n",
    "            \"\",\n",
    "        )\n",
    "        ax.set_ylabel(\"Mean Coefficient\", fontsize=14)\n",
    "        ax.set_yticks([-min_value / 2, 0, min_value / 2])\n",
    "        ax.set_xticks([])\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        # 增加网格线\n",
    "        ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.5)\n",
    "\n",
    "        texts = [\n",
    "            ax.text(\n",
    "                idx,\n",
    "                row[\"mean\"] + row[\"error_high\"],\n",
    "                f\"{row['feature']}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "            for idx, row in plt_data.head(k).iterrows()\n",
    "        ] + [\n",
    "            ax.text(\n",
    "                idx,\n",
    "                row[\"mean\"] - row[\"error_low\"],\n",
    "                f\"{row['feature']}\",\n",
    "                ha=\"center\",\n",
    "                va=\"top\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "            for idx, row in plt_data.tail(k).iterrows()\n",
    "        ]\n",
    "        adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle=\"->\", lw=0.5))\n",
    "\n",
    "        return ax\n",
    "\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def load_glmnet_bootstrap(model_dir):\n",
    "    \"\"\"\n",
    "    dir/\n",
    "        1/Meta/\n",
    "            coef_df.csv\n",
    "            train_score.csv\n",
    "            test_score.csv\n",
    "        1/Prot/\n",
    "            coef_df.csv\n",
    "            train_score.csv\n",
    "            test_score.csv\n",
    "        2/Meta/\n",
    "        ...\n",
    "    \"\"\"\n",
    "\n",
    "    model_dir = Path(model_dir)\n",
    "\n",
    "    coef_df_name = \"coef_df.csv\"\n",
    "    train_score = \"train_score.csv\"\n",
    "    test_score = \"test_score.csv\"\n",
    "\n",
    "    from collections import defaultdict\n",
    "\n",
    "    res = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    found_csvs = list(model_dir.rglob(\"*.csv\"))\n",
    "    for file_dir in found_csvs:\n",
    "        if file_dir.parent == model_dir:\n",
    "            continue\n",
    "        filename = file_dir.stem\n",
    "        submodelname = file_dir.parent.name\n",
    "        seed = file_dir.parent.parent.name\n",
    "        file = pd.read_csv(file_dir)\n",
    "        if filename == \"coef_df\":\n",
    "            file.columns = [\"feature\", f\"coef_{seed}\"]\n",
    "            file.set_index(\"feature\", inplace=True)\n",
    "        elif filename == \"train_score\":\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "            file.rename(columns={\"pred\": f\"pred_{seed}\"}, inplace=True)\n",
    "            file.set_index(\"eid\", inplace=True)\n",
    "\n",
    "        res[submodelname][filename].append(file)\n",
    "\n",
    "    for submodelname in res.keys():\n",
    "        for subcsv in res[submodelname].keys():\n",
    "            # first = res[submodelname][subcsv][0].iloc[:, [0]]\n",
    "            merged = pd.concat(res[submodelname][subcsv], axis=1)\n",
    "            res[submodelname][subcsv] = merged\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "import json\n",
    "import subprocess\n",
    "import shutil\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "def run_glmnet(\n",
    "    json_dir,\n",
    "    train_dir,\n",
    "    out_dir,\n",
    "    test_dir=None,\n",
    "    seed=None,\n",
    "):\n",
    "\n",
    "    if shutil.which(\"run_glmnet.R\") is None:\n",
    "        raise ValueError(\"run_glmnet.R is not in the PATH\")\n",
    "\n",
    "    cmd = f\"run_glmnet.R --json {json_dir} --train {train_dir} --out {out_dir}\"\n",
    "    if test_dir is not None:\n",
    "        cmd += f\" --test {test_dir}\"\n",
    "    if seed is not None:\n",
    "        cmd += f\" --seed {seed}\"\n",
    "    print(cmd)\n",
    "    subprocess.run(cmd, shell=True)\n",
    "    return subprocess\n",
    "\n",
    "\n",
    "class LassoTrainTFPipline(object):\n",
    "    def __init__(\n",
    "        self, mmconfig, dataconfig, tgtconfig, phenoconfig, testdataconfig=None\n",
    "    ):\n",
    "        \"\"\" \"\"\"\n",
    "        self.mmconfig = mmconfig\n",
    "        self.dataconfig = dataconfig\n",
    "        self.tgtconfig = tgtconfig\n",
    "        self.phenoconfig = phenoconfig\n",
    "        self.testdataconfig = testdataconfig\n",
    "\n",
    "    def run(self, n_bootstrap=200, n_jobs=4, outputFolder=\"./out\"):\n",
    "        # simple lasso\n",
    "        mmconfig = self.mmconfig\n",
    "        dataconfig = self.dataconfig\n",
    "        tgtconfig = self.tgtconfig\n",
    "        phenoconfig = self.phenoconfig\n",
    "        outputFolder = Path(outputFolder)\n",
    "\n",
    "        label = tgtconfig.label\n",
    "        diseaseData = tgtconfig.data\n",
    "\n",
    "        phenosData = phenoconfig.data\n",
    "\n",
    "        model_list = mmconfig[\"model\"]\n",
    "        modelname = mmconfig[\"name\"]\n",
    "        feature = mmconfig[\"feature\"]\n",
    "        cov = mmconfig[\"cov\"] if mmconfig[\"cov\"] is not None else []\n",
    "\n",
    "        # copy data\n",
    "        used_pheno_data = phenosData[[\"eid\"] + cov].copy()\n",
    "        used_dis_data = diseaseData[[\"eid\", label]].copy()\n",
    "\n",
    "        # check eid dtype\n",
    "\n",
    "        if used_pheno_data.eid.dtype != dataconfig.data.eid.dtype:\n",
    "            used_pheno_data.eid = used_pheno_data.eid.astype(dataconfig.data.eid.dtype)\n",
    "        if used_dis_data.eid.dtype != dataconfig.data.eid.dtype:\n",
    "            used_dis_data.eid = used_dis_data.eid.astype(dataconfig.data.eid.dtype)\n",
    "\n",
    "        # check output\n",
    "        model_output_folder = outputFolder / modelname\n",
    "        model_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        # lasso\n",
    "        lasso_config = LassoConfig(\n",
    "            feature=feature,\n",
    "            label=label,\n",
    "            cov=cov,\n",
    "            name=modelname,\n",
    "            type_measure=mmconfig.get(\"type_measure\", \"auc\"),\n",
    "            cv=mmconfig.get(\"cv\", 10),\n",
    "        ).to_json()\n",
    "        json_dir = model_output_folder / \"train_config.json\"\n",
    "        json.dump(lasso_config, open(json_dir, \"w\"))\n",
    "\n",
    "        model_save_dir = model_output_folder / \"model\"\n",
    "\n",
    "        # data save to\n",
    "        train_feather = (\n",
    "            dataconfig.data.merge(diseaseData[[\"eid\", label]], on=\"eid\", how=\"inner\")\n",
    "            .merge(phenosData[[\"eid\"] + cov], on=\"eid\", how=\"inner\")\n",
    "            .dropna(subset=[label])\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        tmp_train_feather_dir = model_output_folder / \"train.feather\"\n",
    "        ##################### rm ##################\n",
    "        train_feather = train_feather.head(10000)\n",
    "        ##################### rm ##################\n",
    "        print(f\"Train data shape: {train_feather.shape}\")\n",
    "\n",
    "        train_feather.to_feather(tmp_train_feather_dir)\n",
    "        ##################### rm ##################\n",
    "        if self.testdataconfig is not None:\n",
    "            if self.testdataconfig.data.eid.dtype != dataconfig.data.eid.dtype:\n",
    "                self.testdataconfig.data.eid = self.testdataconfig.data.eid.astype(\n",
    "                    dataconfig.data.eid.dtype\n",
    "                )\n",
    "\n",
    "            # merge disease data\n",
    "            test_feather = (\n",
    "                self.testdataconfig.data.merge(\n",
    "                    diseaseData[[\"eid\", label]], on=\"eid\", how=\"inner\"\n",
    "                ).dropna(subset=[label])\n",
    "            ).reset_index(drop=True)\n",
    "\n",
    "            # check cov in test data\n",
    "            # if not in, merge from phenos\n",
    "            to_merge_cols = []\n",
    "            for c in cov:\n",
    "                if c not in self.testdataconfig.data.columns:\n",
    "                    to_merge_cols.append(c)\n",
    "                    print(f\"Missing cov in test data: {c}\")\n",
    "\n",
    "            if len(to_merge_cols) > 0:\n",
    "                test_feather = test_feather.merge(\n",
    "                    phenosData[[\"eid\"] + to_merge_cols], on=\"eid\", how=\"inner\"\n",
    "                ).reset_index(drop=True)\n",
    "\n",
    "            tmp_test_feather_dir = model_output_folder / \"test.feather\"\n",
    "            test_feather = test_feather[train_feather.columns.tolist()]\n",
    "            print(f\"Test data shape: {test_feather.shape}\")\n",
    "            test_feather.to_feather(tmp_test_feather_dir)\n",
    "        else:\n",
    "            raise ValueError(\"Test data is not provided\")\n",
    "\n",
    "        # run single without random seed\n",
    "        single_lasso_output_folder = model_output_folder / \"single\"\n",
    "        run_glmnet(\n",
    "            json_dir=json_dir,\n",
    "            train_dir=tmp_train_feather_dir,\n",
    "            out_dir=single_lasso_output_folder,\n",
    "            test_dir=tmp_test_feather_dir if self.testdataconfig is not None else None,\n",
    "        )\n",
    "        if isinstance(n_bootstrap, int) and n_bootstrap > 1:\n",
    "            if self.testdataconfig is None:\n",
    "                raise ValueError(\n",
    "                    \"Test data is not provided, cannot run bootstrap to select best\"\n",
    "                )\n",
    "            # run bootstrap\n",
    "            bootstrap_output_folder = model_output_folder / \"bootstrap\"\n",
    "            from joblib import Parallel, delayed\n",
    "\n",
    "            res = Parallel(n_jobs=n_jobs)(\n",
    "                delayed(run_glmnet)(\n",
    "                    json_dir=json_dir,\n",
    "                    train_dir=tmp_train_feather_dir,\n",
    "                    out_dir=bootstrap_output_folder / f\"{i}\",\n",
    "                    test_dir=(\n",
    "                        tmp_test_feather_dir\n",
    "                        if self.testdataconfig is not None\n",
    "                        else None\n",
    "                    ),\n",
    "                    seed=i,\n",
    "                )\n",
    "                for i in range(1, n_bootstrap + 1)\n",
    "            )\n",
    "\n",
    "            # plot bootstrap\n",
    "            res = load_glmnet_bootstrap(bootstrap_output_folder)\n",
    "            coef = res[modelname][\"coef_df\"]\n",
    "            test_score = res[modelname][\"test_score\"]\n",
    "            ## save\n",
    "            coef.to_csv(bootstrap_output_folder / \"bootstrap_coef_df.csv\", index=True)\n",
    "            test_score.reset_index(drop=False).to_feather(\n",
    "                bootstrap_output_folder / \"test_score.feather\"\n",
    "            )\n",
    "\n",
    "            ## plot\n",
    "            fig = plt.figure(figsize=(15, 10))\n",
    "            gs = gridspec.GridSpec(2, 5, hspace=0.5, wspace=0.5, figure=fig)\n",
    "\n",
    "            ax1 = fig.add_subplot(gs[0, 0:2])\n",
    "            ax2 = fig.add_subplot(gs[0, 2:4])\n",
    "            ax3 = fig.add_subplot(gs[:, 4:])\n",
    "            ax4 = fig.add_subplot(gs[1, :4])\n",
    "\n",
    "            glmnet_bootsrap_result = GLMNETBootsrapResult(coef)\n",
    "            glmnet_bootsrap_result._show_models_coeffients(axes=[ax1, ax2])\n",
    "            glmnet_bootsrap_result._plot_top_k_features(ax=ax3)\n",
    "            ax3.yaxis.set_label_position(\"right\")\n",
    "            ax3.yaxis.tick_right()\n",
    "            glmnet_bootsrap_result.coef_barplot(ax=ax4)\n",
    "            fig.savefig(model_output_folder / \"bootstrap_coef_plot.png\")\n",
    "\n",
    "            # fit the passed\n",
    "            coef_mean = coef.mean(axis=1)\n",
    "            non_zero_features = coef_mean[coef_mean != 0].index.tolist()\n",
    "\n",
    "            # this time no need for cov\n",
    "            non_zero_features_lasso_config = LassoConfig(\n",
    "                feature=non_zero_features, label=label, cov=None, name=modelname\n",
    "            ).to_json()\n",
    "            non_zero_features_json_dir = (\n",
    "                model_output_folder / \"non_zero_features_train_config.json\"\n",
    "            )\n",
    "            json.dump(\n",
    "                non_zero_features_lasso_config, open(non_zero_features_json_dir, \"w\")\n",
    "            )\n",
    "\n",
    "            # run glmnet\n",
    "            non_zero_features_output_folder = model_output_folder / \"non_zero_features\"\n",
    "            run_glmnet(\n",
    "                json_dir=non_zero_features_json_dir,\n",
    "                train_dir=tmp_train_feather_dir,\n",
    "                out_dir=non_zero_features_output_folder,\n",
    "                test_dir=(\n",
    "                    tmp_test_feather_dir if self.testdataconfig is not None else None\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # compare them\n",
    "            score_dict = {}\n",
    "            single_test_score = load_data(\n",
    "                single_lasso_output_folder / modelname / \"test_score.csv\"\n",
    "            )\n",
    "            single_test_score.columns = [\"eid\", \"single\"]\n",
    "            score_dict[\"single\"] = single_test_score\n",
    "\n",
    "            bootstrap_test_score = load_data(\n",
    "                bootstrap_output_folder / \"test_score.feather\"\n",
    "            )\n",
    "            bootstrap_test_score[\"mean\"] = bootstrap_test_score.mean(axis=1)\n",
    "            bootstrap_test_score = bootstrap_test_score[[\"eid\", \"mean\"]]\n",
    "            score_dict[\"mean\"] = bootstrap_test_score\n",
    "\n",
    "            non_zero_features_test_score = load_data(\n",
    "                non_zero_features_output_folder / modelname / \"test_score.csv\"\n",
    "            )\n",
    "            non_zero_features_test_score.columns = [\"eid\", \"non_zero_features\"]\n",
    "            score_dict[\"non_zero_features\"] = non_zero_features_test_score\n",
    "\n",
    "            to_compare_df = (\n",
    "                test_feather[[\"eid\", label]]\n",
    "                .merge(single_test_score, on=\"eid\", how=\"inner\")\n",
    "                .merge(bootstrap_test_score, on=\"eid\", how=\"inner\")\n",
    "                .merge(non_zero_features_test_score, on=\"eid\", how=\"inner\")\n",
    "            )\n",
    "\n",
    "            to_compare_metrics = {}\n",
    "            from ppp_prediction.corr import cal_binary_metrics_bootstrap\n",
    "\n",
    "            for col in [\"single\", \"mean\", \"non_zero_features\"]:\n",
    "                to_cal = to_compare_df[[label, col]].dropna()\n",
    "                to_compare_metrics[col] = cal_binary_metrics_bootstrap(\n",
    "                    to_cal[label], to_cal[col], ci_kwargs={\"n_resamples\": 100}\n",
    "                )\n",
    "            to_compare_metrics = pd.DataFrame(to_compare_metrics).T.sort_values(\n",
    "                \"AUC\", ascending=False\n",
    "            )\n",
    "\n",
    "            to_compare_metrics.to_csv(\n",
    "                model_output_folder / \"compare_metrics.csv\", index=True\n",
    "            )\n",
    "\n",
    "            # extract best\n",
    "\n",
    "            best_model = to_compare_metrics.index[0]\n",
    "            best_model_score = score_dict[best_model]\n",
    "            best_model_score.to_csv(\n",
    "                model_output_folder / \"best_model_score.csv\", index=False\n",
    "            )\n",
    "\n",
    "            print(f\"Finished!\")\n",
    "        else:\n",
    "            shutil.copy(\n",
    "                single_lasso_output_folder / modelname / \"test_score.csv\",\n",
    "                model_output_folder / \"best_model_score.csv\",\n",
    "            )\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Params to pass by cmd\n",
    "outputFolder = \"test\"\n",
    "\n",
    "# defined in the json\n",
    "ukbData = \"MulitOmicsDisease/\"\n",
    "ProtTrainDir = f\"{ukbData}/traindata/Prot.feather\"\n",
    "MetaTrainDir = f\"{ukbData}/traindata/Meta.feather\"\n",
    "RFTrainDir = f\"{ukbData}/traindata/RF.feather\"\n",
    "heldOutDataDir = f\"{ukbData}/traindata/heldout.feather\"\n",
    "\n",
    "phenoDataDir = f\"{ukbData}/omicsData/phenos.feather\"\n",
    "diseaseDataDir = f\"{ukbData}/disease/T2D_Coding_Amit_NG2018.feather\"\n",
    "\n",
    "cov = [\"age\", \"sex\"]\n",
    "\n",
    "params_json = {\n",
    "    \"omicsData\": {\n",
    "        \"Prot\": {\n",
    "            \"name\": \"Prot\",\n",
    "            \"path\": MetaTrainDir,\n",
    "            \"feature\": None,\n",
    "        },\n",
    "        \"Meta\": {\n",
    "            \"name\": \"Meta\",\n",
    "            \"path\": MetaTrainDir,\n",
    "            \"feature\": None,\n",
    "        },\n",
    "        \"RF\": {\n",
    "            \"name\": \"RF\",\n",
    "            \"path\": RFTrainDir,\n",
    "            \"feature\": None,\n",
    "        },\n",
    "    },\n",
    "    \"heldOutData\": {\n",
    "        \"name\": \"heldOut\",\n",
    "        \"path\": heldOutDataDir,\n",
    "    },\n",
    "    \"diseaseData\": {\n",
    "        # \"name\": \"T2D_Coding_Amit_NG2018\",\n",
    "        \"path\": diseaseDataDir,\n",
    "        \"label\": \"event\",\n",
    "        \"date\": \"date\",\n",
    "    },\n",
    "    \"phenoData\": {\n",
    "        \"name\": \"phenos\",\n",
    "        \"path\": phenoDataDir,\n",
    "    },\n",
    "    \"modelConfig\": {\n",
    "        \"Prot\": {\n",
    "            \"name\": \"Prot\",  # name of the model for save\n",
    "            \"model\": [\"lasso\"],  # not work now\n",
    "            \"feature\": None,  # feature to use, None is all\n",
    "            \"cov\": cov,  # covariate to use\n",
    "            \"cv\": 10,\n",
    "            \"n_bootstrap\": 8,\n",
    "        },\n",
    "        \"Meta\": {\n",
    "            \"name\": \"Meta\",\n",
    "            \"model\": [\"lasso\"],\n",
    "            \"feature\": None,\n",
    "            \"cov\": cov,\n",
    "            \"cv\": 10,\n",
    "            \"n_bootstrap\": 8,\n",
    "        },\n",
    "        \"RF\": {\n",
    "            \"name\": \"RF\",\n",
    "            \"model\": [\"lasso\"],\n",
    "            \"feature\": None,\n",
    "            \"cov\": None,\n",
    "            \"cv\": 10,\n",
    "            \"n_bootstrap\": None,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OmicsDataDirDict = {k: DataConfig(**v) for k, v in params_json[\"omicsData\"].items()}\n",
    "heldOutDataDict = DataConfig(**params_json[\"heldOutData\"])\n",
    "diseaseDict = DataConfig(**params_json[\"diseaseData\"])\n",
    "phenosDataDict = DataConfig(**params_json[\"phenoData\"])\n",
    "modelconfig = {k: ModelConfig(**v) for k, v in params_json[\"modelConfig\"].items()}\n",
    "\n",
    "Config = {\n",
    "    \"omicsData\": OmicsDataDirDict,\n",
    "    \"heldOutData\": heldOutDataDict,\n",
    "    \"diseaseData\": diseaseDict,\n",
    "    \"phenosData\": phenosDataDict,\n",
    "    \"modelConfig\": modelconfig,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseaseDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OmicsDataDirDict = {\n",
    "#     \"Prot\": DataConfig(\n",
    "#         **{\n",
    "#             \"name\": \"Prot\",\n",
    "#             \"path\": ProtTrainDir,\n",
    "#             \"feature\": None,\n",
    "#         }\n",
    "#     ),\n",
    "#     \"Meta\": DataConfig(\n",
    "#         **{\n",
    "#             \"name\": \"Meta\",\n",
    "#             \"path\": MetaTrainDir,\n",
    "#             \"feature\": None,\n",
    "#         }\n",
    "#     ),\n",
    "# }\n",
    "\n",
    "# heldOutDataDict = DataConfig(\n",
    "#     **{\n",
    "#         \"name\": \"heldOut\",\n",
    "#         \"path\": heldOutDataDir,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# ## disease phenotype\n",
    "# ### eid should be the first column, event is the second column and time is the third column (optional)\n",
    "# diseaseDict = DataConfig(\n",
    "#     **{\n",
    "#         \"name\": \"CAD_xhv2_exclude_more\",\n",
    "#         \"path\": \"/home/xutingfeng/ukb/ukbData/phenotypes/ukb_ph/disease_extracted/AAA_from_renji/CAD_xhv2_exclude_more.csv\",\n",
    "#         \"label\": \"CAD_xhv2_exclude_more_event\",\n",
    "#         \"date\": \"CAD_xhv2_exclude_more_date\",\n",
    "#     }\n",
    "# )\n",
    "# ## covariates\n",
    "# ### eid should be the first column, and the rest are the covariates may need\n",
    "# phenosDataDict = DataConfig(\n",
    "#     **{\n",
    "#         \"name\": \"phenos\",\n",
    "#         \"path\": \"/home/xutingfeng/ukb/project/ppp_prediction/results/Meta_Prot/dataset/RF_training_df.feather\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# ## Model Config\n",
    "# ProtModelConfig = ModelConfig(\n",
    "#     **{\n",
    "#         \"name\": \"Prot\",\n",
    "#         \"model\": [\"lasso\"],\n",
    "#         \"feature\": None,\n",
    "#         \"cov\": [\"age\", \"sex\"],\n",
    "#     }\n",
    "# )\n",
    "# MetaModelConfig = ModelConfig(\n",
    "#     **{\n",
    "#         \"name\": \"Meta\",\n",
    "#         \"model\": [\"lasso\"],\n",
    "#         \"feature\": None,\n",
    "#         \"cov\": [\"age\", \"sex\"],\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# modelconfig = {\"Prot\": ProtModelConfig, \"Meta\": MetaModelConfig}\n",
    "# # Other Params\n",
    "\n",
    "# ## Other Omics Data\n",
    "# ### first col should be eid and left is the feature with no missing values (will drop them if missing, so impute first or if u really want to keep them)\n",
    "\n",
    "# # OtherOmicsDataDirDict.update()\n",
    "\n",
    "# # Config\n",
    "\n",
    "# Config = {\n",
    "#     \"omicsData\": OmicsDataDirDict,\n",
    "#     \"heldOutData\": heldOutDataDict,\n",
    "#     \"diseaseData\": diseaseDict,\n",
    "#     \"phenosData\": phenosDataDict,\n",
    "#     \"modelConfig\": modelconfig,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update output folder to diseasse name\n",
    "# outputFolder = Path(outputFolder) / diseaseDict.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_data\n",
    "\n",
    "for k in Config.keys():\n",
    "    if isinstance(Config[k], DataConfig):\n",
    "        Config[k].__load_data__()\n",
    "    elif k == \"omicsData\":\n",
    "        for omics in Config[\"omicsData\"]:\n",
    "            Config[\"omicsData\"][omics].__load_data__()\n",
    "    else:\n",
    "        print(f\"Skipping {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config[\"diseaseData\"].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_disease_dist(Config):\n",
    "#     # to_check_list = Config\n",
    "#     diseaseData = Config[\"diseaseData\"].data\n",
    "#     disease = Config[\"diseaseData\"].name\n",
    "#     disease_event_col = Config[\"diseaseData\"].label\n",
    "\n",
    "#     dist = {}\n",
    "#     for dataconfig in Config[\"omicsData\"].values():\n",
    "#         data_eids = dataconfig.data[[\"eid\"]].copy()\n",
    "#         dataname = dataconfig.name\n",
    "\n",
    "#         if data_eids.eid.dtype != diseaseData.eid.dtype:\n",
    "#             data_eids.eid = data_eids.eid.astype(diseaseData.eid.dtype)\n",
    "\n",
    "#         inner_data = diseaseData.merge(data_eids, on=\"eid\", how=\"inner\")[\n",
    "#             [disease_event_col]\n",
    "#         ]\n",
    "\n",
    "#         inner_data = inner_data.value_counts().to_dict()\n",
    "\n",
    "#         dist[dataname] = inner_data\n",
    "\n",
    "#     dataconfig = Config[\"heldOutData\"]\n",
    "#     data_eids = dataconfig.data[[\"eid\"]].copy()\n",
    "#     dataname = dataconfig.name\n",
    "\n",
    "#     if data_eids.eid.dtype != diseaseData.eid.dtype:\n",
    "#         data_eids.eid = data_eids.eid.astype(diseaseData.eid.dtype)\n",
    "\n",
    "#     inner_data = diseaseData.merge(data_eids, on=\"eid\", how=\"inner\")[\n",
    "#         [disease_event_col]\n",
    "#     ]\n",
    "\n",
    "#     inner_data = inner_data.value_counts().to_dict()\n",
    "\n",
    "#     dist[dataname] = inner_data\n",
    "\n",
    "#     dist_df = pd.DataFrame(dist)\n",
    "\n",
    "#     return dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df = check_disease_dist(Config)\n",
    "dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check features\n",
    "for mconfig in Config[\"modelConfig\"].values():\n",
    "    if mconfig[\"feature\"] is None:\n",
    "        # if mconfig[\"name\"] in [\"Prot\", \"Meta\"]:\n",
    "        mconfig[\"feature\"] = (\n",
    "            Config[\"omicsData\"][mconfig[\"name\"]].data.columns[1:].tolist()\n",
    "        )\n",
    "        print(f\"Set feature for {mconfig['name']}\")\n",
    "        # else:\n",
    "        #     raise ValueError(f\"Feature for {mconfig['name']} is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cov\n",
    "for mconfig in Config[\"modelConfig\"].values():\n",
    "    cov = mconfig[\"cov\"]\n",
    "    if cov is not None:\n",
    "        if Config[\"phenosData\"] is None:\n",
    "            raise ValueError(\n",
    "                f\"PhenosData is not set, while covariates are set for {mconfig['name']}\"\n",
    "            )\n",
    "        else:\n",
    "            for c in cov:\n",
    "                if c not in Config[\"phenosData\"].data.columns:\n",
    "                    raise ValueError(\n",
    "                        f\"cov of {mconfig['name']}, {c} not in phenosData columns\"\n",
    "                    )\n",
    "        for c in cov:\n",
    "            if c not in Config[\"heldOutData\"].data.columns:\n",
    "                raise ValueError(\n",
    "                    f\"cov of {mconfig['name']}, {c} not in heldOutData columns\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LassoConfig(object):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         feature,\n",
    "#         label,\n",
    "#         cov,\n",
    "#         name=\"lasso\",\n",
    "#         family=\"binomial\",\n",
    "#         lambda_=None,\n",
    "#         type_measure=\"auc\",\n",
    "#         cv=10,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         assert isinstance(label, str), \"label should be a string\"\n",
    "#         if cov is not None:\n",
    "#             if isinstance(cov, str):\n",
    "#                 cov = [cov]\n",
    "#             elif isinstance(cov, list):\n",
    "#                 if len(cov) == 0:\n",
    "#                     cov = None\n",
    "\n",
    "#         assert isinstance(feature, str) or isinstance(\n",
    "#             feature, list\n",
    "#         ), \"feature should be a string or a list\"\n",
    "#         self.config = {\n",
    "#             name: {\n",
    "#                 \"feature\": feature if isinstance(feature, list) else [feature],\n",
    "#                 \"label\": label,\n",
    "#                 \"time\": None,\n",
    "#                 \"cov\": cov,\n",
    "#                 \"family\": family,\n",
    "#                 \"lambda\": lambda_,\n",
    "#                 \"type_measure\": type_measure,\n",
    "#                 \"cv\": cv,\n",
    "#             }\n",
    "#         }\n",
    "#         if kwargs:\n",
    "#             # export them and warning not used\n",
    "#             print(f\"Warning: {kwargs} not used\")\n",
    "\n",
    "#     def to_json(self):\n",
    "#         return self.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_coef_scatter(data, coef, feature, k=6, ax=None, cmap=\"nejm\"):\n",
    "#     data = (\n",
    "#         data[[coef, feature]].copy().rename(columns={coef: \"coef\", feature: \"feature\"})\n",
    "#     )\n",
    "#     plt_data = (\n",
    "#         data.query(\"coef !=0\")\n",
    "#         .sort_values(\"coef\", ascending=False)\n",
    "#         .reset_index(drop=True)\n",
    "#         .reset_index(drop=False, names=[\"idx\"])\n",
    "#     )\n",
    "\n",
    "#     from adjustText import adjust_text\n",
    "\n",
    "#     if ax is None:\n",
    "#         fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "#     hue = \"coef\"\n",
    "#     y = \"coef\"\n",
    "#     name = \"feature\"\n",
    "#     plt_data = plt_data.query(\"feature != 'sex' & feature != 'age' \")\n",
    "\n",
    "#     # 计算每个点的颜色\n",
    "#     colors = plt_data[hue]\n",
    "#     min_value = max(abs(colors.min()), abs(colors.max()))\n",
    "#     norm = plt.Normalize(-min_value, min_value)\n",
    "#     sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "#     sm.set_array([])\n",
    "\n",
    "#     sc = ax.scatter(\n",
    "#         plt_data.index,\n",
    "#         plt_data[y],\n",
    "#         c=colors,\n",
    "#         cmap=cmap,\n",
    "#         s=30,\n",
    "#         # edgecolor=\"k\",\n",
    "#         zorder=3,\n",
    "#     )\n",
    "#     # cb = plt.colorbar(sm, ax=ax)\n",
    "\n",
    "#     # 设置标题和轴标签\n",
    "#     ax.set_title(\n",
    "#         f\"Mean Coefficient of {name} bootstrap model\", fontsize=16, fontweight=\"bold\"\n",
    "#     )\n",
    "#     ax.set_xlabel(\n",
    "#         \"\",\n",
    "#     )\n",
    "#     ax.set_ylabel(\"Mean Coefficient\", fontsize=14)\n",
    "#     ax.set_yticks([-min_value / 2, 0, min_value / 2])\n",
    "#     ax.spines[\"top\"].set_visible(False)\n",
    "#     ax.spines[\"right\"].set_visible(False)\n",
    "#     # 增加网格线\n",
    "#     ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.5)\n",
    "\n",
    "#     texts = [\n",
    "#         ax.text(\n",
    "#             idx,\n",
    "#             row[y],\n",
    "#             f\"{row[name]}\",\n",
    "#             ha=\"center\",\n",
    "#             va=\"bottom\",\n",
    "#             fontsize=8,\n",
    "#         )\n",
    "#         for idx, row in plt_data.head(k).iterrows()\n",
    "#     ] + [\n",
    "#         ax.text(\n",
    "#             idx,\n",
    "#             row[y],\n",
    "#             f\"{row[name]}\",\n",
    "#             ha=\"center\",\n",
    "#             va=\"top\",\n",
    "#             fontsize=8,\n",
    "#         )\n",
    "#         for idx, row in plt_data.tail(k).iterrows()\n",
    "#     ]\n",
    "#     adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle=\"->\", lw=0.5))\n",
    "\n",
    "\n",
    "# class GLMNETBootsrapResult(object):\n",
    "#     def __init__(self, bootstrap_coef_df):\n",
    "#         self.coef = bootstrap_coef_df\n",
    "#         self.features = self.coef.index.tolist()\n",
    "#         self._init_weights_dist()\n",
    "\n",
    "#     def _init_weights_dist(self):\n",
    "\n",
    "#         res = self.coef\n",
    "\n",
    "#         percent_of_nonZero_coefficients = (\n",
    "#             (res != 0).sum(axis=1) * 100 / len(res.columns)\n",
    "#         )\n",
    "#         mean_coefficients = res.mean(axis=1)\n",
    "#         weights_dist_df = pd.DataFrame(\n",
    "#             [percent_of_nonZero_coefficients, mean_coefficients],\n",
    "#             index=[\"percent_of_nonZero_coefficients\", \"mean_coefficients\"],\n",
    "#         ).T\n",
    "#         weights_dist_df[\"abs_mean_coefficients\"] = weights_dist_df[\n",
    "#             \"mean_coefficients\"\n",
    "#         ].abs()\n",
    "#         self.weights_dist_df = weights_dist_df\n",
    "\n",
    "#     def _plot_top_k_features(self, k=10, pallete=\"viridis\", ax=None, exclude=None):\n",
    "#         \"\"\"\n",
    "#         plot top k features\n",
    "#         \"\"\"\n",
    "\n",
    "#         if ax is None:\n",
    "#             fig, ax = plt.subplots(1, 1, figsize=(5, k))\n",
    "\n",
    "#         if isinstance(exclude, str):\n",
    "#             exclude = [exclude]\n",
    "\n",
    "#         if exclude is not None:\n",
    "#             plt_data = self.coef.loc[self.coef.index.difference(exclude), :]\n",
    "\n",
    "#             top_k_features = self.weights_dist_df\n",
    "#             top_k_features = top_k_features.loc[\n",
    "#                 top_k_features.index.difference(exclude), :\n",
    "#             ].sort_values(\n",
    "#                 by=[\"mean_coefficients\"],\n",
    "#                 ascending=False,\n",
    "#             )\n",
    "#         else:\n",
    "#             plt_data = self.coef\n",
    "#             top_k_features = self.weights_dist_df.sort_values(\n",
    "#                 by=[\"mean_coefficients\"],\n",
    "#                 ascending=False,\n",
    "#             )\n",
    "\n",
    "#         plt_data = plt_data.loc[\n",
    "#             [*top_k_features.index[:k], *top_k_features.index[-k:]], :\n",
    "#         ]\n",
    "#         idx_name = plt_data.index.name\n",
    "#         plt_data = plt_data.reset_index(drop=False).melt(id_vars=idx_name)\n",
    "\n",
    "#         sns.boxplot(\n",
    "#             data=plt_data,\n",
    "#             y=idx_name,\n",
    "#             x=\"value\",\n",
    "#             showfliers=False,\n",
    "#             ax=ax,\n",
    "#             palette=pallete,\n",
    "#         )\n",
    "#         ax.set_xticks([0.0])\n",
    "#         ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=10)\n",
    "\n",
    "#         ax.grid(axis=\"x\", linestyle=\"--\", alpha=1, linewidth=2, color=\"red\")\n",
    "#         ax.set_xlabel(\"Mean of Coefficients\")\n",
    "#         ax.set_ylabel(\"Features\")\n",
    "#         ax.set_title(f\"Top {k} Features\")\n",
    "#         return ax\n",
    "\n",
    "#     def _show_models_coeffients(self, axes=None, color=\"#d67b7f\", top=5, exclude=None):\n",
    "#         \"\"\"\n",
    "#         res:\n",
    "#             model1 model2\n",
    "#         SOST xx yy\n",
    "#         BGN xx yy\n",
    "\n",
    "\n",
    "#         \"\"\"\n",
    "#         if self.coef is None:\n",
    "#             self.coef = self._init_coeffeients_df()\n",
    "#         res = self.coef\n",
    "\n",
    "#         # exclude = self.cov if exclude is None else exclude + self.cov\n",
    "#         if exclude:\n",
    "#             if isinstance(exclude, str):\n",
    "#                 exclude = [exclude]\n",
    "#             res = res.loc[res.index.difference(exclude), :]\n",
    "\n",
    "#         if axes is None:\n",
    "#             fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#         else:\n",
    "#             assert len(axes) == 2, \"axes should be a list of length 2\"\n",
    "#             ax1, ax2 = axes\n",
    "\n",
    "#         percent_of_nonZero_coefficients = (\n",
    "#             (res != 0).sum(axis=1) * 100 / len(res.columns)\n",
    "#         )\n",
    "#         mean_coefficients = res.mean(axis=1)\n",
    "#         plt_data = pd.DataFrame(\n",
    "#             [percent_of_nonZero_coefficients, mean_coefficients],\n",
    "#             index=[\"percent_of_nonZero_coefficients\", \"mean_coefficients\"],\n",
    "#         ).T\n",
    "#         plt_data[\"abs_mean_coefficients\"] = plt_data[\"mean_coefficients\"].abs()\n",
    "\n",
    "#         # ax1\n",
    "#         sns.scatterplot(\n",
    "#             x=percent_of_nonZero_coefficients,\n",
    "#             y=mean_coefficients,\n",
    "#             size=mean_coefficients,\n",
    "#             sizes=(20, 400),\n",
    "#             legend=False,\n",
    "#             edgecolor=\"black\",\n",
    "#             ax=ax1,\n",
    "#             color=color,\n",
    "#         )\n",
    "#         ax1.plot([0, 100], [0, 0], \"k--\", lw=3, color=\"grey\")\n",
    "#         ax1.set_xlim(-1, 105)\n",
    "#         ax1.set_xlabel(\"percent of non-zero coefficients\")\n",
    "#         ax1.set_ylabel(\"mean nonzero coefficients\")\n",
    "#         sorted_plt_data = (\n",
    "#             plt_data.sort_values(\n",
    "#                 by=[\"percent_of_nonZero_coefficients\", \"abs_mean_coefficients\"],\n",
    "#                 ascending=False,\n",
    "#             )\n",
    "#             .iloc[:top, :]\n",
    "#             .index\n",
    "#         )\n",
    "#         for i, txt in enumerate(sorted_plt_data):\n",
    "#             # ax1.annotate(txt, (sorted_plt_data.iloc[i, 0], sorted_plt_data.iloc[i, 1]))\n",
    "#             ax1.text(\n",
    "#                 plt_data.loc[txt, \"percent_of_nonZero_coefficients\"],\n",
    "#                 plt_data.loc[txt, \"mean_coefficients\"],\n",
    "#                 txt,\n",
    "#                 ha=\"right\",\n",
    "#                 fontsize=8,\n",
    "#                 color=\"black\",\n",
    "#             )\n",
    "\n",
    "#         # ax2\n",
    "#         absolute_mean_coefficients = mean_coefficients.abs().sort_values(ascending=True)\n",
    "#         sns.barplot(\n",
    "#             y=absolute_mean_coefficients,\n",
    "#             x=absolute_mean_coefficients.index,\n",
    "#             ax=ax2,\n",
    "#             color=color,\n",
    "#         )\n",
    "#         ax2.set_ylabel(\"absolute mean coefficients\")\n",
    "#         ax2.set_xlabel(\"\")\n",
    "#         xticks = ax2.get_xticklabels()\n",
    "#         if len(xticks) > 100:\n",
    "#             ax2.set_xticks([\"\"] * len(xticks))\n",
    "#         else:\n",
    "#             ax2.set_xticklabels(ax2.get_xticklabels(), rotation=90)\n",
    "#         if axes is None:\n",
    "#             # fig.tight_layout()\n",
    "#             return ax1, ax2\n",
    "\n",
    "#     def coef_barplot(\n",
    "#         self,\n",
    "#         cmap=\"RdBu_r\",\n",
    "#         k=10,\n",
    "#         ax=None,\n",
    "#         errorbar_kwargs=None,\n",
    "#         scatter_kwargs=None,\n",
    "#         exclude=[\"age\", \"sex\"],\n",
    "#     ):\n",
    "#         from adjustText import adjust_text\n",
    "#         from scipy import stats\n",
    "\n",
    "#         if errorbar_kwargs is None:\n",
    "#             errorbar_kwargs = {}\n",
    "#         if scatter_kwargs is None:\n",
    "#             scatter_kwargs = {}\n",
    "\n",
    "#         plt_data = self.coef.copy()\n",
    "\n",
    "#         def cal_ci(x):\n",
    "#             mean_x = x.mean()\n",
    "#             scale = stats.sem(x)\n",
    "#             ci_low, ci_high = stats.t.interval(\n",
    "#                 0.95, len(x) - 1, loc=mean_x, scale=scale\n",
    "#             )\n",
    "#             return {\"mean\": mean_x, \"ci_low\": ci_low, \"ci_high\": ci_high}\n",
    "\n",
    "#         # drop age sex\n",
    "\n",
    "#         # exclude = self.cov if exclude is None else exclude + self.cov\n",
    "#         if isinstance(exclude, str):\n",
    "#             exclude = [exclude]\n",
    "\n",
    "#         plt_data = plt_data.loc[[i not in exclude for i in plt_data.index.tolist()]]\n",
    "\n",
    "#         plt_data = plt_data.apply(\n",
    "#             lambda x: pd.Series(cal_ci(x)),\n",
    "#             axis=1,\n",
    "#         )\n",
    "#         plt_data = plt_data.sort_values(\"mean\", ascending=False).reset_index(\n",
    "#             drop=False, names=\"feature\"\n",
    "#         )\n",
    "#         if ax is None:\n",
    "#             fig, ax = plt.subplots(figsize=(12, 4))\n",
    "#         plt_data[\"error_low\"] = plt_data[\"mean\"] - plt_data[\"ci_low\"]\n",
    "#         plt_data[\"error_high\"] = plt_data[\"ci_high\"] - plt_data[\"mean\"]\n",
    "\n",
    "#         # 绘制误差线\n",
    "\n",
    "#         ax.errorbar(\n",
    "#             x=plt_data.index,\n",
    "#             y=plt_data[\"mean\"],\n",
    "#             yerr=[\n",
    "#                 plt_data[\"mean\"] - plt_data.ci_low,\n",
    "#                 plt_data.ci_high - plt_data[\"mean\"],\n",
    "#             ],\n",
    "#             fmt=errorbar_kwargs.pop(\"fmt\", \"none\"),  # 不使用标记\n",
    "#             lw=errorbar_kwargs.pop(\"lw\", 1),\n",
    "#             capsize=errorbar_kwargs.pop(\"capsize\", 2),\n",
    "#             ecolor=errorbar_kwargs.pop(\"ecolor\", \"lightgrey\"),  # 将误差线设置为浅灰色\n",
    "#             **errorbar_kwargs,\n",
    "#         )\n",
    "\n",
    "#         # 使用scatter添加颜色渐变的散点\n",
    "#         # 计算每个点的颜色\n",
    "#         colors = plt_data[\"mean\"]\n",
    "#         min_value = max(abs(colors.min()), abs(colors.max()))\n",
    "#         norm = plt.Normalize(-min_value, min_value)\n",
    "#         sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "#         sm.set_array([])\n",
    "\n",
    "#         sc = ax.scatter(\n",
    "#             plt_data.index,\n",
    "#             plt_data[\"mean\"],\n",
    "#             c=colors,\n",
    "#             cmap=cmap,\n",
    "#             s=scatter_kwargs.pop(\"s\", 5),\n",
    "#             # edgecolor=\"k\",\n",
    "#             zorder=scatter_kwargs.pop(\"zorder\", 3),\n",
    "#             **scatter_kwargs,\n",
    "#         )\n",
    "#         cb = plt.colorbar(sm, ax=ax)\n",
    "\n",
    "#         # 设置标题和轴标签\n",
    "#         ax.set_title(\n",
    "#             \"Mean Coefficient of bootstrap model\", fontsize=16, fontweight=\"bold\"\n",
    "#         )\n",
    "#         ax.set_xlabel(\n",
    "#             \"\",\n",
    "#         )\n",
    "#         ax.set_ylabel(\"Mean Coefficient\", fontsize=14)\n",
    "#         ax.set_yticks([-min_value / 2, 0, min_value / 2])\n",
    "#         ax.set_xticks([])\n",
    "#         ax.spines[\"top\"].set_visible(False)\n",
    "#         ax.spines[\"right\"].set_visible(False)\n",
    "#         # 增加网格线\n",
    "#         ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.5)\n",
    "\n",
    "#         texts = [\n",
    "#             ax.text(\n",
    "#                 idx,\n",
    "#                 row[\"mean\"] + row[\"error_high\"],\n",
    "#                 f\"{row['feature']}\",\n",
    "#                 ha=\"center\",\n",
    "#                 va=\"bottom\",\n",
    "#                 fontsize=8,\n",
    "#             )\n",
    "#             for idx, row in plt_data.head(k).iterrows()\n",
    "#         ] + [\n",
    "#             ax.text(\n",
    "#                 idx,\n",
    "#                 row[\"mean\"] - row[\"error_low\"],\n",
    "#                 f\"{row['feature']}\",\n",
    "#                 ha=\"center\",\n",
    "#                 va=\"top\",\n",
    "#                 fontsize=8,\n",
    "#             )\n",
    "#             for idx, row in plt_data.tail(k).iterrows()\n",
    "#         ]\n",
    "#         adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle=\"->\", lw=0.5))\n",
    "\n",
    "#         return ax\n",
    "\n",
    "\n",
    "# # from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# def load_glmnet_bootstrap(model_dir):\n",
    "#     \"\"\"\n",
    "#     dir/\n",
    "#         1/Meta/\n",
    "#             coef_df.csv\n",
    "#             train_score.csv\n",
    "#             test_score.csv\n",
    "#         1/Prot/\n",
    "#             coef_df.csv\n",
    "#             train_score.csv\n",
    "#             test_score.csv\n",
    "#         2/Meta/\n",
    "#         ...\n",
    "#     \"\"\"\n",
    "\n",
    "#     model_dir = Path(model_dir)\n",
    "\n",
    "#     coef_df_name = \"coef_df.csv\"\n",
    "#     train_score = \"train_score.csv\"\n",
    "#     test_score = \"test_score.csv\"\n",
    "\n",
    "#     from collections import defaultdict\n",
    "\n",
    "#     res = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "#     found_csvs = list(model_dir.rglob(\"*.csv\"))\n",
    "#     for file_dir in found_csvs:\n",
    "#         if file_dir.parent == model_dir:\n",
    "#             continue\n",
    "#         filename = file_dir.stem\n",
    "#         submodelname = file_dir.parent.name\n",
    "#         seed = file_dir.parent.parent.name\n",
    "#         file = pd.read_csv(file_dir)\n",
    "#         if filename == \"coef_df\":\n",
    "#             file.columns = [\"feature\", f\"coef_{seed}\"]\n",
    "#             file.set_index(\"feature\", inplace=True)\n",
    "#         elif filename == \"train_score\":\n",
    "#             continue\n",
    "#         else:\n",
    "\n",
    "#             file.rename(columns={\"pred\": f\"pred_{seed}\"}, inplace=True)\n",
    "#             file.set_index(\"eid\", inplace=True)\n",
    "\n",
    "#         res[submodelname][filename].append(file)\n",
    "\n",
    "#     for submodelname in res.keys():\n",
    "#         for subcsv in res[submodelname].keys():\n",
    "#             # first = res[submodelname][subcsv][0].iloc[:, [0]]\n",
    "#             merged = pd.concat(res[submodelname][subcsv], axis=1)\n",
    "#             res[submodelname][subcsv] = merged\n",
    "\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import subprocess\n",
    "# import shutil\n",
    "# import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "# def run_glmnet(\n",
    "#     json_dir,\n",
    "#     train_dir,\n",
    "#     out_dir,\n",
    "#     test_dir=None,\n",
    "#     seed=None,\n",
    "# ):\n",
    "\n",
    "#     if shutil.which(\"run_glmnet.R\") is None:\n",
    "#         raise ValueError(\"run_glmnet.R is not in the PATH\")\n",
    "\n",
    "#     cmd = f\"run_glmnet.R --json {json_dir} --train {train_dir} --out {out_dir}\"\n",
    "#     if test_dir is not None:\n",
    "#         cmd += f\" --test {test_dir}\"\n",
    "#     if seed is not None:\n",
    "#         cmd += f\" --seed {seed}\"\n",
    "#     print(cmd)\n",
    "#     subprocess.run(cmd, shell=True)\n",
    "#     return subprocess\n",
    "\n",
    "\n",
    "# class LassoTrainTFPipline(object):\n",
    "#     def __init__(\n",
    "#         self, mmconfig, dataconfig, tgtconfig, phenoconfig, testdataconfig=None\n",
    "#     ):\n",
    "#         \"\"\" \"\"\"\n",
    "#         self.mmconfig = mmconfig\n",
    "#         self.dataconfig = dataconfig\n",
    "#         self.tgtconfig = tgtconfig\n",
    "#         self.phenoconfig = phenoconfig\n",
    "#         self.testdataconfig = testdataconfig\n",
    "\n",
    "#     def run(self, n_bootstrap=200, n_jobs=4, outputFolder=\"./out\"):\n",
    "#         # simple lasso\n",
    "#         mmconfig = self.mmconfig\n",
    "#         dataconfig = self.dataconfig\n",
    "#         tgtconfig = self.tgtconfig\n",
    "#         phenoconfig = self.phenoconfig\n",
    "#         outputFolder = Path(outputFolder)\n",
    "\n",
    "#         label = tgtconfig.label\n",
    "#         diseaseData = tgtconfig.data\n",
    "\n",
    "#         phenosData = phenoconfig.data\n",
    "\n",
    "#         model_list = mmconfig[\"model\"]\n",
    "#         modelname = mmconfig[\"name\"]\n",
    "#         feature = mmconfig[\"feature\"]\n",
    "#         cov = mmconfig[\"cov\"] if mmconfig[\"cov\"] is not None else []\n",
    "\n",
    "#         # copy data\n",
    "#         used_pheno_data = phenosData[[\"eid\"] + cov].copy()\n",
    "#         used_dis_data = diseaseData[[\"eid\", label]].copy()\n",
    "\n",
    "#         # check eid dtype\n",
    "\n",
    "#         if used_pheno_data.eid.dtype != dataconfig.data.eid.dtype:\n",
    "#             used_pheno_data.eid = used_pheno_data.eid.astype(dataconfig.data.eid.dtype)\n",
    "#         if used_dis_data.eid.dtype != dataconfig.data.eid.dtype:\n",
    "#             used_dis_data.eid = used_dis_data.eid.astype(dataconfig.data.eid.dtype)\n",
    "\n",
    "#         # check output\n",
    "#         model_output_folder = outputFolder / modelname\n",
    "#         model_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "#         # lasso\n",
    "#         lasso_config = LassoConfig(\n",
    "#             feature=feature,\n",
    "#             label=label,\n",
    "#             cov=cov,\n",
    "#             name=modelname,\n",
    "#             type_measure=mmconfig.get(\"type_measure\", \"auc\"),\n",
    "#             cv=mmconfig.get(\"cv\", 10),\n",
    "#         ).to_json()\n",
    "#         json_dir = model_output_folder / \"train_config.json\"\n",
    "#         json.dump(lasso_config, open(json_dir, \"w\"))\n",
    "\n",
    "#         model_save_dir = model_output_folder / \"model\"\n",
    "\n",
    "#         # data save to\n",
    "#         train_feather = (\n",
    "#             dataconfig.data.merge(diseaseData[[\"eid\", label]], on=\"eid\", how=\"inner\")\n",
    "#             .merge(phenosData[[\"eid\"] + cov], on=\"eid\", how=\"inner\")\n",
    "#             .dropna(subset=[label])\n",
    "#         ).reset_index(drop=True)\n",
    "\n",
    "#         tmp_train_feather_dir = model_output_folder / \"train.feather\"\n",
    "#         ##################### rm ##################\n",
    "#         train_feather = train_feather.head(10000)\n",
    "#         ##################### rm ##################\n",
    "#         print(f\"Train data shape: {train_feather.shape}\")\n",
    "\n",
    "#         train_feather.to_feather(tmp_train_feather_dir)\n",
    "#         ##################### rm ##################\n",
    "#         if self.testdataconfig is not None:\n",
    "#             if self.testdataconfig.data.eid.dtype != dataconfig.data.eid.dtype:\n",
    "#                 self.testdataconfig.data.eid = self.testdataconfig.data.eid.astype(\n",
    "#                     dataconfig.data.eid.dtype\n",
    "#                 )\n",
    "\n",
    "#             # merge disease data\n",
    "#             test_feather = (\n",
    "#                 self.testdataconfig.data.merge(\n",
    "#                     diseaseData[[\"eid\", label]], on=\"eid\", how=\"inner\"\n",
    "#                 ).dropna(subset=[label])\n",
    "#             ).reset_index(drop=True)\n",
    "\n",
    "#             # check cov in test data\n",
    "#             # if not in, merge from phenos\n",
    "#             to_merge_cols = []\n",
    "#             for c in cov:\n",
    "#                 if c not in self.testdataconfig.data.columns:\n",
    "#                     to_merge_cols.append(c)\n",
    "#                     print(f\"Missing cov in test data: {c}\")\n",
    "\n",
    "#             if len(to_merge_cols) > 0:\n",
    "#                 test_feather = test_feather.merge(\n",
    "#                     phenosData[[\"eid\"] + to_merge_cols], on=\"eid\", how=\"inner\"\n",
    "#                 ).reset_index(drop=True)\n",
    "\n",
    "#             tmp_test_feather_dir = model_output_folder / \"test.feather\"\n",
    "#             test_feather = test_feather[train_feather.columns.tolist()]\n",
    "#             print(f\"Test data shape: {test_feather.shape}\")\n",
    "#             test_feather.to_feather(tmp_test_feather_dir)\n",
    "#         else:\n",
    "#             raise ValueError(\"Test data is not provided\")\n",
    "\n",
    "#         # run single without random seed\n",
    "#         single_lasso_output_folder = model_output_folder / \"single\"\n",
    "#         run_glmnet(\n",
    "#             json_dir=json_dir,\n",
    "#             train_dir=tmp_train_feather_dir,\n",
    "#             out_dir=single_lasso_output_folder,\n",
    "#             test_dir=tmp_test_feather_dir if self.testdataconfig is not None else None,\n",
    "#         )\n",
    "#         if isinstance(n_bootstrap, int) and n_bootstrap > 1:\n",
    "#             if self.testdataconfig is None:\n",
    "#                 raise ValueError(\n",
    "#                     \"Test data is not provided, cannot run bootstrap to select best\"\n",
    "#                 )\n",
    "#             # run bootstrap\n",
    "#             bootstrap_output_folder = model_output_folder / \"bootstrap\"\n",
    "#             from joblib import Parallel, delayed\n",
    "\n",
    "#             res = Parallel(n_jobs=n_jobs)(\n",
    "#                 delayed(run_glmnet)(\n",
    "#                     json_dir=json_dir,\n",
    "#                     train_dir=tmp_train_feather_dir,\n",
    "#                     out_dir=bootstrap_output_folder / f\"{i}\",\n",
    "#                     test_dir=(\n",
    "#                         tmp_test_feather_dir\n",
    "#                         if self.testdataconfig is not None\n",
    "#                         else None\n",
    "#                     ),\n",
    "#                     seed=i,\n",
    "#                 )\n",
    "#                 for i in range(1, n_bootstrap + 1)\n",
    "#             )\n",
    "\n",
    "#             # plot bootstrap\n",
    "#             res = load_glmnet_bootstrap(bootstrap_output_folder)\n",
    "#             coef = res[modelname][\"coef_df\"]\n",
    "#             test_score = res[modelname][\"test_score\"]\n",
    "#             ## save\n",
    "#             coef.to_csv(bootstrap_output_folder / \"bootstrap_coef_df.csv\", index=True)\n",
    "#             test_score.reset_index(drop=False).to_feather(\n",
    "#                 bootstrap_output_folder / \"test_score.feather\"\n",
    "#             )\n",
    "\n",
    "#             ## plot\n",
    "#             fig = plt.figure(figsize=(15, 10))\n",
    "#             gs = gridspec.GridSpec(2, 5, hspace=0.5, wspace=0.5, figure=fig)\n",
    "\n",
    "#             ax1 = fig.add_subplot(gs[0, 0:2])\n",
    "#             ax2 = fig.add_subplot(gs[0, 2:4])\n",
    "#             ax3 = fig.add_subplot(gs[:, 4:])\n",
    "#             ax4 = fig.add_subplot(gs[1, :4])\n",
    "\n",
    "#             glmnet_bootsrap_result = GLMNETBootsrapResult(coef)\n",
    "#             glmnet_bootsrap_result._show_models_coeffients(axes=[ax1, ax2])\n",
    "#             glmnet_bootsrap_result._plot_top_k_features(ax=ax3)\n",
    "#             ax3.yaxis.set_label_position(\"right\")\n",
    "#             ax3.yaxis.tick_right()\n",
    "#             glmnet_bootsrap_result.coef_barplot(ax=ax4)\n",
    "#             fig.savefig(model_output_folder / \"bootstrap_coef_plot.png\")\n",
    "\n",
    "#             # fit the passed\n",
    "#             coef_mean = coef.mean(axis=1)\n",
    "#             non_zero_features = coef_mean[coef_mean != 0].index.tolist()\n",
    "\n",
    "#             # this time no need for cov\n",
    "#             non_zero_features_lasso_config = LassoConfig(\n",
    "#                 feature=non_zero_features, label=label, cov=None, name=modelname\n",
    "#             ).to_json()\n",
    "#             non_zero_features_json_dir = (\n",
    "#                 model_output_folder / \"non_zero_features_train_config.json\"\n",
    "#             )\n",
    "#             json.dump(\n",
    "#                 non_zero_features_lasso_config, open(non_zero_features_json_dir, \"w\")\n",
    "#             )\n",
    "\n",
    "#             # run glmnet\n",
    "#             non_zero_features_output_folder = model_output_folder / \"non_zero_features\"\n",
    "#             run_glmnet(\n",
    "#                 json_dir=non_zero_features_json_dir,\n",
    "#                 train_dir=tmp_train_feather_dir,\n",
    "#                 out_dir=non_zero_features_output_folder,\n",
    "#                 test_dir=(\n",
    "#                     tmp_test_feather_dir if self.testdataconfig is not None else None\n",
    "#                 ),\n",
    "#             )\n",
    "\n",
    "#             # compare them\n",
    "#             score_dict = {}\n",
    "#             single_test_score = load_data(\n",
    "#                 single_lasso_output_folder / modelname / \"test_score.csv\"\n",
    "#             )\n",
    "#             single_test_score.columns = [\"eid\", \"single\"]\n",
    "#             score_dict[\"single\"] = single_test_score\n",
    "\n",
    "#             bootstrap_test_score = load_data(\n",
    "#                 bootstrap_output_folder / \"test_score.feather\"\n",
    "#             )\n",
    "#             bootstrap_test_score[\"mean\"] = bootstrap_test_score.mean(axis=1)\n",
    "#             bootstrap_test_score = bootstrap_test_score[[\"eid\", \"mean\"]]\n",
    "#             score_dict[\"mean\"] = bootstrap_test_score\n",
    "\n",
    "#             non_zero_features_test_score = load_data(\n",
    "#                 non_zero_features_output_folder / modelname / \"test_score.csv\"\n",
    "#             )\n",
    "#             non_zero_features_test_score.columns = [\"eid\", \"non_zero_features\"]\n",
    "#             score_dict[\"non_zero_features\"] = non_zero_features_test_score\n",
    "\n",
    "#             to_compare_df = (\n",
    "#                 test_feather[[\"eid\", label]]\n",
    "#                 .merge(single_test_score, on=\"eid\", how=\"inner\")\n",
    "#                 .merge(bootstrap_test_score, on=\"eid\", how=\"inner\")\n",
    "#                 .merge(non_zero_features_test_score, on=\"eid\", how=\"inner\")\n",
    "#             )\n",
    "\n",
    "#             to_compare_metrics = {}\n",
    "#             from ppp_prediction.corr import cal_binary_metrics_bootstrap\n",
    "\n",
    "#             for col in [\"single\", \"mean\", \"non_zero_features\"]:\n",
    "#                 to_cal = to_compare_df[[label, col]].dropna()\n",
    "#                 to_compare_metrics[col] = cal_binary_metrics_bootstrap(\n",
    "#                     to_cal[label], to_cal[col], ci_kwargs={\"n_resamples\": 100}\n",
    "#                 )\n",
    "#             to_compare_metrics = pd.DataFrame(to_compare_metrics).T.sort_values(\n",
    "#                 \"AUC\", ascending=False\n",
    "#             )\n",
    "\n",
    "#             to_compare_metrics.to_csv(\n",
    "#                 model_output_folder / \"compare_metrics.csv\", index=True\n",
    "#             )\n",
    "\n",
    "#             # extract best\n",
    "\n",
    "#             best_model = to_compare_metrics.index[0]\n",
    "#             best_model_score = score_dict[best_model]\n",
    "#             best_model_score.to_csv(\n",
    "#                 model_output_folder / \"best_model_score.csv\", index=False\n",
    "#             )\n",
    "\n",
    "#             print(f\"Finished!\")\n",
    "#         else:\n",
    "#             shutil.copy(\n",
    "#                 single_lasso_output_folder / modelname / \"test_score.csv\",\n",
    "#                 model_output_folder / \"best_model_score.csv\",\n",
    "#             )\n",
    "#             return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmconfig = Config[\"modelConfig\"][\"Meta\"]\n",
    "dataconfig = Config[\"omicsData\"][\"Meta\"]\n",
    "tgtconfig = Config[\"diseaseData\"]\n",
    "phenoconfig = Config[\"phenosData\"]\n",
    "testconfig = Config[\"heldOutData\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RF\n",
      "Train data shape: (10000, 12)\n",
      "Test data shape: (28000, 12)\n",
      "run_glmnet.R --json test/T2D_Coding_Amit_NG2018/RF/train_config.json --train test/T2D_Coding_Amit_NG2018/RF/train.feather --out test/T2D_Coding_Amit_NG2018/RF/single --test test/T2D_Coding_Amit_NG2018/RF/test.feather\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded glmnet 4.1-8\n",
      "\n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$train\n",
      "[1] \"test/T2D_Coding_Amit_NG2018/RF/train.feather\"\n",
      "\n",
      "$test\n",
      "[1] \"test/T2D_Coding_Amit_NG2018/RF/test.feather\"\n",
      "\n",
      "$json\n",
      "[1] \"test/T2D_Coding_Amit_NG2018/RF/train_config.json\"\n",
      "\n",
      "$output\n",
      "[1] \"test/T2D_Coding_Amit_NG2018/RF/single\"\n",
      "\n",
      "$help\n",
      "[1] FALSE\n",
      "\n",
      "[1] \"train data size: 10000\"\n",
      "[1] \"json_file have keys: 1\"\n",
      "[1] \"Processing RF\"\n",
      "[1] TRUE\n",
      "[1] \"train data size: 9998 with featuers 10\"\n",
      "Training\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "executing %dopar% sequentially: no parallel backend registered \n"
     ]
    }
   ],
   "source": [
    "tgtconfig = Config[\"diseaseData\"]\n",
    "phenoconfig = Config[\"phenosData\"]\n",
    "testconfig = Config[\"heldOutData\"]\n",
    "for omics in Config[\"omicsData\"].keys():\n",
    "    if omics != \"RF\":\n",
    "        continue\n",
    "    assert omics in Config[\"modelConfig\"].keys(), f\"{omics} not in model config\"\n",
    "    mmconfig = Config[\"modelConfig\"][omics]\n",
    "    dataconfig = Config[\"omicsData\"][omics]\n",
    "    print(f\"Running {omics}\")\n",
    "    LassoTrainTFPipline(\n",
    "        mmconfig=mmconfig,\n",
    "        dataconfig=dataconfig,\n",
    "        tgtconfig=tgtconfig,\n",
    "        phenoconfig=phenoconfig,\n",
    "        testdataconfig=testconfig,\n",
    "    ).run(\n",
    "        outputFolder=f\"./test/{tgtconfig.name}\",\n",
    "        n_bootstrap=mmconfig.get(\"n_bootstrap\", None),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_feather(\n",
    "    \"/home/xutingfeng/ukb/project/ppp_prediction/test/T2D_Coding_Amit_NG2018/Meta/test.feather\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseaseDict.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "mmconfig = Config[\"modelConfig\"][\"Meta\"]\n",
    "dataconfig = Config[\"omicsData\"][\"Meta\"]\n",
    "label = Config[\"diseaseData\"].label\n",
    "diseaseData = Config[\"diseaseData\"].data\n",
    "phenoData = Config[\"phenosData\"].data\n",
    "n_bootstrap = 100\n",
    "\n",
    "model_list = mmconfig.model\n",
    "modelname = mmconfig.name\n",
    "feature = mmconfig.feature\n",
    "cov = mmconfig.cov\n",
    "\n",
    "# copy data\n",
    "used_pheno_data = phenoData[[\"eid\"] + cov].copy()\n",
    "used_dis_data = diseaseData[[\"eid\", label]].copy()\n",
    "\n",
    "# check eid dtype\n",
    "if used_pheno_data.eid.dtype != dataconfig.data.eid.dtype:\n",
    "    used_pheno_data.eid = used_pheno_data.eid.astype(dataconfig.data.eid.dtype)\n",
    "if used_dis_data.eid.dtype != dataconfig.data.eid.dtype:\n",
    "    used_dis_data.eid = used_dis_data.eid.astype(dataconfig.data.eid.dtype)\n",
    "\n",
    "# check output\n",
    "model_output_folder = outputFolder / modelname\n",
    "model_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "# lasso\n",
    "lasso_config = LassoConfig(\n",
    "    feature=feature, label=Config[\"diseaseData\"].label, cov=cov, name=modelname\n",
    ").to_json()\n",
    "json_dir = model_output_folder / \"train_config.json\"\n",
    "json.dump(lasso_config, open(json_dir, \"w\"))\n",
    "\n",
    "model_save_dir = model_output_folder / \"model\"\n",
    "\n",
    "# data save to\n",
    "train_feather = (\n",
    "    dataconfig.data.merge(diseaseData[[\"eid\", label]], on=\"eid\", how=\"inner\")\n",
    "    .merge(phenoData[[\"eid\"] + cov], on=\"eid\", how=\"inner\")\n",
    "    .dropna(subset=[label])\n",
    ").reset_index(drop=True)\n",
    "tmp_train_feather_dir = model_output_folder / \"train.feather\"\n",
    "train_feather.to_feather(tmp_train_feather_dir)\n",
    "\n",
    "\n",
    "# run single without random seed\n",
    "print(\n",
    "    f\"run_glmnet.R --json {json_dir} --train {tmp_train_feather_dir} --test {heldOutDataDict.path} --out {model_save_dir}\"\n",
    ")\n",
    "# run bootstrap with random seed to get the confidence interval\n",
    "\n",
    "for i in range(1, n_bootstrap+1):\n",
    "    print(\n",
    "        f\"run_glmnet.R --json {json_dir} --train {tmp_train_feather_dir} --test {heldOutDataDict.path} --out {model_save_dir}/{i} --seed {i}\"\n",
    "    )\n",
    "\n",
    "# TODO: run bootstrap and optim by python to control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!run_glmnet.R --json CAD_xhv2_exclude_more/Meta/train_config.json --train CAD_xhv2_exclude_more/Meta/train.feather --test /home/xutingfeng/ukb/ukbData/MultiOmicsDiseasePrediction/data/held_out_df.feather --out CAD_xhv2_exclude_more/Meta/model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
