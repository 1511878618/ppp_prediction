{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "from pytorch_lightning import LightningModule, LightningDataModule\n",
    "import torch\n",
    "from pytorch_lightning import trainer, LightningModule\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    SequentialSampler,\n",
    "    RandomSampler,\n",
    "    WeightedRandomSampler,\n",
    "    Dataset,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TableDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        features: list,\n",
    "        label: list,\n",
    "        covariates: list = None,\n",
    "        num_classes=2,\n",
    "        y_type=\"bt\",\n",
    "    ):\n",
    "        super(Dataset, self).__init__()\n",
    "        assert isinstance(df, pd.DataFrame)\n",
    "        assert isinstance(features, list)\n",
    "        assert isinstance(label, list)\n",
    "\n",
    "        for feature in features + label:\n",
    "            assert feature in df.columns\n",
    "        if covariates:\n",
    "            for cov in covariates:\n",
    "\n",
    "                assert cov in df.columns\n",
    "\n",
    "        if not covariates:\n",
    "\n",
    "            self.df = df.dropna(subset=features + label)\n",
    "        else:\n",
    "            self.df = df.dropna(subset=features + label + covariates)\n",
    "        assert len(self.df) > 0\n",
    "        self.features = features\n",
    "        self.covariates = covariates\n",
    "        self.label = label\n",
    "        self.num_classes = num_classes\n",
    "        self.y_type = y_type\n",
    "        self._init_dataset()\n",
    "\n",
    "    def _init_dataset(self):\n",
    "        X = torch.tensor(self.df[self.features].values).float()\n",
    "        if self.covariates:\n",
    "            X_cov = torch.tensor(self.df[self.covariates].values).float()\n",
    "\n",
    "        y = torch.tensor(self.df[self.label].values)\n",
    "        if (self.num_classes != len(self.label)) and self.y_type == \"bt\":\n",
    "            y = F.one_hot(\n",
    "                torch.tensor(y).long(), num_classes=self.num_classes\n",
    "            ).squeeze()\n",
    "\n",
    "        self.X = X\n",
    "        if self.covariates:\n",
    "            self.X_cov = X_cov\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.covariates:\n",
    "            return (self.X[idx], self.X_cov[idx]), self.y[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class TableDatasetModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train,\n",
    "        test,\n",
    "        batch_size=32,\n",
    "        features: list = None,\n",
    "        covariates: list = None,\n",
    "        label: list = None,\n",
    "        num_classes=2,\n",
    "        y_type=\"bt\",\n",
    "        num_workers=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.features = features\n",
    "        self.covariates = covariates\n",
    "        self.label = label\n",
    "        self.num_classes = num_classes\n",
    "        self.y_type = y_type\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self._init_dataset(train, test)\n",
    "\n",
    "    def _init_dataset(self, train, test):\n",
    "        train, val = train_test_split(train, test_size=0.2)\n",
    "        print(\n",
    "            f\"Train : {train[self.label].value_counts()}\\nval : {val[self.label].value_counts()}\\nTest : {test[self.label].value_counts()}\"\n",
    "        )\n",
    "        if self.y_type == \"bt\" and len(self.label) == 1:\n",
    "\n",
    "            class_weights = dict(\n",
    "                enumerate(\n",
    "                    class_weight.compute_class_weight(\n",
    "                        \"balanced\",\n",
    "                        classes=np.arange(self.num_classes),\n",
    "                        y=train[self.label[0]],\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            self.class_weights = class_weights\n",
    "\n",
    "        self.train = TableDataset(\n",
    "            df=train,\n",
    "            features=self.features,\n",
    "            label=self.label,\n",
    "            covariates=self.covariates,\n",
    "            num_classes=self.num_classes,\n",
    "            y_type=self.y_type,\n",
    "        )\n",
    "        self.validation = TableDataset(\n",
    "            df=val,\n",
    "            features=self.features,\n",
    "            label=self.label,\n",
    "            covariates=self.covariates,\n",
    "            num_classes=self.num_classes,\n",
    "            y_type=self.y_type,\n",
    "        )\n",
    "        self.test = TableDataset(\n",
    "            df=test,\n",
    "            features=self.features,\n",
    "            label=self.label,\n",
    "            covariates=self.covariates,\n",
    "            num_classes=self.num_classes,\n",
    "            y_type=self.y_type,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        if self.y_type == \"bt\":\n",
    "            train_class_weights = [\n",
    "                self.class_weights[torch.argmax(i).item()] for i in self.train.y\n",
    "            ]\n",
    "            sampler = WeightedRandomSampler(\n",
    "                train_class_weights, len(train_class_weights), replacement=True\n",
    "            )\n",
    "        else:\n",
    "            sampler = RandomSampler(self.train)\n",
    "\n",
    "        return DataLoader(\n",
    "            self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=sampler,\n",
    "            drop_last=True,\n",
    "            persistent_workers=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.validation,\n",
    "            batch_size=self.batch_size,\n",
    "            persistent_workers=True,\n",
    "            num_workers=self.num_workers,\n",
    "            sampler=SequentialSampler(self.validation),\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test,\n",
    "            batch_size=self.batch_size,\n",
    "            persistent_workers=True,\n",
    "            num_workers=self.num_workers,\n",
    "            sampler=SequentialSampler(self.test),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed = pd.read_pickle(\"result/part1/train_imputed.pkl\")\n",
    "test_imputed = pd.read_pickle(\"result/part1/test_imputed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C3',\n",
       " 'KLK7',\n",
       " 'GCHFR',\n",
       " 'NHLRC3',\n",
       " 'APOD',\n",
       " 'GAPDH',\n",
       " 'TP53I3',\n",
       " 'CPA4',\n",
       " 'ANXA2',\n",
       " 'GRSF1',\n",
       " 'IL25',\n",
       " 'HMMR',\n",
       " 'MRPL52',\n",
       " 'PAIP2B',\n",
       " 'THAP12',\n",
       " 'FOS',\n",
       " 'FGF9',\n",
       " 'PITHD1',\n",
       " 'THSD1',\n",
       " 'PTGES2',\n",
       " 'DEFB103A_DEFB103B',\n",
       " 'ATP1B4',\n",
       " 'CYB5A',\n",
       " 'UNC79',\n",
       " 'SLC34A3',\n",
       " 'TAGLN3',\n",
       " 'SLIRP',\n",
       " 'CLASP1',\n",
       " 'PSMC3',\n",
       " 'KIR3DL2',\n",
       " 'BEX3',\n",
       " 'PFDN4',\n",
       " 'BCL7A',\n",
       " 'SMC3',\n",
       " 'SLC28A1',\n",
       " 'CDC123',\n",
       " 'GJA8',\n",
       " 'NMRK2',\n",
       " 'GATA3',\n",
       " 'CPLX2',\n",
       " 'RASGRF1',\n",
       " 'FGF7',\n",
       " 'ANKRA2',\n",
       " 'RBM25',\n",
       " 'LYZL2',\n",
       " 'CDK1',\n",
       " 'CREB3',\n",
       " 'CREBZF',\n",
       " 'IGLON5',\n",
       " 'SHC1',\n",
       " 'ZP4',\n",
       " 'TMOD4',\n",
       " 'CEP152',\n",
       " 'MYH7B',\n",
       " 'CEP350',\n",
       " 'CDC25A',\n",
       " 'TRIM26',\n",
       " 'MANEAL',\n",
       " 'MUCL3',\n",
       " 'GIMAP8',\n",
       " 'CYTH3',\n",
       " 'PDXDC1',\n",
       " 'CLINT1',\n",
       " 'MAPRE3',\n",
       " 'EVI2B',\n",
       " 'STAU1',\n",
       " 'PCNA',\n",
       " 'DNAJA1',\n",
       " 'JMJD1C',\n",
       " 'GAGE2A',\n",
       " 'GAD1',\n",
       " 'IZUMO1',\n",
       " 'PDCL2',\n",
       " 'PDE1C',\n",
       " 'STOML2',\n",
       " 'BSND',\n",
       " 'MAPK13',\n",
       " 'PDIA2',\n",
       " 'BTLA',\n",
       " 'MLLT1',\n",
       " 'TPRKB',\n",
       " 'ARHGAP5',\n",
       " 'BTNL10',\n",
       " 'PHLDB2',\n",
       " 'PDIA5',\n",
       " 'ATF4',\n",
       " 'PRAME',\n",
       " 'TOP1MT',\n",
       " 'KHDC3L',\n",
       " 'DCUN1D2',\n",
       " 'IL3',\n",
       " 'DCLRE1C',\n",
       " 'ERCC1',\n",
       " 'DCDC2C',\n",
       " 'VCPKMT',\n",
       " 'SPRING1',\n",
       " 'MORN4',\n",
       " 'ESPL1',\n",
       " 'H2AP',\n",
       " 'MORF4L2',\n",
       " 'SSH3',\n",
       " 'VWA5A',\n",
       " 'PBK',\n",
       " 'REST',\n",
       " 'SHD',\n",
       " 'TXNL1',\n",
       " 'TPM3',\n",
       " 'NEB',\n",
       " 'ATP1B2',\n",
       " 'CEP112',\n",
       " 'SART1',\n",
       " 'ATP6V1G2',\n",
       " 'ATP2B4',\n",
       " 'SAT1',\n",
       " 'ATP1B1',\n",
       " 'NECAP2',\n",
       " 'ATP5F1D',\n",
       " 'ATP1B3',\n",
       " 'ARNTL',\n",
       " 'ARL2BP',\n",
       " 'SCGB2A2',\n",
       " 'GAMT',\n",
       " 'ASS1',\n",
       " 'NFYA',\n",
       " 'GASK1A',\n",
       " 'MANSC4',\n",
       " 'HMGCS1',\n",
       " 'MMUT',\n",
       " 'CBX2',\n",
       " 'BRD3',\n",
       " 'BRDT',\n",
       " 'MAP1LC3B2',\n",
       " 'CASQ2',\n",
       " 'HIP1',\n",
       " 'GSTM4',\n",
       " 'GUK1',\n",
       " 'CALY',\n",
       " 'C1GALT1C1',\n",
       " 'TEF',\n",
       " 'CACNA1H',\n",
       " 'HADH',\n",
       " 'MEGF11',\n",
       " 'MED21',\n",
       " 'THRAP3',\n",
       " 'SPINK8',\n",
       " 'NAA10',\n",
       " 'MRPL24',\n",
       " 'GBP6',\n",
       " 'MYOM2',\n",
       " 'B3GAT3',\n",
       " 'GCLM',\n",
       " 'MYL1',\n",
       " 'HSD17B3',\n",
       " 'MYH4',\n",
       " 'TMED4',\n",
       " 'TMED10',\n",
       " 'SKIV2L',\n",
       " 'SLC12A2',\n",
       " 'SLC51B',\n",
       " 'MTR',\n",
       " 'CD2',\n",
       " 'BHMT2',\n",
       " 'SNU13',\n",
       " 'GP1BB',\n",
       " 'ARL13B',\n",
       " 'HCG22',\n",
       " 'RYR1',\n",
       " 'FDX2',\n",
       " 'ADRA2A',\n",
       " 'ERVV-1',\n",
       " 'EXOSC10',\n",
       " 'EXTL1',\n",
       " 'CYP24A1',\n",
       " 'KIF1C',\n",
       " 'USP47',\n",
       " 'PRKD2',\n",
       " 'PROCR',\n",
       " 'PACS2',\n",
       " 'KIF22',\n",
       " 'NXPE4',\n",
       " 'RTKN2',\n",
       " 'CSRP3',\n",
       " 'NUDT15',\n",
       " 'UHRF2',\n",
       " 'UGDH',\n",
       " 'CSF2',\n",
       " 'KRT17',\n",
       " 'FDX1',\n",
       " 'PYY',\n",
       " 'UBQLN3',\n",
       " 'CSDE1',\n",
       " 'DDA1',\n",
       " 'PALM3',\n",
       " 'VSIG10L',\n",
       " 'PKD2',\n",
       " 'ABCA2',\n",
       " 'EDEM2',\n",
       " 'ABRAXAS2',\n",
       " 'ECI2',\n",
       " 'PGLYRP4',\n",
       " 'PDZD2',\n",
       " 'EIF2AK3',\n",
       " 'EIF5',\n",
       " 'ELOB',\n",
       " 'ITPA',\n",
       " 'ACSL1',\n",
       " 'DENND2B',\n",
       " 'ZCCHC8',\n",
       " 'ACTN2',\n",
       " 'PDE4D',\n",
       " 'ACY3',\n",
       " 'ENOX2',\n",
       " 'YOD1',\n",
       " 'ENPEP',\n",
       " 'PMCH',\n",
       " 'PMM2',\n",
       " 'DHODH',\n",
       " 'KRT6C',\n",
       " 'NUP50',\n",
       " 'LAMA1',\n",
       " 'COPB2',\n",
       " 'LRCH4',\n",
       " 'TSNAX',\n",
       " 'LPP',\n",
       " 'TRPV3',\n",
       " 'IGHMBP2',\n",
       " 'LILRA4',\n",
       " 'FHIP2A',\n",
       " 'NOP56',\n",
       " 'RIPK4',\n",
       " 'TRAF3IP2',\n",
       " 'IGF2BP3',\n",
       " 'NFKB1',\n",
       " 'NFX1',\n",
       " 'REXO2',\n",
       " 'TSPAN15',\n",
       " 'RBM19',\n",
       " 'FRMD4B',\n",
       " 'NOS2',\n",
       " 'TPR',\n",
       " 'NPR1',\n",
       " 'RAB33A',\n",
       " 'RAB39B',\n",
       " 'RPS10',\n",
       " 'ANK2',\n",
       " 'IFNW1',\n",
       " 'CPTP',\n",
       " 'TTN',\n",
       " 'IL36G',\n",
       " 'IL31RA',\n",
       " 'RNASE4',\n",
       " 'LRIG3',\n",
       " 'CACNA1C',\n",
       " 'SCIN',\n",
       " 'DNLZ',\n",
       " 'STEAP4',\n",
       " 'CBLN1',\n",
       " 'CHP1',\n",
       " 'SAG',\n",
       " 'DOCK9',\n",
       " 'RRP15',\n",
       " 'SYNGAP1',\n",
       " 'CNTF',\n",
       " 'ECSCR',\n",
       " 'ELAVL4',\n",
       " 'FZD8',\n",
       " 'SCN2A',\n",
       " 'CNGB3',\n",
       " 'GABRA4',\n",
       " 'CACNB1',\n",
       " 'DEFB118',\n",
       " 'PNMA2',\n",
       " 'SMS',\n",
       " 'CDH4',\n",
       " 'SH3BGRL2',\n",
       " 'RAB3GAP1',\n",
       " 'RANBP2',\n",
       " 'MYOM1',\n",
       " 'CDKL5',\n",
       " 'CSPG5',\n",
       " 'CTNNA1',\n",
       " 'OMP',\n",
       " 'OTOA',\n",
       " 'GLP1R',\n",
       " 'CEND1',\n",
       " 'SNAP25',\n",
       " 'PCARE',\n",
       " 'FH',\n",
       " 'CORO6',\n",
       " 'SCN3B',\n",
       " 'DCUN1D1',\n",
       " 'NLGN2',\n",
       " 'DEFB104A_DEFB104B',\n",
       " 'DEFB116',\n",
       " 'CRYM',\n",
       " 'SPTBN2',\n",
       " 'GPR101',\n",
       " 'DGCR6',\n",
       " 'GRIN2B',\n",
       " 'ZPR1',\n",
       " 'CD3D',\n",
       " 'HTR1A',\n",
       " 'TFAP2A',\n",
       " 'BLOC1S2',\n",
       " 'IMPG1',\n",
       " 'BRME1',\n",
       " 'KLRC1',\n",
       " 'HTR1B',\n",
       " 'IFNL2',\n",
       " 'VAV3',\n",
       " 'ITPRIP',\n",
       " 'KLF4',\n",
       " 'KIF20B',\n",
       " 'ATXN2',\n",
       " 'TSPAN7',\n",
       " 'BCAT2',\n",
       " 'IGDCC3',\n",
       " 'LELP1',\n",
       " 'TMPRSS11B',\n",
       " 'KCNC4',\n",
       " 'MAP1LC3A',\n",
       " 'BRD2',\n",
       " 'LYPLA2',\n",
       " 'BOLA1',\n",
       " 'ART5',\n",
       " 'AGBL2',\n",
       " 'UPK3A',\n",
       " 'IL13RA2',\n",
       " 'HDAC9',\n",
       " 'ARMCX2',\n",
       " 'KIRREL1',\n",
       " 'TJP3',\n",
       " 'TUBB3',\n",
       " 'ARID3A',\n",
       " 'KRT8',\n",
       " 'BHLHE40',\n",
       " 'ARHGEF5',\n",
       " 'ADGRV1',\n",
       " 'LMOD2',\n",
       " 'GFRAL',\n",
       " 'DNAJB6',\n",
       " 'CD7',\n",
       " 'NAGA',\n",
       " 'PTPN9',\n",
       " 'NDUFA5',\n",
       " 'SCPEP1',\n",
       " 'PRR4',\n",
       " 'CSF3R',\n",
       " 'UNC5D',\n",
       " 'TYRP1',\n",
       " 'SHH',\n",
       " 'GLI2',\n",
       " 'GIPR',\n",
       " 'UBE2Z',\n",
       " 'GAD2',\n",
       " 'SLITRK1',\n",
       " 'BCL2L15',\n",
       " 'TLR1',\n",
       " 'EDNRB',\n",
       " 'NUMB',\n",
       " 'ALPI',\n",
       " 'KLRF1',\n",
       " 'SIRT1',\n",
       " 'HS6ST2',\n",
       " 'GIT1',\n",
       " 'CD36',\n",
       " 'TLR4',\n",
       " 'CSNK1D',\n",
       " 'CSF2RB',\n",
       " 'CD3G',\n",
       " 'RNF168',\n",
       " 'RAP1A',\n",
       " 'FGF12',\n",
       " 'REPS1',\n",
       " 'FOLH1',\n",
       " 'RICTOR',\n",
       " 'TRAF3',\n",
       " 'NFAT5',\n",
       " 'FOXJ3',\n",
       " 'CEBPA',\n",
       " 'TPSG1',\n",
       " 'NEDD9',\n",
       " 'RNF31',\n",
       " 'CEMIP2',\n",
       " 'RPA2',\n",
       " 'CLEC12A',\n",
       " 'NEDD4L',\n",
       " 'S100A13',\n",
       " 'NECTIN1',\n",
       " 'TOP2B',\n",
       " 'TP53BP1',\n",
       " 'SEMA6C',\n",
       " 'RELB',\n",
       " 'FGF16',\n",
       " 'NME1',\n",
       " 'NPHS2',\n",
       " 'NPHS1',\n",
       " 'FGF20',\n",
       " 'RALB',\n",
       " 'FGF3',\n",
       " 'IL12RB2',\n",
       " 'ANKMY2',\n",
       " 'FGF6',\n",
       " 'PTP4A3',\n",
       " 'BAG4',\n",
       " 'CPOX',\n",
       " 'TSPYL1',\n",
       " 'BABAM1',\n",
       " 'LATS1',\n",
       " 'TSC1',\n",
       " 'IGFL4',\n",
       " 'RBPMS',\n",
       " 'CD226',\n",
       " 'NXPH3',\n",
       " 'MTDH',\n",
       " 'DGKA',\n",
       " 'STX7',\n",
       " 'STX5',\n",
       " 'HIF1A',\n",
       " 'EIF4E',\n",
       " 'IL36A',\n",
       " 'CASP9',\n",
       " 'PGR',\n",
       " 'DENR',\n",
       " 'ST8SIA1',\n",
       " 'TGFBR1',\n",
       " 'KDM3A',\n",
       " 'PPL',\n",
       " 'DDX4',\n",
       " 'DDX39A',\n",
       " 'ACP1',\n",
       " 'PDZK1',\n",
       " 'SMPD3',\n",
       " 'MKI67',\n",
       " 'POLR2A',\n",
       " 'POF1B',\n",
       " 'PIKFYVE',\n",
       " 'C1QL2',\n",
       " 'ACRV1',\n",
       " 'ZBP1',\n",
       " 'PLCB1',\n",
       " 'YY1',\n",
       " 'ZNF174',\n",
       " 'ADAM12',\n",
       " 'XIAP',\n",
       " 'EP300',\n",
       " 'TERF1',\n",
       " 'ADAMTS1',\n",
       " 'WASL',\n",
       " 'SUMF1',\n",
       " 'ADAMTS4',\n",
       " 'PPM1B',\n",
       " 'STAT2',\n",
       " 'ERMAP',\n",
       " 'HDAC8',\n",
       " 'DAPK2',\n",
       " 'DAND5',\n",
       " 'IL21R',\n",
       " 'IL31',\n",
       " 'VAMP8',\n",
       " 'IL20RB',\n",
       " 'CCNE1',\n",
       " 'EVI5',\n",
       " 'MRPS16',\n",
       " 'PRR5',\n",
       " 'PRSS22',\n",
       " 'PSMG4',\n",
       " 'AKR7L',\n",
       " 'PER3',\n",
       " 'BLNK',\n",
       " 'CA8',\n",
       " 'DBN1',\n",
       " 'SPRED2',\n",
       " 'PALLD',\n",
       " 'SSBP1',\n",
       " 'BNIP3L',\n",
       " 'VEGFB',\n",
       " 'MCEMP1',\n",
       " 'ITGAL',\n",
       " 'INSR',\n",
       " 'ESR1',\n",
       " 'IFI30',\n",
       " 'CNP',\n",
       " 'NAGK',\n",
       " 'LAMP1',\n",
       " 'TP73',\n",
       " 'PGM2',\n",
       " 'DYNLT1',\n",
       " 'CHM',\n",
       " 'PFDN6',\n",
       " 'TPBGL',\n",
       " 'FZD10',\n",
       " 'CLIC5',\n",
       " 'DTX2',\n",
       " 'CLNS1A',\n",
       " 'RRAS',\n",
       " 'CLGN',\n",
       " 'PDRG1',\n",
       " 'RPGR',\n",
       " 'DUSP29',\n",
       " 'CLEC2L',\n",
       " 'EFNB2',\n",
       " 'CHRM1',\n",
       " 'CIT',\n",
       " 'LRFN2',\n",
       " 'AP2B1',\n",
       " 'FRMD7',\n",
       " 'CRTAP',\n",
       " 'PTH',\n",
       " 'FARSA',\n",
       " 'AKR1B10',\n",
       " 'PSMD5',\n",
       " 'FBN2',\n",
       " 'CUZD1',\n",
       " 'OSTN',\n",
       " 'UROS',\n",
       " 'AIDA',\n",
       " 'PRKAG3',\n",
       " 'NRXN3',\n",
       " 'AMIGO1',\n",
       " 'DCC',\n",
       " 'PPT1',\n",
       " 'ERC2',\n",
       " 'DOC2B',\n",
       " 'RAC3',\n",
       " 'DDX25',\n",
       " 'DDX53',\n",
       " 'TTF2',\n",
       " 'KCNH2',\n",
       " 'DIPK1C',\n",
       " 'RBP1',\n",
       " 'TRIM40',\n",
       " 'NLGN1',\n",
       " 'PMS1',\n",
       " 'COL28A1',\n",
       " 'EPB41L5',\n",
       " 'IFT20',\n",
       " 'CNTNAP4',\n",
       " 'LRP2',\n",
       " 'C2orf69',\n",
       " 'LYSMD3',\n",
       " 'MAG',\n",
       " 'MRI1',\n",
       " 'SCT',\n",
       " 'CASC3',\n",
       " 'LRTM1',\n",
       " 'SLC44A4',\n",
       " 'GTPBP2',\n",
       " 'TDO2',\n",
       " 'SLC1A4',\n",
       " 'SV2A',\n",
       " 'MFAP3L',\n",
       " 'GBA',\n",
       " 'SOX9',\n",
       " 'CAMLG',\n",
       " 'MN1',\n",
       " 'CABP2',\n",
       " 'CCDC28A',\n",
       " 'TMCO5A',\n",
       " 'NAA80',\n",
       " 'TEX101',\n",
       " 'STX1B',\n",
       " 'BATF',\n",
       " 'CADPS',\n",
       " 'LRRC38',\n",
       " 'SEZ6',\n",
       " 'MSLNL',\n",
       " 'MYL6B',\n",
       " 'MDM1',\n",
       " 'SOWAHA',\n",
       " 'LRP2BP',\n",
       " 'SCN2B',\n",
       " 'CD164L2',\n",
       " 'TBR1',\n",
       " 'MYLPF',\n",
       " 'CGN',\n",
       " 'TARM1',\n",
       " 'MICALL2',\n",
       " 'GNGT1',\n",
       " 'SCN3A',\n",
       " 'HNF1A',\n",
       " 'ANXA1',\n",
       " 'SUSD5',\n",
       " 'RBPMS2',\n",
       " 'RANBP1',\n",
       " 'COQ7',\n",
       " 'MYBPC2',\n",
       " 'DMP1',\n",
       " 'ANP32C',\n",
       " 'PRRT3',\n",
       " 'PNMA1',\n",
       " 'HSDL2',\n",
       " 'TMEM132A',\n",
       " 'IGSF21',\n",
       " 'MYL4',\n",
       " 'DLL4',\n",
       " 'DMD',\n",
       " 'MYL3',\n",
       " 'EDN1',\n",
       " 'GIP',\n",
       " 'HSBP1',\n",
       " 'BOLA2_BOLA2B',\n",
       " 'AIF1L',\n",
       " 'OXCT1',\n",
       " 'PAGR1',\n",
       " 'SNED1',\n",
       " 'OPLAH',\n",
       " 'GNPDA1',\n",
       " 'SNX5',\n",
       " 'AHNAK2',\n",
       " 'AHNAK',\n",
       " 'BECN1',\n",
       " 'FAM172A',\n",
       " 'VIPR1',\n",
       " 'HRC',\n",
       " 'KHK',\n",
       " 'POMC',\n",
       " 'HS1BP3',\n",
       " 'NUDT10',\n",
       " 'PYDC1',\n",
       " 'SIL1',\n",
       " 'HMGCL',\n",
       " 'SIGLEC8',\n",
       " 'CRYZL1',\n",
       " 'CCER2',\n",
       " 'LAMB1',\n",
       " 'GRP',\n",
       " 'CBS',\n",
       " 'ADAMTSL4',\n",
       " 'EPPK1',\n",
       " 'LIPF',\n",
       " 'B3GNT7',\n",
       " 'RECK',\n",
       " 'SCRIB',\n",
       " 'SEC31A',\n",
       " 'RNF149',\n",
       " 'COMMD1',\n",
       " 'ATP6V1G1',\n",
       " 'RNF5',\n",
       " 'ROBO4',\n",
       " 'FSHB',\n",
       " 'RPL14',\n",
       " 'CEP170',\n",
       " 'AAMDC',\n",
       " 'EIF2S2',\n",
       " 'SCN4B',\n",
       " 'SEL1L',\n",
       " 'INPP5D',\n",
       " 'FSTL1',\n",
       " 'EHD3',\n",
       " 'PECR',\n",
       " 'ECHS1',\n",
       " 'MECR',\n",
       " 'TOR1AIP1',\n",
       " 'ASRGL1',\n",
       " 'IDO1',\n",
       " 'ZP3',\n",
       " 'GADD45GIP1',\n",
       " 'RNASE10',\n",
       " 'MAN1A2',\n",
       " 'COL2A1',\n",
       " 'NIT1',\n",
       " 'ITPR1',\n",
       " 'ENPP6',\n",
       " 'ENO3',\n",
       " 'LONP1',\n",
       " 'DNAJC6',\n",
       " 'NFE2',\n",
       " 'ENTR1',\n",
       " 'GATD3',\n",
       " 'M6PR',\n",
       " 'CALCOCO2',\n",
       " 'APOBR',\n",
       " 'ECM1',\n",
       " 'ACYP1',\n",
       " 'WFDC1',\n",
       " 'GM2A',\n",
       " 'PLG',\n",
       " 'SH3GL3',\n",
       " 'PCBD1',\n",
       " 'RLN2',\n",
       " 'C1QTNF9',\n",
       " 'SERPINI1',\n",
       " 'GLA',\n",
       " 'CACYBP',\n",
       " 'MARS1',\n",
       " 'HMCN2',\n",
       " 'C7',\n",
       " 'LPA',\n",
       " 'FGA',\n",
       " 'CLEC3B',\n",
       " 'PAXX',\n",
       " 'C1QTNF5',\n",
       " 'MENT',\n",
       " 'ADGRD1',\n",
       " 'VTI1A',\n",
       " 'DAAM1',\n",
       " 'GNPDA2',\n",
       " 'PENK',\n",
       " 'SYAP1',\n",
       " 'ADD1',\n",
       " 'PINLYP',\n",
       " 'JAM3',\n",
       " 'PRKG1',\n",
       " 'ITGA2',\n",
       " 'DNAJB2',\n",
       " 'SNX15',\n",
       " 'DIPK2B',\n",
       " 'TBCA',\n",
       " 'GP5',\n",
       " 'YWHAQ',\n",
       " 'PDE5A',\n",
       " 'DTD1',\n",
       " 'DDI2',\n",
       " 'ADH1B',\n",
       " 'ST13',\n",
       " 'INHBB',\n",
       " 'ERP29',\n",
       " 'PHYKPL',\n",
       " 'MOCS2',\n",
       " 'AFAP1',\n",
       " 'SPART',\n",
       " 'HEG1',\n",
       " 'BMPER',\n",
       " 'PDIA3',\n",
       " 'DCTD',\n",
       " 'MFAP4',\n",
       " 'BMP10',\n",
       " 'SPINK2',\n",
       " 'EPHA4',\n",
       " 'ACHE',\n",
       " 'CHAD',\n",
       " 'UBXN1',\n",
       " 'TNFRSF17',\n",
       " 'SLC9A3R1',\n",
       " 'LZTFL1',\n",
       " 'ARHGAP45',\n",
       " 'AMOT',\n",
       " 'CD72',\n",
       " 'CELSR2',\n",
       " 'GIMAP7',\n",
       " 'SDK2',\n",
       " 'GHR',\n",
       " 'RABEP1',\n",
       " 'CD300A',\n",
       " 'SEMA3G',\n",
       " 'CRELD1',\n",
       " 'RIDA',\n",
       " 'SFRP4',\n",
       " 'MXRA8',\n",
       " 'APPL2',\n",
       " 'MYOM3',\n",
       " 'FGFR4',\n",
       " 'TNFAIP8L2',\n",
       " 'PTRHD1',\n",
       " 'COL5A1',\n",
       " 'FUOM',\n",
       " 'AKAP12',\n",
       " 'CTSE',\n",
       " 'SCGB3A1',\n",
       " 'TPD52L2',\n",
       " 'NAGPA',\n",
       " 'UROD',\n",
       " 'GMPR2',\n",
       " 'SNCA',\n",
       " 'GLRX5',\n",
       " 'KCTD5',\n",
       " 'UPK3BL1',\n",
       " 'TRIM24',\n",
       " 'CTAG1A_CTAG1B',\n",
       " 'FUT1',\n",
       " 'HRAS',\n",
       " 'TET2',\n",
       " 'COL4A4',\n",
       " 'TCN1',\n",
       " 'KLKB1',\n",
       " 'QSOX1',\n",
       " 'CEACAM18',\n",
       " 'EFCAB2',\n",
       " 'NEK7',\n",
       " 'NFKB2',\n",
       " 'CEACAM20',\n",
       " 'RGL2',\n",
       " 'SEPTIN7',\n",
       " 'SAP18',\n",
       " 'ARAF',\n",
       " 'GABARAPL1',\n",
       " 'SAT2',\n",
       " 'ARHGAP30',\n",
       " 'TRDMT1',\n",
       " 'ID4',\n",
       " 'PKN3',\n",
       " 'MAPKAPK2',\n",
       " 'TNPO1',\n",
       " 'TAP1',\n",
       " 'TCP11',\n",
       " 'ITGAX',\n",
       " 'IFIT3',\n",
       " 'ACADM',\n",
       " 'CEP290',\n",
       " 'TAB2',\n",
       " 'GAS2',\n",
       " 'RPE',\n",
       " 'ZNF75D',\n",
       " 'LSM8',\n",
       " 'CENPJ',\n",
       " 'CINP',\n",
       " 'RNF43',\n",
       " 'IFIT1',\n",
       " 'CA7',\n",
       " 'RNF4',\n",
       " 'CENPF',\n",
       " 'TPPP2',\n",
       " 'IL9',\n",
       " 'PAFAH2',\n",
       " 'EPN1',\n",
       " 'COL9A2',\n",
       " 'PPIE',\n",
       " 'TLR2',\n",
       " 'MNAT1',\n",
       " 'ERI1',\n",
       " 'CD3E',\n",
       " 'MAGEA3',\n",
       " 'ALMS1',\n",
       " 'PPP1R12B',\n",
       " 'VPS28',\n",
       " 'PTTG1',\n",
       " 'MORF4L1',\n",
       " 'KIAA1549',\n",
       " 'SPRR1B',\n",
       " 'SLK',\n",
       " 'TK1',\n",
       " 'OFD1',\n",
       " 'KIAA1549L',\n",
       " 'MTHFSD',\n",
       " 'EVPL',\n",
       " 'GADD45B',\n",
       " 'TIGIT',\n",
       " 'CCND2',\n",
       " 'BRD1',\n",
       " 'SHPK',\n",
       " 'VSTM2B',\n",
       " 'TEX33',\n",
       " 'GUCY2C',\n",
       " 'CDH22',\n",
       " 'SERPINH1',\n",
       " 'RAPGEF2',\n",
       " 'PRUNE2',\n",
       " 'MTUS1',\n",
       " 'TMED1',\n",
       " 'GTF2IRD1',\n",
       " 'CASP4',\n",
       " 'OGT',\n",
       " 'RAD51',\n",
       " 'TXK',\n",
       " 'PARD3',\n",
       " 'CD82',\n",
       " 'BCHE',\n",
       " 'SERPINF2',\n",
       " 'SERPINA1',\n",
       " 'SERPINA4',\n",
       " 'SGSH',\n",
       " 'CFB',\n",
       " 'NPC2',\n",
       " 'PRDX2',\n",
       " 'TXN',\n",
       " 'CYB5R2',\n",
       " 'MST1',\n",
       " 'CAT',\n",
       " 'CTBS',\n",
       " 'SERPINF1',\n",
       " 'BRAP',\n",
       " 'HPSE',\n",
       " 'SERPINA5',\n",
       " 'F11',\n",
       " 'MBL2',\n",
       " 'CFHR5',\n",
       " 'IST1',\n",
       " 'PGLYRP2',\n",
       " 'CWC15',\n",
       " 'PALM',\n",
       " 'TTR',\n",
       " 'PSAP',\n",
       " 'ASAH1',\n",
       " 'HGFAC',\n",
       " 'AMOTL2',\n",
       " 'CRISP3',\n",
       " 'NMI',\n",
       " 'EIF2AK2',\n",
       " 'APCS',\n",
       " 'SLURP1',\n",
       " 'DTNB',\n",
       " 'LACRT',\n",
       " 'BTN1A1',\n",
       " 'THTPA',\n",
       " 'MPRIP',\n",
       " 'KLK15',\n",
       " 'RNASE6',\n",
       " 'NAP1L4',\n",
       " 'CDC26',\n",
       " 'LMNB1',\n",
       " 'NUDT16',\n",
       " 'PPBP',\n",
       " 'PF4',\n",
       " 'CFHR2',\n",
       " 'GSR',\n",
       " 'MDH1',\n",
       " 'IL2RG',\n",
       " 'REG3G',\n",
       " 'FNTA',\n",
       " 'RFC4',\n",
       " 'CMIP',\n",
       " 'NUBP1',\n",
       " 'FAM171B',\n",
       " 'NENF',\n",
       " 'AHSA1',\n",
       " 'IL22',\n",
       " 'COMMD9',\n",
       " 'VSIG10',\n",
       " 'KIAA2013',\n",
       " 'RCC1',\n",
       " 'ALDH2',\n",
       " 'UNG',\n",
       " 'VPS4B',\n",
       " 'RALY',\n",
       " 'RAB44',\n",
       " 'PXDNL',\n",
       " 'RAB2B',\n",
       " 'VSIG2',\n",
       " 'KIR2DL2',\n",
       " 'USP25',\n",
       " 'UBE2B',\n",
       " 'LARP1',\n",
       " 'S100A3',\n",
       " 'TDP1',\n",
       " 'CAPN3',\n",
       " 'MINDY1',\n",
       " 'SUSD4',\n",
       " 'TADA3',\n",
       " 'TARS1',\n",
       " 'LRRFIP1',\n",
       " 'TG',\n",
       " 'STAM',\n",
       " 'TGFB2',\n",
       " 'LTB',\n",
       " 'LUZP2',\n",
       " 'MAMDC4',\n",
       " 'HSPA2',\n",
       " 'BCL7B',\n",
       " 'CCDC134',\n",
       " 'GPRC5C',\n",
       " 'LAMTOR5',\n",
       " 'MTSS2',\n",
       " 'NDST1',\n",
       " 'GABARAP',\n",
       " 'CHCHD6',\n",
       " 'NACC1',\n",
       " 'AP1G2',\n",
       " 'TRIM58',\n",
       " 'SLC13A1',\n",
       " 'GPD1',\n",
       " 'SMAD2',\n",
       " 'SMAD3',\n",
       " 'GLYR1',\n",
       " 'SMPDL3B',\n",
       " 'SNX2',\n",
       " 'ARG2',\n",
       " 'SDCCAG8',\n",
       " 'TMEM106A',\n",
       " 'ACRBP',\n",
       " 'DUSP13',\n",
       " 'DYNC1H1',\n",
       " 'EDDM3B',\n",
       " 'DYNLT3',\n",
       " 'WDR46',\n",
       " 'PCDHB15',\n",
       " 'EPGN',\n",
       " 'DHPS',\n",
       " 'IMMT',\n",
       " 'PRC1',\n",
       " 'PPP1CC',\n",
       " 'ERN1',\n",
       " 'ZNRF4',\n",
       " 'ZNF830',\n",
       " 'YJU2',\n",
       " 'PCSK7',\n",
       " 'INSL4',\n",
       " 'ENOPH1',\n",
       " 'ITIH5',\n",
       " 'ENSA',\n",
       " 'TMPRSS11D',\n",
       " 'FTCD',\n",
       " 'PLSCR3',\n",
       " 'SEPTIN8',\n",
       " 'PRKAR2A',\n",
       " 'SMTN',\n",
       " 'NFU1',\n",
       " 'PBXIP1',\n",
       " 'HIP1R',\n",
       " 'ZFYVE19',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteomics = test_imputed.columns[test_imputed.columns.tolist().index(\"C3\") :].tolist()\n",
    "risk_factors = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"ldl_a\",\n",
    "    \"hdl_a\",\n",
    "    \"tc_a\",\n",
    "    \"tg_a\",\n",
    "    \"sbp_a\",\n",
    "    \"BMI\",\n",
    "    \"smoking\",\n",
    "    \"prevalent_diabetes\",\n",
    "]\n",
    "\n",
    "PRS = [\"PRS\"]\n",
    "proteomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DatasetModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetModule\u001b[49m(\n\u001b[1;32m      2\u001b[0m     train\u001b[38;5;241m=\u001b[39mtrain_imputed,\n\u001b[1;32m      3\u001b[0m     test\u001b[38;5;241m=\u001b[39mtest_imputed,\n\u001b[1;32m      4\u001b[0m     features\u001b[38;5;241m=\u001b[39mproteomics,\n\u001b[1;32m      5\u001b[0m     covariates\u001b[38;5;241m=\u001b[39mrisk_factors,\n\u001b[1;32m      6\u001b[0m     label\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincident_cad\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      7\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DatasetModule' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = DatasetModule(\n",
    "    train=train_imputed,\n",
    "    test=test_imputed,\n",
    "    features=proteomics,\n",
    "    covariates=risk_factors,\n",
    "    label=[\"incident_cad\"],\n",
    "    num_classes=2,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mtrain_dataloader():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# print(x.shape, y.shape)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39margmax(y, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.train_dataloader():\n",
    "    # print(x.shape, y.shape)\n",
    "    print(torch.argmax(y, dim=1).sum())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FullyResNetWork(pl.LightningModule):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         hidden_size,\n",
    "#         features,\n",
    "#         output_size,\n",
    "#         # num_resblocks=3,\n",
    "#         lr=1e-3,\n",
    "#         weight_decay=1e-2,\n",
    "#         weight=[1, 1],\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         super(FullyResNetWork, self).__init__()\n",
    "\n",
    "#         input_size = len(features)\n",
    "#         self.features = features\n",
    "#         self.norm = nn.BatchNorm1d(input_size)\n",
    "\n",
    "#         self.sharedNetWork = nn.Sequential(\n",
    "#             nn.Linear(input_size, hidden_size),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(hidden_size, hidden_size),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(hidden_size, hidden_size * 2),\n",
    "#             nn.SiLU(),\n",
    "#         )\n",
    "#         self.ResidualHeadNetwork_1 = nn.Sequential(\n",
    "#             nn.Linear(hidden_size * 2, 256),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(128, 32),\n",
    "#             nn.SiLU(),\n",
    "#         )\n",
    "#         self.ResidualHeadNetwork_2 = nn.Sequential(\n",
    "#             nn.Linear(input_size, 256),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(128, 32),\n",
    "#             nn.SiLU(),\n",
    "#         )\n",
    "#         self.ResidualHeadNetwork_3 = nn.Sequential(\n",
    "#             nn.Linear(32, 128),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(128, output_size),\n",
    "#         )\n",
    "\n",
    "#         self.lr = lr\n",
    "#         self.weight_decay = weight_decay\n",
    "\n",
    "#         self.mertic = {\n",
    "#             \"train_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "#             \"val_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "#         }\n",
    "#         self.history = defaultdict(dict)\n",
    "#         self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(weight).float())\n",
    "\n",
    "#     def forward(self, x):\n",
    "\n",
    "#         x = self.norm(x)\n",
    "\n",
    "#         out = self.sharedNetWork(x)\n",
    "\n",
    "#         out = self.ResidualHeadNetwork_1(out) + self.ResidualHeadNetwork_2(x)\n",
    "#         out = self.ResidualHeadNetwork_3(out)\n",
    "#         return out\n",
    "\n",
    "#     def training_step(self, train_batch, batch_idx):\n",
    "#         x, y = train_batch\n",
    "#         outputs = self.forward(x)\n",
    "#         loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "#         self.mertic[\"train_auc\"].update(\n",
    "#             torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "#         )\n",
    "\n",
    "#         self.log(\"ptl/train_loss\", loss, on_epoch=True, prog_bar=True, on_step=False)\n",
    "#         return loss\n",
    "\n",
    "#     def validation_step(self, val_batch, batch_idx):\n",
    "#         x, y = val_batch\n",
    "#         outputs = self.forward(x)\n",
    "#         loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "#         self.mertic[\"val_auc\"].update(\n",
    "#             torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "#         )\n",
    "\n",
    "#         self.log(\"ptl/val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "#     def on_train_epoch_end(self):\n",
    "\n",
    "#         auc = self.mertic[\"train_auc\"].compute()\n",
    "#         self.log(\"ptl/train_auc\", auc, prog_bar=True)\n",
    "\n",
    "#     def on_validation_epoch_end(self):\n",
    "#         auc = self.mertic[\"val_auc\"].compute()\n",
    "#         self.log(\"ptl/val_auc\", auc, prog_bar=True)\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(\n",
    "#             self.parameters(), lr=self.lr, weight_decay=self.weight_decay\n",
    "#         )\n",
    "#         return optimizer\n",
    "\n",
    "#     def predict_df(self, df, batch_size=256):\n",
    "\n",
    "#         for feature in self.features:\n",
    "#             assert feature in df.columns\n",
    "#         print(f\"input df have NA: {df[self.features].isna().sum(axis=1).sum()}\")\n",
    "#         df = df.copy().dropna(subset=self.features)\n",
    "\n",
    "#         predict_dataloader = DataLoader(\n",
    "#             torch.tensor(df[self.features].values).float(),\n",
    "#             batch_size=batch_size,\n",
    "#             persistent_workers=True,\n",
    "#             num_workers=4,\n",
    "#         )\n",
    "\n",
    "#         self.eval()\n",
    "#         pred = []\n",
    "#         with torch.no_grad():\n",
    "#             for x in predict_dataloader:\n",
    "#                 y_hat = self.forward(x).cpu().detach()\n",
    "#                 y_hat = torch.softmax(y_hat, dim=-1)[:, 1]\n",
    "\n",
    "#                 pred.append(y_hat)\n",
    "#         pred = torch.cat(pred).numpy()\n",
    "#         df[\"pred\"] = pred\n",
    "#         return df\n",
    "\n",
    "\n",
    "# class FullyConnectedNet(pl.LightningModule):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         hidden_size,\n",
    "#         features,\n",
    "#         output_size,\n",
    "#         num_resblocks=3,\n",
    "#         lr=1e-3,\n",
    "#         weight_decay=1e-2,\n",
    "#         weight=[1, 1],\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         super(FullyConnectedNet, self).__init__()\n",
    "#         input_size = len(features)\n",
    "#         self.features = features\n",
    "#         self.norm = nn.BatchNorm1d(input_size)\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "#         self.resblocks = nn.Sequential(\n",
    "#             *[LinearResBlock(hidden_size, hidden_size) for _ in range(num_resblocks)]\n",
    "#         )\n",
    "#         self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "#         self.lr = lr\n",
    "#         self.weight_decay = weight_decay\n",
    "\n",
    "#         self.mertic = {\n",
    "#             \"train_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "#             \"val_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "#         }\n",
    "#         self.history = defaultdict(dict)\n",
    "#         self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(weight).float())\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.norm(x)\n",
    "#         out = torch.relu(self.fc1(x))\n",
    "#         out = self.resblocks(out)\n",
    "#         out = self.fc2(out)\n",
    "#         return out\n",
    "\n",
    "#     def training_step(self, train_batch, batch_idx):\n",
    "#         x, y = train_batch\n",
    "#         outputs = self.forward(x)\n",
    "#         loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "#         self.mertic[\"train_auc\"].update(\n",
    "#             torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "#         )\n",
    "\n",
    "#         self.log(\"ptl/train_loss\", loss, on_epoch=True, prog_bar=True, on_step=False)\n",
    "#         return loss\n",
    "\n",
    "#     def validation_step(self, val_batch, batch_idx):\n",
    "#         x, y = val_batch\n",
    "#         outputs = self.forward(x)\n",
    "#         loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "#         self.mertic[\"val_auc\"].update(\n",
    "#             torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "#         )\n",
    "\n",
    "#         self.log(\"ptl/val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "#     def on_train_epoch_end(self):\n",
    "\n",
    "#         auc = self.mertic[\"train_auc\"].compute()\n",
    "#         self.log(\"ptl/train_auc\", auc, prog_bar=True)\n",
    "\n",
    "#     def on_validation_epoch_end(self):\n",
    "#         auc = self.mertic[\"val_auc\"].compute()\n",
    "#         self.log(\"ptl/val_auc\", auc, prog_bar=True)\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(\n",
    "#             self.parameters(), lr=self.lr, weight_decay=self.weight_decay\n",
    "#         )\n",
    "#         return optimizer\n",
    "\n",
    "#     def predict_df(self, df, batch_size=256):\n",
    "\n",
    "#         for feature in self.features:\n",
    "#             assert feature in df.columns\n",
    "#         print(f\"input df have NA: {df[self.features].isna().sum(axis=1).sum()}\")\n",
    "#         df = df.copy().dropna(subset=self.features)\n",
    "\n",
    "#         predict_dataloader = DataLoader(\n",
    "#             torch.tensor(df[self.features].values).float(),\n",
    "#             batch_size=batch_size,\n",
    "#             persistent_workers=True,\n",
    "#             num_workers=4,\n",
    "#         )\n",
    "\n",
    "#         self.eval()\n",
    "#         pred = []\n",
    "#         with torch.no_grad():\n",
    "#             for x in predict_dataloader:\n",
    "#                 y_hat = self.forward(x).cpu().detach()\n",
    "#                 y_hat = torch.softmax(y_hat, dim=-1)[:, 1]\n",
    "\n",
    "#                 pred.append(y_hat)\n",
    "#         pred = torch.cat(pred).numpy()\n",
    "#         df[\"pred\"] = pred\n",
    "#         return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class LinearResBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=None, dropout=0.1):\n",
    "        super(LinearResBlock, self).__init__()\n",
    "        if d_ff is None:\n",
    "            d_ff = d_model * 2\n",
    "\n",
    "        self.fc1 = nn.Linear(d_model, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # d_model => d_model (default is d_model)\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.dropout1(self.fc1(x))\n",
    "        x = self.norm2(x)\n",
    "        x = x + self.dropout2(self.ff(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearTransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=None, num_classes=0, num_layers=3, dropout=0.1):\n",
    "        super(LinearTransformerEncoder, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            *[\n",
    "                LinearResBlock(d_model, d_ff=d_ff, dropout=dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_norm = (\n",
    "            nn.LayerNorm(d_model, eps=1e-6) if num_classes > 0 else nn.Identity()\n",
    "        )\n",
    "        self.head_drop = nn.Dropout(dropout)\n",
    "        self.head = (\n",
    "            nn.Linear(d_model, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        )\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "\n",
    "        x = self.fc_norm(x)\n",
    "        x = self.head_drop(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearActivationNormDropOut(nn.Module):\n",
    "    def __init__(self, d_in, d_out, activation=nn.SiLU(), dropout=0.1):\n",
    "        super(LinearActivationNormDropOut, self).__init__()\n",
    "        self.fc = nn.Linear(d_in, d_out)\n",
    "        self.norm = nn.LayerNorm(d_out)\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearFeatureExtractor(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=None, d_out=None, dropout=0.1):\n",
    "        super(LinearFeatureExtractor, self).__init__()\n",
    "        if d_ff is None:\n",
    "            d_ff = d_model * 2\n",
    "        if d_out is None:\n",
    "            d_out = d_model\n",
    "\n",
    "        self.extractor = nn.Sequential(\n",
    "            LinearActivationNormDropOut(\n",
    "                d_model, d_ff, activation=nn.SiLU(), dropout=dropout\n",
    "            ),\n",
    "            LinearActivationNormDropOut(\n",
    "                d_ff, d_ff, activation=nn.SiLU(), dropout=dropout\n",
    "            ),\n",
    "            LinearActivationNormDropOut(\n",
    "                d_ff, d_out, activation=nn.SiLU(), dropout=dropout\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.extractor(x)\n",
    "\n",
    "\n",
    "class LinearFeatureFusionBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model_list,\n",
    "        d_ff=128,  # median layer dim. recommanded not to higher than any of d_model passed\n",
    "        d_out=128,\n",
    "        dropout=0.1,\n",
    "        fusion_method=\"add\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        fusion_method: add\n",
    "        \"\"\"\n",
    "        super(LinearFeatureFusionBlock, self).__init__()\n",
    "        self.EachPartModuleList = nn.ModuleList(\n",
    "            [\n",
    "                LinearFeatureExtractor(\n",
    "                    d_model, d_ff=d_model * 2, d_out=d_ff, dropout=dropout\n",
    "                )\n",
    "                for d_model in d_model_list\n",
    "            ]\n",
    "        )\n",
    "        self.d_ff = d_ff\n",
    "        self.fusionDecoder = LinearFeatureExtractor(\n",
    "            d_ff, d_ff=d_ff * 2, d_out=d_out, dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.d_model_list = d_model_list\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.dropout = dropout\n",
    "        self.fusion_method = fusion_method\n",
    "\n",
    "    def intermidiate_forward(self, *x_list):\n",
    "        return [module(x) for module, x in zip(self.EachPartModuleList, x_list)]\n",
    "\n",
    "    def forward(self, *x_list):\n",
    "        x_list = self.intermidiate_forward(*x_list)\n",
    "\n",
    "        if self.fusion_method == \"add\":\n",
    "            x = torch.stack(x_list, dim=-1).sum(dim=-1)\n",
    "        # elif self.fusion_method == \"concat\":\n",
    "        #     x = torch.cat(x_list, dim=-1)\n",
    "        # elif self.fusion_method == \"minus\":\n",
    "        else:\n",
    "            raise NotImplementedError(\"Not implemented\")\n",
    "\n",
    "        x = self.fusionDecoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        features_dict,\n",
    "        covariates_dict=None,\n",
    "        d_ff=128,\n",
    "        num_classes=2,\n",
    "        num_layers=3,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super(LinearTransformer, self).__init__()\n",
    "        self.features_dict = features_dict\n",
    "        self.covariates_dict = covariates_dict if covariates_dict else None\n",
    "        self.features_name = list(features_dict.keys())[0]\n",
    "        self.covariates_name = (\n",
    "            list(covariates_dict.keys())[0] if covariates_dict else None\n",
    "        )\n",
    "        self.features = features_dict[self.features_name]\n",
    "        self.covariates = (\n",
    "            covariates_dict[self.covariates_name] if covariates_dict else None\n",
    "        )\n",
    "\n",
    "        self.d_featurs = len(self.features)\n",
    "        self.d_covariates = len(self.covariates) if covariates_dict else None\n",
    "        self.d_ff = d_ff if d_ff else self.d_featurs\n",
    "\n",
    "        self.encoder = LinearTransformerEncoder(\n",
    "            self.d_featurs,\n",
    "            d_ff=self.d_ff,\n",
    "            num_classes=d_ff,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "        )  # d_features => d_ff\n",
    "\n",
    "        d_model_list = (\n",
    "            [self.d_ff, self.d_covariates]\n",
    "            if self.d_covariates is not None\n",
    "            else [self.d_ff]\n",
    "        )\n",
    "        self.decoder = LinearFeatureFusionBlock(\n",
    "            d_model_list=d_model_list, d_out=d_ff, dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.fc_norm = (\n",
    "            nn.LayerNorm(d_ff, eps=1e-6) if num_classes > 0 else nn.Identity()\n",
    "        )\n",
    "        self.head_drop = nn.Dropout(dropout)\n",
    "        self.head = nn.Linear(d_ff, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def run_encoder(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def forward(self, x, cov=None):\n",
    "\n",
    "        x = self.run_encoder(x)\n",
    "\n",
    "        if cov is not None:\n",
    "            out = self.decoder(x, cov)\n",
    "        else:\n",
    "            out = self.decoder(x)\n",
    "\n",
    "        out = self.fc_norm(out)\n",
    "        out = self.head_drop(out)\n",
    "        out = self.head(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelParametersNum(model):\n",
    "    totalNum = sum([i.numel() for i in model.parameters()])\n",
    "    print(f\"模型总参数个数：{totalNum}\\t占用的总显存为{totalNum*4/1024/1024:.2f}MB\")\n",
    "    return totalNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelParametersNum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m lt \u001b[38;5;241m=\u001b[39m LinearTransformer(\n\u001b[1;32m      2\u001b[0m     features_dict\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproteomics\u001b[39m\u001b[38;5;124m\"\u001b[39m: proteomics},\n\u001b[1;32m      3\u001b[0m     covariates_dict\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrisk_factors\u001b[39m\u001b[38;5;124m\"\u001b[39m: risk_factors},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodelParametersNum\u001b[49m(lt))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(lt(torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(proteomics)), torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(risk_factors)))\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m lt\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelParametersNum' is not defined"
     ]
    }
   ],
   "source": [
    "lt = LinearTransformer(\n",
    "    features_dict={\"proteomics\": proteomics},\n",
    "    covariates_dict={\"risk_factors\": risk_factors},\n",
    "    d_ff=512,\n",
    "    num_classes=2,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    ")\n",
    "print(modelParametersNum(lt))\n",
    "print(lt(torch.randn(32, len(proteomics)), torch.randn(32, len(risk_factors))).shape)\n",
    "lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数个数：26387254\t占用的总显存为100.66MB\n",
      "26387254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearTransformer(\n",
       "  (encoder): LinearTransformerEncoder(\n",
       "    (layers): Sequential(\n",
       "      (0): LinearResBlock(\n",
       "        (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "        (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=2911, out_features=512, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=2911, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): LinearResBlock(\n",
       "        (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "        (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=2911, out_features=512, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=2911, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_norm): LayerNorm((2911,), eps=1e-06, elementwise_affine=True)\n",
       "    (head_drop): Dropout(p=0.1, inplace=False)\n",
       "    (head): Linear(in_features=2911, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): LinearFeatureFusionBlock(\n",
       "    (EachPartModuleList): ModuleList(\n",
       "      (0): LinearFeatureExtractor(\n",
       "        (extractor): Sequential(\n",
       "          (0): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=1024, out_features=128, bias=True)\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fusionDecoder): LinearFeatureExtractor(\n",
       "      (extractor): Sequential(\n",
       "        (0): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  (head_drop): Dropout(p=0.1, inplace=False)\n",
       "  (head): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt = LinearTransformer(\n",
    "    features_dict={\"proteomics\": proteomics},\n",
    "    # covariates_dict={\"risk_factors\": risk_factors},\n",
    "    d_ff=512,\n",
    "    num_classes=2,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    ")\n",
    "print(modelParametersNum(lt))\n",
    "# print(lt(torch.randn(32, len(proteomics)), torch.randn(32, len(risk_factors))).shape)\n",
    "lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearFeatureFusionBlock(\n",
       "  (EachPartModuleList): ModuleList(\n",
       "    (0): LinearFeatureExtractor(\n",
       "      (extractor): Sequential(\n",
       "        (0): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): LinearFeatureExtractor(\n",
       "      (extractor): Sequential(\n",
       "        (0): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=10, out_features=20, bias=True)\n",
       "          (norm): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=20, out_features=20, bias=True)\n",
       "          (norm): LayerNorm((20,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): LinearActivationNormDropOut(\n",
       "          (fc): Linear(in_features=20, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): SiLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fusionDecoder): LinearFeatureExtractor(\n",
       "    (extractor): Sequential(\n",
       "      (0): LinearActivationNormDropOut(\n",
       "        (fc): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): SiLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): LinearActivationNormDropOut(\n",
       "        (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): SiLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): LinearActivationNormDropOut(\n",
       "        (fc): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): SiLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lff = LinearFeatureFusionBlock([128, 10], d_ff=256, d_out=128, dropout=0.1)\n",
    "print(lff(torch.randn(32, 128), torch.randn(32, 10)).shape)\n",
    "lff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearTransformerEncoder(\n",
       "  (layers): Sequential(\n",
       "    (0): LinearResBlock(\n",
       "      (fc1): Linear(in_features=30, out_features=30, bias=True)\n",
       "      (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=30, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=30, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): LinearResBlock(\n",
       "      (fc1): Linear(in_features=30, out_features=30, bias=True)\n",
       "      (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=30, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=30, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): LinearResBlock(\n",
       "      (fc1): Linear(in_features=30, out_features=30, bias=True)\n",
       "      (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=30, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=30, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc_norm): LayerNorm((30,), eps=1e-06, elementwise_affine=True)\n",
       "  (head_drop): Dropout(p=0.1, inplace=False)\n",
       "  (head): Linear(in_features=30, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lte = LinearTransformerEncoder(d_model=30, d_ff=256, num_classes=128, num_layers=3)\n",
    "print(lte(torch.randn(32, 30)).shape)\n",
    "lte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTransformerPL(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        features_dict,\n",
    "        covariates_dict=None,\n",
    "        d_ff=512,\n",
    "        num_classes=2,\n",
    "        num_layers=2,\n",
    "        dropout=0.1,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-2,\n",
    "        weight=[1, 1],\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super(LinearTransformerPL, self).__init__()\n",
    "\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.mertic = {\n",
    "            \"train_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "            \"val_auc\": torchmetrics.AUROC(num_classes=2, task=\"multiclass\"),\n",
    "        }\n",
    "        self.history = defaultdict(dict)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(weight).float())\n",
    "        self.model = LinearTransformer(\n",
    "            features_dict=features_dict,\n",
    "            covariates_dict=covariates_dict,\n",
    "            d_ff=d_ff,\n",
    "            num_classes=num_classes,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.features = self.model.features\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.model(*x) if isinstance(x, (list, tuple)) else self.model(x)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        outputs = self.forward(x)\n",
    "        loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "        self.mertic[\"train_auc\"].update(\n",
    "            torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "        )\n",
    "\n",
    "        self.log(\"ptl/train_loss\", loss, on_epoch=True, prog_bar=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        outputs = self.forward(x)\n",
    "        loss = self.loss_fn(outputs, y.squeeze(-1).float())\n",
    "\n",
    "        self.mertic[\"val_auc\"].update(\n",
    "            torch.softmax(outputs, dim=-1), torch.argmax(y, dim=1)\n",
    "        )\n",
    "\n",
    "        self.log(\"ptl/val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "\n",
    "        auc = self.mertic[\"train_auc\"].compute()\n",
    "        self.log(\"ptl/train_auc\", auc, prog_bar=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        auc = self.mertic[\"val_auc\"].compute()\n",
    "        self.log(\"ptl/val_auc\", auc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), lr=self.lr, weight_decay=self.weight_decay\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def predict_df(self, df, batch_size=256):\n",
    "\n",
    "        for feature in self.features:\n",
    "            assert feature in df.columns\n",
    "        print(f\"input df have NA: {df[self.features].isna().sum(axis=1).sum()}\")\n",
    "        df = df.copy().dropna(subset=self.features)\n",
    "\n",
    "        predict_dataloader = DataLoader(\n",
    "            torch.tensor(df[self.features].values).float(),\n",
    "            batch_size=batch_size,\n",
    "            persistent_workers=True,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "        self.eval()\n",
    "        pred = []\n",
    "        with torch.no_grad():\n",
    "            for x in predict_dataloader:\n",
    "                y_hat = self.forward(x).cpu().detach()\n",
    "                y_hat = torch.softmax(y_hat, dim=-1)[:, 1]\n",
    "\n",
    "                pred.append(y_hat)\n",
    "        pred = torch.cat(pred).numpy()\n",
    "        df[\"pred\"] = pred\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trainer\n",
    "# used_fatures = proteomics\n",
    "# # + risk_factors + PRS\n",
    "# model = LinearTransformerPL(\n",
    "#     features_dict={\"proteomics\": proteomics},\n",
    "#     covariates_dict={\"risk_factors\": risk_factors},\n",
    "#     d_ff=512,\n",
    "#     num_classes=2,\n",
    "#     num_layers=2,\n",
    "#     dropout=0.1,\n",
    "#     lr=1e-3,\n",
    "#     weight_decay=1e-5,\n",
    "#     weight=[1, 1],\n",
    "# )\n",
    "\n",
    "# dataset = DatasetModule(\n",
    "#     train=train_imputed,\n",
    "#     test=test_imputed,\n",
    "#     features=used_fatures,\n",
    "#     covariates=risk_factors,\n",
    "#     label=[\"incident_cad\"],\n",
    "#     num_classes=2,\n",
    "#     batch_size=256,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(126)\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.train_dataloader():\n",
    "    # print(x.shape, y.shape)\n",
    "    print(torch.argmax(y, dim=1).sum())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : incident_cad\n",
      "0.0             27199\n",
      "1.0              1606\n",
      "dtype: int64\n",
      "val : incident_cad\n",
      "0.0             6809\n",
      "1.0              393\n",
      "dtype: int64\n",
      "Test : incident_cad\n",
      "0.0             14599\n",
      "1.0               833\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2006/3827040605.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y).long(), num_classes=self.num_classes\n",
      "/tmp/ipykernel_2006/3827040605.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y).long(), num_classes=self.num_classes\n",
      "/tmp/ipykernel_2006/3827040605.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y).long(), num_classes=self.num_classes\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss_fn | CrossEntropyLoss  | 0     \n",
      "1 | model   | LinearTransformer | 9.2 M \n",
      "----------------------------------------------\n",
      "9.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.2 M     Total params\n",
      "36.860    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c20c4b4cbe142bf8254bbbab12ddc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1425ab374f4d3c8818445c94562c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0462e1abf344b6692992835dba41846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ca32c9baa64936b4d6e4b7340c8051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628a910a8b314d47a5c5397ee42fe767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d39b97583b4164a7994c2d7d877cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393f85faf2e54b5986f950c7db18b39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7321a56d8c4dab91b1cb7fd971219c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79fb785c3b3426e98a4e3d811f48df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5532cdc4c4047f381ba757886837121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93d1406155742cc9618fc3758d3a7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f58e5d555864b0d8d0452c70b406188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# trainer\n",
    "\n",
    "\n",
    "model = LinearTransformerPL(\n",
    "    features_dict={\"proteomics\": proteomics},\n",
    "    # covariates_dict={\"risk_factors\": risk_factors},\n",
    "    d_ff=64,\n",
    "    num_classes=2,\n",
    "    num_layers=1,\n",
    "    dropout=0.3,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-3,\n",
    "    weight=[1, 1],\n",
    ")\n",
    "\n",
    "dataset = TableDatasetModule(\n",
    "    train=train_imputed,\n",
    "    test=test_imputed,\n",
    "    features=proteomics,\n",
    "    covariates=risk_factors,\n",
    "    label=[\"incident_cad\"],\n",
    "    num_classes=2,\n",
    "    batch_size=256,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=1,\n",
    ")\n",
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main_embedd = model.model.run_encoder(x[0].to(model.device))\n",
    "# main_embedd.shape\n",
    "# o = model.model.decoder.intermidiate_forward(main_embedd, x[1].to(model.device))\n",
    "# o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C3',\n",
       " 'KLK7',\n",
       " 'GCHFR',\n",
       " 'NHLRC3',\n",
       " 'APOD',\n",
       " 'GAPDH',\n",
       " 'TP53I3',\n",
       " 'CPA4',\n",
       " 'ANXA2',\n",
       " 'GRSF1',\n",
       " 'IL25',\n",
       " 'HMMR',\n",
       " 'MRPL52',\n",
       " 'PAIP2B',\n",
       " 'THAP12',\n",
       " 'FOS',\n",
       " 'FGF9',\n",
       " 'PITHD1',\n",
       " 'THSD1',\n",
       " 'PTGES2',\n",
       " 'DEFB103A_DEFB103B',\n",
       " 'ATP1B4',\n",
       " 'CYB5A',\n",
       " 'UNC79',\n",
       " 'SLC34A3',\n",
       " 'TAGLN3',\n",
       " 'SLIRP',\n",
       " 'CLASP1',\n",
       " 'PSMC3',\n",
       " 'KIR3DL2',\n",
       " 'BEX3',\n",
       " 'PFDN4',\n",
       " 'BCL7A',\n",
       " 'SMC3',\n",
       " 'SLC28A1',\n",
       " 'CDC123',\n",
       " 'GJA8',\n",
       " 'NMRK2',\n",
       " 'GATA3',\n",
       " 'CPLX2',\n",
       " 'RASGRF1',\n",
       " 'FGF7',\n",
       " 'ANKRA2',\n",
       " 'RBM25',\n",
       " 'LYZL2',\n",
       " 'CDK1',\n",
       " 'CREB3',\n",
       " 'CREBZF',\n",
       " 'IGLON5',\n",
       " 'SHC1',\n",
       " 'ZP4',\n",
       " 'TMOD4',\n",
       " 'CEP152',\n",
       " 'MYH7B',\n",
       " 'CEP350',\n",
       " 'CDC25A',\n",
       " 'TRIM26',\n",
       " 'MANEAL',\n",
       " 'MUCL3',\n",
       " 'GIMAP8',\n",
       " 'CYTH3',\n",
       " 'PDXDC1',\n",
       " 'CLINT1',\n",
       " 'MAPRE3',\n",
       " 'EVI2B',\n",
       " 'STAU1',\n",
       " 'PCNA',\n",
       " 'DNAJA1',\n",
       " 'JMJD1C',\n",
       " 'GAGE2A',\n",
       " 'GAD1',\n",
       " 'IZUMO1',\n",
       " 'PDCL2',\n",
       " 'PDE1C',\n",
       " 'STOML2',\n",
       " 'BSND',\n",
       " 'MAPK13',\n",
       " 'PDIA2',\n",
       " 'BTLA',\n",
       " 'MLLT1',\n",
       " 'TPRKB',\n",
       " 'ARHGAP5',\n",
       " 'BTNL10',\n",
       " 'PHLDB2',\n",
       " 'PDIA5',\n",
       " 'ATF4',\n",
       " 'PRAME',\n",
       " 'TOP1MT',\n",
       " 'KHDC3L',\n",
       " 'DCUN1D2',\n",
       " 'IL3',\n",
       " 'DCLRE1C',\n",
       " 'ERCC1',\n",
       " 'DCDC2C',\n",
       " 'VCPKMT',\n",
       " 'SPRING1',\n",
       " 'MORN4',\n",
       " 'ESPL1',\n",
       " 'H2AP',\n",
       " 'MORF4L2',\n",
       " 'SSH3',\n",
       " 'VWA5A',\n",
       " 'PBK',\n",
       " 'REST',\n",
       " 'SHD',\n",
       " 'TXNL1',\n",
       " 'TPM3',\n",
       " 'NEB',\n",
       " 'ATP1B2',\n",
       " 'CEP112',\n",
       " 'SART1',\n",
       " 'ATP6V1G2',\n",
       " 'ATP2B4',\n",
       " 'SAT1',\n",
       " 'ATP1B1',\n",
       " 'NECAP2',\n",
       " 'ATP5F1D',\n",
       " 'ATP1B3',\n",
       " 'ARNTL',\n",
       " 'ARL2BP',\n",
       " 'SCGB2A2',\n",
       " 'GAMT',\n",
       " 'ASS1',\n",
       " 'NFYA',\n",
       " 'GASK1A',\n",
       " 'MANSC4',\n",
       " 'HMGCS1',\n",
       " 'MMUT',\n",
       " 'CBX2',\n",
       " 'BRD3',\n",
       " 'BRDT',\n",
       " 'MAP1LC3B2',\n",
       " 'CASQ2',\n",
       " 'HIP1',\n",
       " 'GSTM4',\n",
       " 'GUK1',\n",
       " 'CALY',\n",
       " 'C1GALT1C1',\n",
       " 'TEF',\n",
       " 'CACNA1H',\n",
       " 'HADH',\n",
       " 'MEGF11',\n",
       " 'MED21',\n",
       " 'THRAP3',\n",
       " 'SPINK8',\n",
       " 'NAA10',\n",
       " 'MRPL24',\n",
       " 'GBP6',\n",
       " 'MYOM2',\n",
       " 'B3GAT3',\n",
       " 'GCLM',\n",
       " 'MYL1',\n",
       " 'HSD17B3',\n",
       " 'MYH4',\n",
       " 'TMED4',\n",
       " 'TMED10',\n",
       " 'SKIV2L',\n",
       " 'SLC12A2',\n",
       " 'SLC51B',\n",
       " 'MTR',\n",
       " 'CD2',\n",
       " 'BHMT2',\n",
       " 'SNU13',\n",
       " 'GP1BB',\n",
       " 'ARL13B',\n",
       " 'HCG22',\n",
       " 'RYR1',\n",
       " 'FDX2',\n",
       " 'ADRA2A',\n",
       " 'ERVV-1',\n",
       " 'EXOSC10',\n",
       " 'EXTL1',\n",
       " 'CYP24A1',\n",
       " 'KIF1C',\n",
       " 'USP47',\n",
       " 'PRKD2',\n",
       " 'PROCR',\n",
       " 'PACS2',\n",
       " 'KIF22',\n",
       " 'NXPE4',\n",
       " 'RTKN2',\n",
       " 'CSRP3',\n",
       " 'NUDT15',\n",
       " 'UHRF2',\n",
       " 'UGDH',\n",
       " 'CSF2',\n",
       " 'KRT17',\n",
       " 'FDX1',\n",
       " 'PYY',\n",
       " 'UBQLN3',\n",
       " 'CSDE1',\n",
       " 'DDA1',\n",
       " 'PALM3',\n",
       " 'VSIG10L',\n",
       " 'PKD2',\n",
       " 'ABCA2',\n",
       " 'EDEM2',\n",
       " 'ABRAXAS2',\n",
       " 'ECI2',\n",
       " 'PGLYRP4',\n",
       " 'PDZD2',\n",
       " 'EIF2AK3',\n",
       " 'EIF5',\n",
       " 'ELOB',\n",
       " 'ITPA',\n",
       " 'ACSL1',\n",
       " 'DENND2B',\n",
       " 'ZCCHC8',\n",
       " 'ACTN2',\n",
       " 'PDE4D',\n",
       " 'ACY3',\n",
       " 'ENOX2',\n",
       " 'YOD1',\n",
       " 'ENPEP',\n",
       " 'PMCH',\n",
       " 'PMM2',\n",
       " 'DHODH',\n",
       " 'KRT6C',\n",
       " 'NUP50',\n",
       " 'LAMA1',\n",
       " 'COPB2',\n",
       " 'LRCH4',\n",
       " 'TSNAX',\n",
       " 'LPP',\n",
       " 'TRPV3',\n",
       " 'IGHMBP2',\n",
       " 'LILRA4',\n",
       " 'FHIP2A',\n",
       " 'NOP56',\n",
       " 'RIPK4',\n",
       " 'TRAF3IP2',\n",
       " 'IGF2BP3',\n",
       " 'NFKB1',\n",
       " 'NFX1',\n",
       " 'REXO2',\n",
       " 'TSPAN15',\n",
       " 'RBM19',\n",
       " 'FRMD4B',\n",
       " 'NOS2',\n",
       " 'TPR',\n",
       " 'NPR1',\n",
       " 'RAB33A',\n",
       " 'RAB39B',\n",
       " 'RPS10',\n",
       " 'ANK2',\n",
       " 'IFNW1',\n",
       " 'CPTP',\n",
       " 'TTN',\n",
       " 'IL36G',\n",
       " 'IL31RA',\n",
       " 'RNASE4',\n",
       " 'LRIG3',\n",
       " 'CACNA1C',\n",
       " 'SCIN',\n",
       " 'DNLZ',\n",
       " 'STEAP4',\n",
       " 'CBLN1',\n",
       " 'CHP1',\n",
       " 'SAG',\n",
       " 'DOCK9',\n",
       " 'RRP15',\n",
       " 'SYNGAP1',\n",
       " 'CNTF',\n",
       " 'ECSCR',\n",
       " 'ELAVL4',\n",
       " 'FZD8',\n",
       " 'SCN2A',\n",
       " 'CNGB3',\n",
       " 'GABRA4',\n",
       " 'CACNB1',\n",
       " 'DEFB118',\n",
       " 'PNMA2',\n",
       " 'SMS',\n",
       " 'CDH4',\n",
       " 'SH3BGRL2',\n",
       " 'RAB3GAP1',\n",
       " 'RANBP2',\n",
       " 'MYOM1',\n",
       " 'CDKL5',\n",
       " 'CSPG5',\n",
       " 'CTNNA1',\n",
       " 'OMP',\n",
       " 'OTOA',\n",
       " 'GLP1R',\n",
       " 'CEND1',\n",
       " 'SNAP25',\n",
       " 'PCARE',\n",
       " 'FH',\n",
       " 'CORO6',\n",
       " 'SCN3B',\n",
       " 'DCUN1D1',\n",
       " 'NLGN2',\n",
       " 'DEFB104A_DEFB104B',\n",
       " 'DEFB116',\n",
       " 'CRYM',\n",
       " 'SPTBN2',\n",
       " 'GPR101',\n",
       " 'DGCR6',\n",
       " 'GRIN2B',\n",
       " 'ZPR1',\n",
       " 'CD3D',\n",
       " 'HTR1A',\n",
       " 'TFAP2A',\n",
       " 'BLOC1S2',\n",
       " 'IMPG1',\n",
       " 'BRME1',\n",
       " 'KLRC1',\n",
       " 'HTR1B',\n",
       " 'IFNL2',\n",
       " 'VAV3',\n",
       " 'ITPRIP',\n",
       " 'KLF4',\n",
       " 'KIF20B',\n",
       " 'ATXN2',\n",
       " 'TSPAN7',\n",
       " 'BCAT2',\n",
       " 'IGDCC3',\n",
       " 'LELP1',\n",
       " 'TMPRSS11B',\n",
       " 'KCNC4',\n",
       " 'MAP1LC3A',\n",
       " 'BRD2',\n",
       " 'LYPLA2',\n",
       " 'BOLA1',\n",
       " 'ART5',\n",
       " 'AGBL2',\n",
       " 'UPK3A',\n",
       " 'IL13RA2',\n",
       " 'HDAC9',\n",
       " 'ARMCX2',\n",
       " 'KIRREL1',\n",
       " 'TJP3',\n",
       " 'TUBB3',\n",
       " 'ARID3A',\n",
       " 'KRT8',\n",
       " 'BHLHE40',\n",
       " 'ARHGEF5',\n",
       " 'ADGRV1',\n",
       " 'LMOD2',\n",
       " 'GFRAL',\n",
       " 'DNAJB6',\n",
       " 'CD7',\n",
       " 'NAGA',\n",
       " 'PTPN9',\n",
       " 'NDUFA5',\n",
       " 'SCPEP1',\n",
       " 'PRR4',\n",
       " 'CSF3R',\n",
       " 'UNC5D',\n",
       " 'TYRP1',\n",
       " 'SHH',\n",
       " 'GLI2',\n",
       " 'GIPR',\n",
       " 'UBE2Z',\n",
       " 'GAD2',\n",
       " 'SLITRK1',\n",
       " 'BCL2L15',\n",
       " 'TLR1',\n",
       " 'EDNRB',\n",
       " 'NUMB',\n",
       " 'ALPI',\n",
       " 'KLRF1',\n",
       " 'SIRT1',\n",
       " 'HS6ST2',\n",
       " 'GIT1',\n",
       " 'CD36',\n",
       " 'TLR4',\n",
       " 'CSNK1D',\n",
       " 'CSF2RB',\n",
       " 'CD3G',\n",
       " 'RNF168',\n",
       " 'RAP1A',\n",
       " 'FGF12',\n",
       " 'REPS1',\n",
       " 'FOLH1',\n",
       " 'RICTOR',\n",
       " 'TRAF3',\n",
       " 'NFAT5',\n",
       " 'FOXJ3',\n",
       " 'CEBPA',\n",
       " 'TPSG1',\n",
       " 'NEDD9',\n",
       " 'RNF31',\n",
       " 'CEMIP2',\n",
       " 'RPA2',\n",
       " 'CLEC12A',\n",
       " 'NEDD4L',\n",
       " 'S100A13',\n",
       " 'NECTIN1',\n",
       " 'TOP2B',\n",
       " 'TP53BP1',\n",
       " 'SEMA6C',\n",
       " 'RELB',\n",
       " 'FGF16',\n",
       " 'NME1',\n",
       " 'NPHS2',\n",
       " 'NPHS1',\n",
       " 'FGF20',\n",
       " 'RALB',\n",
       " 'FGF3',\n",
       " 'IL12RB2',\n",
       " 'ANKMY2',\n",
       " 'FGF6',\n",
       " 'PTP4A3',\n",
       " 'BAG4',\n",
       " 'CPOX',\n",
       " 'TSPYL1',\n",
       " 'BABAM1',\n",
       " 'LATS1',\n",
       " 'TSC1',\n",
       " 'IGFL4',\n",
       " 'RBPMS',\n",
       " 'CD226',\n",
       " 'NXPH3',\n",
       " 'MTDH',\n",
       " 'DGKA',\n",
       " 'STX7',\n",
       " 'STX5',\n",
       " 'HIF1A',\n",
       " 'EIF4E',\n",
       " 'IL36A',\n",
       " 'CASP9',\n",
       " 'PGR',\n",
       " 'DENR',\n",
       " 'ST8SIA1',\n",
       " 'TGFBR1',\n",
       " 'KDM3A',\n",
       " 'PPL',\n",
       " 'DDX4',\n",
       " 'DDX39A',\n",
       " 'ACP1',\n",
       " 'PDZK1',\n",
       " 'SMPD3',\n",
       " 'MKI67',\n",
       " 'POLR2A',\n",
       " 'POF1B',\n",
       " 'PIKFYVE',\n",
       " 'C1QL2',\n",
       " 'ACRV1',\n",
       " 'ZBP1',\n",
       " 'PLCB1',\n",
       " 'YY1',\n",
       " 'ZNF174',\n",
       " 'ADAM12',\n",
       " 'XIAP',\n",
       " 'EP300',\n",
       " 'TERF1',\n",
       " 'ADAMTS1',\n",
       " 'WASL',\n",
       " 'SUMF1',\n",
       " 'ADAMTS4',\n",
       " 'PPM1B',\n",
       " 'STAT2',\n",
       " 'ERMAP',\n",
       " 'HDAC8',\n",
       " 'DAPK2',\n",
       " 'DAND5',\n",
       " 'IL21R',\n",
       " 'IL31',\n",
       " 'VAMP8',\n",
       " 'IL20RB',\n",
       " 'CCNE1',\n",
       " 'EVI5',\n",
       " 'MRPS16',\n",
       " 'PRR5',\n",
       " 'PRSS22',\n",
       " 'PSMG4',\n",
       " 'AKR7L',\n",
       " 'PER3',\n",
       " 'BLNK',\n",
       " 'CA8',\n",
       " 'DBN1',\n",
       " 'SPRED2',\n",
       " 'PALLD',\n",
       " 'SSBP1',\n",
       " 'BNIP3L',\n",
       " 'VEGFB',\n",
       " 'MCEMP1',\n",
       " 'ITGAL',\n",
       " 'INSR',\n",
       " 'ESR1',\n",
       " 'IFI30',\n",
       " 'CNP',\n",
       " 'NAGK',\n",
       " 'LAMP1',\n",
       " 'TP73',\n",
       " 'PGM2',\n",
       " 'DYNLT1',\n",
       " 'CHM',\n",
       " 'PFDN6',\n",
       " 'TPBGL',\n",
       " 'FZD10',\n",
       " 'CLIC5',\n",
       " 'DTX2',\n",
       " 'CLNS1A',\n",
       " 'RRAS',\n",
       " 'CLGN',\n",
       " 'PDRG1',\n",
       " 'RPGR',\n",
       " 'DUSP29',\n",
       " 'CLEC2L',\n",
       " 'EFNB2',\n",
       " 'CHRM1',\n",
       " 'CIT',\n",
       " 'LRFN2',\n",
       " 'AP2B1',\n",
       " 'FRMD7',\n",
       " 'CRTAP',\n",
       " 'PTH',\n",
       " 'FARSA',\n",
       " 'AKR1B10',\n",
       " 'PSMD5',\n",
       " 'FBN2',\n",
       " 'CUZD1',\n",
       " 'OSTN',\n",
       " 'UROS',\n",
       " 'AIDA',\n",
       " 'PRKAG3',\n",
       " 'NRXN3',\n",
       " 'AMIGO1',\n",
       " 'DCC',\n",
       " 'PPT1',\n",
       " 'ERC2',\n",
       " 'DOC2B',\n",
       " 'RAC3',\n",
       " 'DDX25',\n",
       " 'DDX53',\n",
       " 'TTF2',\n",
       " 'KCNH2',\n",
       " 'DIPK1C',\n",
       " 'RBP1',\n",
       " 'TRIM40',\n",
       " 'NLGN1',\n",
       " 'PMS1',\n",
       " 'COL28A1',\n",
       " 'EPB41L5',\n",
       " 'IFT20',\n",
       " 'CNTNAP4',\n",
       " 'LRP2',\n",
       " 'C2orf69',\n",
       " 'LYSMD3',\n",
       " 'MAG',\n",
       " 'MRI1',\n",
       " 'SCT',\n",
       " 'CASC3',\n",
       " 'LRTM1',\n",
       " 'SLC44A4',\n",
       " 'GTPBP2',\n",
       " 'TDO2',\n",
       " 'SLC1A4',\n",
       " 'SV2A',\n",
       " 'MFAP3L',\n",
       " 'GBA',\n",
       " 'SOX9',\n",
       " 'CAMLG',\n",
       " 'MN1',\n",
       " 'CABP2',\n",
       " 'CCDC28A',\n",
       " 'TMCO5A',\n",
       " 'NAA80',\n",
       " 'TEX101',\n",
       " 'STX1B',\n",
       " 'BATF',\n",
       " 'CADPS',\n",
       " 'LRRC38',\n",
       " 'SEZ6',\n",
       " 'MSLNL',\n",
       " 'MYL6B',\n",
       " 'MDM1',\n",
       " 'SOWAHA',\n",
       " 'LRP2BP',\n",
       " 'SCN2B',\n",
       " 'CD164L2',\n",
       " 'TBR1',\n",
       " 'MYLPF',\n",
       " 'CGN',\n",
       " 'TARM1',\n",
       " 'MICALL2',\n",
       " 'GNGT1',\n",
       " 'SCN3A',\n",
       " 'HNF1A',\n",
       " 'ANXA1',\n",
       " 'SUSD5',\n",
       " 'RBPMS2',\n",
       " 'RANBP1',\n",
       " 'COQ7',\n",
       " 'MYBPC2',\n",
       " 'DMP1',\n",
       " 'ANP32C',\n",
       " 'PRRT3',\n",
       " 'PNMA1',\n",
       " 'HSDL2',\n",
       " 'TMEM132A',\n",
       " 'IGSF21',\n",
       " 'MYL4',\n",
       " 'DLL4',\n",
       " 'DMD',\n",
       " 'MYL3',\n",
       " 'EDN1',\n",
       " 'GIP',\n",
       " 'HSBP1',\n",
       " 'BOLA2_BOLA2B',\n",
       " 'AIF1L',\n",
       " 'OXCT1',\n",
       " 'PAGR1',\n",
       " 'SNED1',\n",
       " 'OPLAH',\n",
       " 'GNPDA1',\n",
       " 'SNX5',\n",
       " 'AHNAK2',\n",
       " 'AHNAK',\n",
       " 'BECN1',\n",
       " 'FAM172A',\n",
       " 'VIPR1',\n",
       " 'HRC',\n",
       " 'KHK',\n",
       " 'POMC',\n",
       " 'HS1BP3',\n",
       " 'NUDT10',\n",
       " 'PYDC1',\n",
       " 'SIL1',\n",
       " 'HMGCL',\n",
       " 'SIGLEC8',\n",
       " 'CRYZL1',\n",
       " 'CCER2',\n",
       " 'LAMB1',\n",
       " 'GRP',\n",
       " 'CBS',\n",
       " 'ADAMTSL4',\n",
       " 'EPPK1',\n",
       " 'LIPF',\n",
       " 'B3GNT7',\n",
       " 'RECK',\n",
       " 'SCRIB',\n",
       " 'SEC31A',\n",
       " 'RNF149',\n",
       " 'COMMD1',\n",
       " 'ATP6V1G1',\n",
       " 'RNF5',\n",
       " 'ROBO4',\n",
       " 'FSHB',\n",
       " 'RPL14',\n",
       " 'CEP170',\n",
       " 'AAMDC',\n",
       " 'EIF2S2',\n",
       " 'SCN4B',\n",
       " 'SEL1L',\n",
       " 'INPP5D',\n",
       " 'FSTL1',\n",
       " 'EHD3',\n",
       " 'PECR',\n",
       " 'ECHS1',\n",
       " 'MECR',\n",
       " 'TOR1AIP1',\n",
       " 'ASRGL1',\n",
       " 'IDO1',\n",
       " 'ZP3',\n",
       " 'GADD45GIP1',\n",
       " 'RNASE10',\n",
       " 'MAN1A2',\n",
       " 'COL2A1',\n",
       " 'NIT1',\n",
       " 'ITPR1',\n",
       " 'ENPP6',\n",
       " 'ENO3',\n",
       " 'LONP1',\n",
       " 'DNAJC6',\n",
       " 'NFE2',\n",
       " 'ENTR1',\n",
       " 'GATD3',\n",
       " 'M6PR',\n",
       " 'CALCOCO2',\n",
       " 'APOBR',\n",
       " 'ECM1',\n",
       " 'ACYP1',\n",
       " 'WFDC1',\n",
       " 'GM2A',\n",
       " 'PLG',\n",
       " 'SH3GL3',\n",
       " 'PCBD1',\n",
       " 'RLN2',\n",
       " 'C1QTNF9',\n",
       " 'SERPINI1',\n",
       " 'GLA',\n",
       " 'CACYBP',\n",
       " 'MARS1',\n",
       " 'HMCN2',\n",
       " 'C7',\n",
       " 'LPA',\n",
       " 'FGA',\n",
       " 'CLEC3B',\n",
       " 'PAXX',\n",
       " 'C1QTNF5',\n",
       " 'MENT',\n",
       " 'ADGRD1',\n",
       " 'VTI1A',\n",
       " 'DAAM1',\n",
       " 'GNPDA2',\n",
       " 'PENK',\n",
       " 'SYAP1',\n",
       " 'ADD1',\n",
       " 'PINLYP',\n",
       " 'JAM3',\n",
       " 'PRKG1',\n",
       " 'ITGA2',\n",
       " 'DNAJB2',\n",
       " 'SNX15',\n",
       " 'DIPK2B',\n",
       " 'TBCA',\n",
       " 'GP5',\n",
       " 'YWHAQ',\n",
       " 'PDE5A',\n",
       " 'DTD1',\n",
       " 'DDI2',\n",
       " 'ADH1B',\n",
       " 'ST13',\n",
       " 'INHBB',\n",
       " 'ERP29',\n",
       " 'PHYKPL',\n",
       " 'MOCS2',\n",
       " 'AFAP1',\n",
       " 'SPART',\n",
       " 'HEG1',\n",
       " 'BMPER',\n",
       " 'PDIA3',\n",
       " 'DCTD',\n",
       " 'MFAP4',\n",
       " 'BMP10',\n",
       " 'SPINK2',\n",
       " 'EPHA4',\n",
       " 'ACHE',\n",
       " 'CHAD',\n",
       " 'UBXN1',\n",
       " 'TNFRSF17',\n",
       " 'SLC9A3R1',\n",
       " 'LZTFL1',\n",
       " 'ARHGAP45',\n",
       " 'AMOT',\n",
       " 'CD72',\n",
       " 'CELSR2',\n",
       " 'GIMAP7',\n",
       " 'SDK2',\n",
       " 'GHR',\n",
       " 'RABEP1',\n",
       " 'CD300A',\n",
       " 'SEMA3G',\n",
       " 'CRELD1',\n",
       " 'RIDA',\n",
       " 'SFRP4',\n",
       " 'MXRA8',\n",
       " 'APPL2',\n",
       " 'MYOM3',\n",
       " 'FGFR4',\n",
       " 'TNFAIP8L2',\n",
       " 'PTRHD1',\n",
       " 'COL5A1',\n",
       " 'FUOM',\n",
       " 'AKAP12',\n",
       " 'CTSE',\n",
       " 'SCGB3A1',\n",
       " 'TPD52L2',\n",
       " 'NAGPA',\n",
       " 'UROD',\n",
       " 'GMPR2',\n",
       " 'SNCA',\n",
       " 'GLRX5',\n",
       " 'KCTD5',\n",
       " 'UPK3BL1',\n",
       " 'TRIM24',\n",
       " 'CTAG1A_CTAG1B',\n",
       " 'FUT1',\n",
       " 'HRAS',\n",
       " 'TET2',\n",
       " 'COL4A4',\n",
       " 'TCN1',\n",
       " 'KLKB1',\n",
       " 'QSOX1',\n",
       " 'CEACAM18',\n",
       " 'EFCAB2',\n",
       " 'NEK7',\n",
       " 'NFKB2',\n",
       " 'CEACAM20',\n",
       " 'RGL2',\n",
       " 'SEPTIN7',\n",
       " 'SAP18',\n",
       " 'ARAF',\n",
       " 'GABARAPL1',\n",
       " 'SAT2',\n",
       " 'ARHGAP30',\n",
       " 'TRDMT1',\n",
       " 'ID4',\n",
       " 'PKN3',\n",
       " 'MAPKAPK2',\n",
       " 'TNPO1',\n",
       " 'TAP1',\n",
       " 'TCP11',\n",
       " 'ITGAX',\n",
       " 'IFIT3',\n",
       " 'ACADM',\n",
       " 'CEP290',\n",
       " 'TAB2',\n",
       " 'GAS2',\n",
       " 'RPE',\n",
       " 'ZNF75D',\n",
       " 'LSM8',\n",
       " 'CENPJ',\n",
       " 'CINP',\n",
       " 'RNF43',\n",
       " 'IFIT1',\n",
       " 'CA7',\n",
       " 'RNF4',\n",
       " 'CENPF',\n",
       " 'TPPP2',\n",
       " 'IL9',\n",
       " 'PAFAH2',\n",
       " 'EPN1',\n",
       " 'COL9A2',\n",
       " 'PPIE',\n",
       " 'TLR2',\n",
       " 'MNAT1',\n",
       " 'ERI1',\n",
       " 'CD3E',\n",
       " 'MAGEA3',\n",
       " 'ALMS1',\n",
       " 'PPP1R12B',\n",
       " 'VPS28',\n",
       " 'PTTG1',\n",
       " 'MORF4L1',\n",
       " 'KIAA1549',\n",
       " 'SPRR1B',\n",
       " 'SLK',\n",
       " 'TK1',\n",
       " 'OFD1',\n",
       " 'KIAA1549L',\n",
       " 'MTHFSD',\n",
       " 'EVPL',\n",
       " 'GADD45B',\n",
       " 'TIGIT',\n",
       " 'CCND2',\n",
       " 'BRD1',\n",
       " 'SHPK',\n",
       " 'VSTM2B',\n",
       " 'TEX33',\n",
       " 'GUCY2C',\n",
       " 'CDH22',\n",
       " 'SERPINH1',\n",
       " 'RAPGEF2',\n",
       " 'PRUNE2',\n",
       " 'MTUS1',\n",
       " 'TMED1',\n",
       " 'GTF2IRD1',\n",
       " 'CASP4',\n",
       " 'OGT',\n",
       " 'RAD51',\n",
       " 'TXK',\n",
       " 'PARD3',\n",
       " 'CD82',\n",
       " 'BCHE',\n",
       " 'SERPINF2',\n",
       " 'SERPINA1',\n",
       " 'SERPINA4',\n",
       " 'SGSH',\n",
       " 'CFB',\n",
       " 'NPC2',\n",
       " 'PRDX2',\n",
       " 'TXN',\n",
       " 'CYB5R2',\n",
       " 'MST1',\n",
       " 'CAT',\n",
       " 'CTBS',\n",
       " 'SERPINF1',\n",
       " 'BRAP',\n",
       " 'HPSE',\n",
       " 'SERPINA5',\n",
       " 'F11',\n",
       " 'MBL2',\n",
       " 'CFHR5',\n",
       " 'IST1',\n",
       " 'PGLYRP2',\n",
       " 'CWC15',\n",
       " 'PALM',\n",
       " 'TTR',\n",
       " 'PSAP',\n",
       " 'ASAH1',\n",
       " 'HGFAC',\n",
       " 'AMOTL2',\n",
       " 'CRISP3',\n",
       " 'NMI',\n",
       " 'EIF2AK2',\n",
       " 'APCS',\n",
       " 'SLURP1',\n",
       " 'DTNB',\n",
       " 'LACRT',\n",
       " 'BTN1A1',\n",
       " 'THTPA',\n",
       " 'MPRIP',\n",
       " 'KLK15',\n",
       " 'RNASE6',\n",
       " 'NAP1L4',\n",
       " 'CDC26',\n",
       " 'LMNB1',\n",
       " 'NUDT16',\n",
       " 'PPBP',\n",
       " 'PF4',\n",
       " 'CFHR2',\n",
       " 'GSR',\n",
       " 'MDH1',\n",
       " 'IL2RG',\n",
       " 'REG3G',\n",
       " 'FNTA',\n",
       " 'RFC4',\n",
       " 'CMIP',\n",
       " 'NUBP1',\n",
       " 'FAM171B',\n",
       " 'NENF',\n",
       " 'AHSA1',\n",
       " 'IL22',\n",
       " 'COMMD9',\n",
       " 'VSIG10',\n",
       " 'KIAA2013',\n",
       " 'RCC1',\n",
       " 'ALDH2',\n",
       " 'UNG',\n",
       " 'VPS4B',\n",
       " 'RALY',\n",
       " 'RAB44',\n",
       " 'PXDNL',\n",
       " 'RAB2B',\n",
       " 'VSIG2',\n",
       " 'KIR2DL2',\n",
       " 'USP25',\n",
       " 'UBE2B',\n",
       " 'LARP1',\n",
       " 'S100A3',\n",
       " 'TDP1',\n",
       " 'CAPN3',\n",
       " 'MINDY1',\n",
       " 'SUSD4',\n",
       " 'TADA3',\n",
       " 'TARS1',\n",
       " 'LRRFIP1',\n",
       " 'TG',\n",
       " 'STAM',\n",
       " 'TGFB2',\n",
       " 'LTB',\n",
       " 'LUZP2',\n",
       " 'MAMDC4',\n",
       " 'HSPA2',\n",
       " 'BCL7B',\n",
       " 'CCDC134',\n",
       " 'GPRC5C',\n",
       " 'LAMTOR5',\n",
       " 'MTSS2',\n",
       " 'NDST1',\n",
       " 'GABARAP',\n",
       " 'CHCHD6',\n",
       " 'NACC1',\n",
       " 'AP1G2',\n",
       " 'TRIM58',\n",
       " 'SLC13A1',\n",
       " 'GPD1',\n",
       " 'SMAD2',\n",
       " 'SMAD3',\n",
       " 'GLYR1',\n",
       " 'SMPDL3B',\n",
       " 'SNX2',\n",
       " 'ARG2',\n",
       " 'SDCCAG8',\n",
       " 'TMEM106A',\n",
       " 'ACRBP',\n",
       " 'DUSP13',\n",
       " 'DYNC1H1',\n",
       " 'EDDM3B',\n",
       " 'DYNLT3',\n",
       " 'WDR46',\n",
       " 'PCDHB15',\n",
       " 'EPGN',\n",
       " 'DHPS',\n",
       " 'IMMT',\n",
       " 'PRC1',\n",
       " 'PPP1CC',\n",
       " 'ERN1',\n",
       " 'ZNRF4',\n",
       " 'ZNF830',\n",
       " 'YJU2',\n",
       " 'PCSK7',\n",
       " 'INSL4',\n",
       " 'ENOPH1',\n",
       " 'ITIH5',\n",
       " 'ENSA',\n",
       " 'TMPRSS11D',\n",
       " 'FTCD',\n",
       " 'PLSCR3',\n",
       " 'SEPTIN8',\n",
       " 'PRKAR2A',\n",
       " 'SMTN',\n",
       " 'NFU1',\n",
       " 'PBXIP1',\n",
       " 'HIP1R',\n",
       " 'ZFYVE19',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_fatures = proteomics\n",
    "# + risk_factors + PRS\n",
    "used_fatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-04-18 14:35:59</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:29.08        </td></tr>\n",
       "<tr><td>Memory:      </td><td>18.4/50.1 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=2<br>Bracket: Iter 16.000: 0.6438496112823486 | Iter 8.000: 0.6683449745178223 | Iter 4.000: 0.7107754945755005 | Iter 2.000: 0.7137609720230103 | Iter 1.000: 0.6116625368595123<br>Logical resource usage: 4.0/12 CPUs, 0.99/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">   train_loop_config/ba\n",
       "tch_size</th><th>train_loop_config/co\n",
       "variates_dict                     </th><th style=\"text-align: right;\">    train_loop_config/d_\n",
       "ff</th><th style=\"text-align: right;\">         train_loop_config/dr\n",
       "opout</th><th style=\"text-align: right;\">  train_loop_config/lr</th><th style=\"text-align: right;\">  train_loop_config/nu\n",
       "m_layers</th><th>train_loop_config/we\n",
       "ight           </th><th style=\"text-align: right;\">            train_loop_config/we\n",
       "ight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ptl/val_loss</th><th style=\"text-align: right;\">  ptl/val_auc</th><th style=\"text-align: right;\">  ptl/train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_26cec_00000</td><td>TERMINATED</td><td>172.22.18.47:13883</td><td style=\"text-align: right;\">64</td><td>                    </td><td style=\"text-align: right;\">128</td><td style=\"text-align: right;\">0.173362</td><td style=\"text-align: right;\">            0.00081795</td><td style=\"text-align: right;\">4</td><td>[0.1, 100]</td><td style=\"text-align: right;\">0.00112076 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        303.029 </td><td style=\"text-align: right;\">      0.654624</td><td style=\"text-align: right;\">     0.632138</td><td style=\"text-align: right;\">        0.364551</td></tr>\n",
       "<tr><td>TorchTrainer_26cec_00001</td><td>TERMINATED</td><td>172.22.18.47:1450 </td><td style=\"text-align: right;\">64</td><td>{&#x27;risk_factors&#x27;_13c0</td><td style=\"text-align: right;\">256</td><td style=\"text-align: right;\">0.118666</td><td style=\"text-align: right;\">            0.0834193 </td><td style=\"text-align: right;\">2</td><td>[0.1, 1]  </td><td style=\"text-align: right;\">0.000292107</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.5355</td><td style=\"text-align: right;\">      0.236837</td><td style=\"text-align: right;\">     0.501361</td><td style=\"text-align: right;\">        0.256112</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 14:35:59,132\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/home/xutingfeng/ray_results/TorchTrainer_2024-04-18_14-30-30' in 0.0115s.\n",
      "2024-04-18 14:35:59,143\tINFO tune.py:1048 -- Total run time: 329.10 seconds (329.06 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearTransformerPL(\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (model): LinearTransformer(\n",
       "    (encoder): LinearTransformerEncoder(\n",
       "      (layers): Sequential(\n",
       "        (0): LinearResBlock(\n",
       "          (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "          (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=2911, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=2911, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          (dropout2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "        )\n",
       "        (1): LinearResBlock(\n",
       "          (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "          (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=2911, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=2911, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          (dropout2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "        )\n",
       "        (2): LinearResBlock(\n",
       "          (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "          (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=2911, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=2911, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          (dropout2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "        )\n",
       "        (3): LinearResBlock(\n",
       "          (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "          (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=2911, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=2911, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          (dropout2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (fc_norm): LayerNorm((2911,), eps=1e-06, elementwise_affine=True)\n",
       "      (head_drop): Dropout(p=0.17336180394137352, inplace=False)\n",
       "      (head): Linear(in_features=2911, out_features=128, bias=True)\n",
       "    )\n",
       "    (decoder): LinearFeatureFusionBlock(\n",
       "      (EachPartModuleList): ModuleList(\n",
       "        (0): LinearFeatureExtractor(\n",
       "          (extractor): Sequential(\n",
       "            (0): LinearActivationNormDropOut(\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation): SiLU()\n",
       "              (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            )\n",
       "            (1): LinearActivationNormDropOut(\n",
       "              (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation): SiLU()\n",
       "              (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            )\n",
       "            (2): LinearActivationNormDropOut(\n",
       "              (fc): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation): SiLU()\n",
       "              (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fusionDecoder): LinearFeatureExtractor(\n",
       "        (extractor): Sequential(\n",
       "          (0): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          )\n",
       "          (1): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          )\n",
       "          (2): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "    (head_drop): Dropout(p=0.17336180394137352, inplace=False)\n",
       "    (head): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.train.lightning import (\n",
    "    RayDDPStrategy,\n",
    "    RayLightningEnvironment,\n",
    "    RayTrainReportCallback,\n",
    "    prepare_trainer,\n",
    ")\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "\n",
    "def train_func(config):\n",
    "    features_key = list(config[\"features_dict\"].keys())[0]\n",
    "    covariates_key = (\n",
    "        list(config[\"covariates_dict\"].keys())[0] if config[\"covariates_dict\"] else None\n",
    "    )\n",
    "\n",
    "    dataset = TableDatasetModule(\n",
    "        train=train_imputed,\n",
    "        test=test_imputed,\n",
    "        features=config[\"features_dict\"][features_key],\n",
    "        covariates=(\n",
    "            config[\"covariates_dict\"][covariates_key]\n",
    "            if config[\"covariates_dict\"]\n",
    "            else None\n",
    "        ),\n",
    "        label=[\"incident_cad\"],\n",
    "        num_classes=2,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "    )\n",
    "    # model = FullyConnectedNet(\n",
    "    #     input_size=len(proteomics),\n",
    "    #     hidden_size=config[\"hidden_size\"],\n",
    "    #     output_size=2,\n",
    "    #     lr=config[\"lr\"],\n",
    "    #     weight_decay=config[\"weight_decay\"],\n",
    "    #     weight=config[\"weight\"],\n",
    "    #     num_resblocks=config[\"num_resblocks\"],\n",
    "    # )\n",
    "    # model = FullyConnectedNet(**config)\n",
    "    model = LinearTransformerPL(**config)\n",
    "    trainer = Trainer(\n",
    "        devices=\"auto\",\n",
    "        strategy=RayDDPStrategy(),\n",
    "        callbacks=[RayTrainReportCallback()],\n",
    "        plugins=[RayLightningEnvironment()],\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "    trainer = prepare_trainer(trainer)\n",
    "    trainer.fit(model, dataset)\n",
    "\n",
    "\n",
    "LinearTransformerPL_search_space = {\n",
    "    \"features_dict\": {\"proteomics\": proteomics},\n",
    "    \"covariates_dict\": tune.choice([{\"risk_factors\": risk_factors}, None]),\n",
    "    \"d_ff\": tune.choice([64, 128, 256, 512]),\n",
    "    \"num_classes\": 2,\n",
    "    \"num_layers\": tune.choice([1, 2, 3, 4, 5]),\n",
    "    \"dropout\": tune.uniform(0.1, 0.5),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"weight_decay\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"weight\": tune.choice([[1, 1], [0.1, 1], [0.1, 10], [0.1, 100]]),\n",
    "    \"batch_size\": tune.choice([64, 256]),\n",
    "}\n",
    "\n",
    "\n",
    "search_space = LinearTransformerPL_search_space\n",
    "\n",
    "\n",
    "# The maximum training epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Number of sampls from parameter space\n",
    "num_samples = 2\n",
    "scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)\n",
    "\n",
    "\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=1, use_gpu=True, resources_per_worker={\"CPU\": 3, \"GPU\": 0.99}\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        num_to_keep=2,\n",
    "        checkpoint_score_attribute=\"ptl/val_auc\",\n",
    "        checkpoint_score_order=\"max\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define a TorchTrainer without hyper-parameters for Tuner\n",
    "ray_trainer = TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "\n",
    "def tune_asha(num_samples=10):\n",
    "    scheduler = ASHAScheduler(max_t=num_epochs, grace_period=1, reduction_factor=2)\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        ray_trainer,\n",
    "        param_space={\"train_loop_config\": search_space},\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"ptl/val_auc\",\n",
    "            mode=\"max\",\n",
    "            num_samples=num_samples,\n",
    "            scheduler=scheduler,\n",
    "        ),\n",
    "    )\n",
    "    return tuner.fit()\n",
    "\n",
    "\n",
    "results = tune_asha(num_samples=num_samples)\n",
    "\n",
    "\n",
    "# results.get_best_result(\"ptl/val_auc\")\n",
    "\n",
    "best_result = results.get_best_result(\"ptl/val_auc\")\n",
    "best_params = best_result.config\n",
    "best_result_epoch_dir = (\n",
    "    best_result.get_best_checkpoint(\"ptl/val_auc\", \"max\").path + \"/checkpoint.ckpt\"\n",
    ")\n",
    "best_model_state = torch.load(best_result_epoch_dir)\n",
    "best_model = LinearTransformerPL(**best_params[\"train_loop_config\"])\n",
    "best_model.load_state_dict(best_model_state[\"state_dict\"])\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptl/val_loss</th>\n",
       "      <th>ptl/val_auc</th>\n",
       "      <th>ptl/train_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>...</th>\n",
       "      <th>config/train_loop_config/num_classes</th>\n",
       "      <th>config/train_loop_config/num_layers</th>\n",
       "      <th>config/train_loop_config/dropout</th>\n",
       "      <th>config/train_loop_config/lr</th>\n",
       "      <th>config/train_loop_config/weight_decay</th>\n",
       "      <th>config/train_loop_config/weight</th>\n",
       "      <th>config/train_loop_config/batch_size</th>\n",
       "      <th>ptl/train_auc</th>\n",
       "      <th>logdir</th>\n",
       "      <th>config/train_loop_config/covariates_dict/risk_factors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.236837</td>\n",
       "      <td>0.501361</td>\n",
       "      <td>0.256112</td>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>1713422159</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.118666</td>\n",
       "      <td>0.083419</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>[0.1, 1]</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26cec_00001</td>\n",
       "      <td>[age, sex, ldl_a, hdl_a, tc_a, tg_a, sbp_a, BM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.654624</td>\n",
       "      <td>0.632138</td>\n",
       "      <td>0.364551</td>\n",
       "      <td>19</td>\n",
       "      <td>9000</td>\n",
       "      <td>1713422136</td>\n",
       "      <td>checkpoint_000019</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.173362</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>[0.1, 100]</td>\n",
       "      <td>64</td>\n",
       "      <td>0.649011</td>\n",
       "      <td>26cec_00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ptl/val_loss  ptl/val_auc  ptl/train_loss  epoch  step   timestamp  \\\n",
       "1      0.236837     0.501361        0.256112      0   450  1713422159   \n",
       "0      0.654624     0.632138        0.364551     19  9000  1713422136   \n",
       "\n",
       "  checkpoint_dir_name  should_checkpoint  done  training_iteration  ...  \\\n",
       "1   checkpoint_000000               True  True                   1  ...   \n",
       "0   checkpoint_000019               True  True                  20  ...   \n",
       "\n",
       "  config/train_loop_config/num_classes config/train_loop_config/num_layers  \\\n",
       "1                                    2                                   2   \n",
       "0                                    2                                   4   \n",
       "\n",
       "   config/train_loop_config/dropout  config/train_loop_config/lr  \\\n",
       "1                          0.118666                     0.083419   \n",
       "0                          0.173362                     0.000818   \n",
       "\n",
       "   config/train_loop_config/weight_decay config/train_loop_config/weight  \\\n",
       "1                               0.000292                        [0.1, 1]   \n",
       "0                               0.001121                      [0.1, 100]   \n",
       "\n",
       "  config/train_loop_config/batch_size  ptl/train_auc       logdir  \\\n",
       "1                                  64            NaN  26cec_00001   \n",
       "0                                  64       0.649011  26cec_00000   \n",
       "\n",
       "  config/train_loop_config/covariates_dict/risk_factors  \n",
       "1  [age, sex, ldl_a, hdl_a, tc_a, tg_a, sbp_a, BM...     \n",
       "0                                                NaN     \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_dataframe().sort_values(\"ptl/val_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearTransformerPL(\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       "  (model): LinearTransformer(\n",
       "    (encoder): LinearTransformerEncoder(\n",
       "      (layers): Sequential(\n",
       "        (0): LinearResBlock(\n",
       "          (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "          (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=2911, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=2911, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          (dropout2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "        )\n",
       "        (1): LinearResBlock(\n",
       "          (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "          (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=2911, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=2911, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          (dropout2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "        )\n",
       "        (2): LinearResBlock(\n",
       "          (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "          (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=2911, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=2911, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          (dropout2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "        )\n",
       "        (3): LinearResBlock(\n",
       "          (fc1): Linear(in_features=2911, out_features=2911, bias=True)\n",
       "          (norm1): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=2911, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            (3): Linear(in_features=128, out_features=2911, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((2911,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          (dropout2): Dropout(p=0.17336180394137352, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (fc_norm): LayerNorm((2911,), eps=1e-06, elementwise_affine=True)\n",
       "      (head_drop): Dropout(p=0.17336180394137352, inplace=False)\n",
       "      (head): Linear(in_features=2911, out_features=128, bias=True)\n",
       "    )\n",
       "    (decoder): LinearFeatureFusionBlock(\n",
       "      (EachPartModuleList): ModuleList(\n",
       "        (0): LinearFeatureExtractor(\n",
       "          (extractor): Sequential(\n",
       "            (0): LinearActivationNormDropOut(\n",
       "              (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation): SiLU()\n",
       "              (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            )\n",
       "            (1): LinearActivationNormDropOut(\n",
       "              (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation): SiLU()\n",
       "              (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            )\n",
       "            (2): LinearActivationNormDropOut(\n",
       "              (fc): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation): SiLU()\n",
       "              (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fusionDecoder): LinearFeatureExtractor(\n",
       "        (extractor): Sequential(\n",
       "          (0): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          )\n",
       "          (1): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          )\n",
       "          (2): LinearActivationNormDropOut(\n",
       "            (fc): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): SiLU()\n",
       "            (dropout): Dropout(p=0.17336180394137352, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "    (head_drop): Dropout(p=0.17336180394137352, inplace=False)\n",
       "    (head): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results.get_best_result(\"ptl/val_auc\")\n",
    "\n",
    "best_result = results.get_best_result(\"ptl/val_auc\")\n",
    "best_params = best_result.config\n",
    "best_result_epoch_dir = (\n",
    "    best_result.get_best_checkpoint(\"ptl/val_auc\", \"max\").path + \"/checkpoint.ckpt\"\n",
    ")\n",
    "best_model_state = torch.load(best_result_epoch_dir)\n",
    "best_model = LinearTransformerPL(**best_params[\"train_loop_config\"])\n",
    "best_model.load_state_dict(best_model_state[\"state_dict\"])\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': ['C3',\n",
       "  'KLK7',\n",
       "  'GCHFR',\n",
       "  'NHLRC3',\n",
       "  'APOD',\n",
       "  'GAPDH',\n",
       "  'TP53I3',\n",
       "  'CPA4',\n",
       "  'ANXA2',\n",
       "  'GRSF1',\n",
       "  'IL25',\n",
       "  'HMMR',\n",
       "  'MRPL52',\n",
       "  'PAIP2B',\n",
       "  'THAP12',\n",
       "  'FOS',\n",
       "  'FGF9',\n",
       "  'PITHD1',\n",
       "  'THSD1',\n",
       "  'PTGES2',\n",
       "  'DEFB103A_DEFB103B',\n",
       "  'ATP1B4',\n",
       "  'CYB5A',\n",
       "  'UNC79',\n",
       "  'SLC34A3',\n",
       "  'TAGLN3',\n",
       "  'SLIRP',\n",
       "  'CLASP1',\n",
       "  'PSMC3',\n",
       "  'KIR3DL2',\n",
       "  'BEX3',\n",
       "  'PFDN4',\n",
       "  'BCL7A',\n",
       "  'SMC3',\n",
       "  'SLC28A1',\n",
       "  'CDC123',\n",
       "  'GJA8',\n",
       "  'NMRK2',\n",
       "  'GATA3',\n",
       "  'CPLX2',\n",
       "  'RASGRF1',\n",
       "  'FGF7',\n",
       "  'ANKRA2',\n",
       "  'RBM25',\n",
       "  'LYZL2',\n",
       "  'CDK1',\n",
       "  'CREB3',\n",
       "  'CREBZF',\n",
       "  'IGLON5',\n",
       "  'SHC1',\n",
       "  'ZP4',\n",
       "  'TMOD4',\n",
       "  'CEP152',\n",
       "  'MYH7B',\n",
       "  'CEP350',\n",
       "  'CDC25A',\n",
       "  'TRIM26',\n",
       "  'MANEAL',\n",
       "  'MUCL3',\n",
       "  'GIMAP8',\n",
       "  'CYTH3',\n",
       "  'PDXDC1',\n",
       "  'CLINT1',\n",
       "  'MAPRE3',\n",
       "  'EVI2B',\n",
       "  'STAU1',\n",
       "  'PCNA',\n",
       "  'DNAJA1',\n",
       "  'JMJD1C',\n",
       "  'GAGE2A',\n",
       "  'GAD1',\n",
       "  'IZUMO1',\n",
       "  'PDCL2',\n",
       "  'PDE1C',\n",
       "  'STOML2',\n",
       "  'BSND',\n",
       "  'MAPK13',\n",
       "  'PDIA2',\n",
       "  'BTLA',\n",
       "  'MLLT1',\n",
       "  'TPRKB',\n",
       "  'ARHGAP5',\n",
       "  'BTNL10',\n",
       "  'PHLDB2',\n",
       "  'PDIA5',\n",
       "  'ATF4',\n",
       "  'PRAME',\n",
       "  'TOP1MT',\n",
       "  'KHDC3L',\n",
       "  'DCUN1D2',\n",
       "  'IL3',\n",
       "  'DCLRE1C',\n",
       "  'ERCC1',\n",
       "  'DCDC2C',\n",
       "  'VCPKMT',\n",
       "  'SPRING1',\n",
       "  'MORN4',\n",
       "  'ESPL1',\n",
       "  'H2AP',\n",
       "  'MORF4L2',\n",
       "  'SSH3',\n",
       "  'VWA5A',\n",
       "  'PBK',\n",
       "  'REST',\n",
       "  'SHD',\n",
       "  'TXNL1',\n",
       "  'TPM3',\n",
       "  'NEB',\n",
       "  'ATP1B2',\n",
       "  'CEP112',\n",
       "  'SART1',\n",
       "  'ATP6V1G2',\n",
       "  'ATP2B4',\n",
       "  'SAT1',\n",
       "  'ATP1B1',\n",
       "  'NECAP2',\n",
       "  'ATP5F1D',\n",
       "  'ATP1B3',\n",
       "  'ARNTL',\n",
       "  'ARL2BP',\n",
       "  'SCGB2A2',\n",
       "  'GAMT',\n",
       "  'ASS1',\n",
       "  'NFYA',\n",
       "  'GASK1A',\n",
       "  'MANSC4',\n",
       "  'HMGCS1',\n",
       "  'MMUT',\n",
       "  'CBX2',\n",
       "  'BRD3',\n",
       "  'BRDT',\n",
       "  'MAP1LC3B2',\n",
       "  'CASQ2',\n",
       "  'HIP1',\n",
       "  'GSTM4',\n",
       "  'GUK1',\n",
       "  'CALY',\n",
       "  'C1GALT1C1',\n",
       "  'TEF',\n",
       "  'CACNA1H',\n",
       "  'HADH',\n",
       "  'MEGF11',\n",
       "  'MED21',\n",
       "  'THRAP3',\n",
       "  'SPINK8',\n",
       "  'NAA10',\n",
       "  'MRPL24',\n",
       "  'GBP6',\n",
       "  'MYOM2',\n",
       "  'B3GAT3',\n",
       "  'GCLM',\n",
       "  'MYL1',\n",
       "  'HSD17B3',\n",
       "  'MYH4',\n",
       "  'TMED4',\n",
       "  'TMED10',\n",
       "  'SKIV2L',\n",
       "  'SLC12A2',\n",
       "  'SLC51B',\n",
       "  'MTR',\n",
       "  'CD2',\n",
       "  'BHMT2',\n",
       "  'SNU13',\n",
       "  'GP1BB',\n",
       "  'ARL13B',\n",
       "  'HCG22',\n",
       "  'RYR1',\n",
       "  'FDX2',\n",
       "  'ADRA2A',\n",
       "  'ERVV-1',\n",
       "  'EXOSC10',\n",
       "  'EXTL1',\n",
       "  'CYP24A1',\n",
       "  'KIF1C',\n",
       "  'USP47',\n",
       "  'PRKD2',\n",
       "  'PROCR',\n",
       "  'PACS2',\n",
       "  'KIF22',\n",
       "  'NXPE4',\n",
       "  'RTKN2',\n",
       "  'CSRP3',\n",
       "  'NUDT15',\n",
       "  'UHRF2',\n",
       "  'UGDH',\n",
       "  'CSF2',\n",
       "  'KRT17',\n",
       "  'FDX1',\n",
       "  'PYY',\n",
       "  'UBQLN3',\n",
       "  'CSDE1',\n",
       "  'DDA1',\n",
       "  'PALM3',\n",
       "  'VSIG10L',\n",
       "  'PKD2',\n",
       "  'ABCA2',\n",
       "  'EDEM2',\n",
       "  'ABRAXAS2',\n",
       "  'ECI2',\n",
       "  'PGLYRP4',\n",
       "  'PDZD2',\n",
       "  'EIF2AK3',\n",
       "  'EIF5',\n",
       "  'ELOB',\n",
       "  'ITPA',\n",
       "  'ACSL1',\n",
       "  'DENND2B',\n",
       "  'ZCCHC8',\n",
       "  'ACTN2',\n",
       "  'PDE4D',\n",
       "  'ACY3',\n",
       "  'ENOX2',\n",
       "  'YOD1',\n",
       "  'ENPEP',\n",
       "  'PMCH',\n",
       "  'PMM2',\n",
       "  'DHODH',\n",
       "  'KRT6C',\n",
       "  'NUP50',\n",
       "  'LAMA1',\n",
       "  'COPB2',\n",
       "  'LRCH4',\n",
       "  'TSNAX',\n",
       "  'LPP',\n",
       "  'TRPV3',\n",
       "  'IGHMBP2',\n",
       "  'LILRA4',\n",
       "  'FHIP2A',\n",
       "  'NOP56',\n",
       "  'RIPK4',\n",
       "  'TRAF3IP2',\n",
       "  'IGF2BP3',\n",
       "  'NFKB1',\n",
       "  'NFX1',\n",
       "  'REXO2',\n",
       "  'TSPAN15',\n",
       "  'RBM19',\n",
       "  'FRMD4B',\n",
       "  'NOS2',\n",
       "  'TPR',\n",
       "  'NPR1',\n",
       "  'RAB33A',\n",
       "  'RAB39B',\n",
       "  'RPS10',\n",
       "  'ANK2',\n",
       "  'IFNW1',\n",
       "  'CPTP',\n",
       "  'TTN',\n",
       "  'IL36G',\n",
       "  'IL31RA',\n",
       "  'RNASE4',\n",
       "  'LRIG3',\n",
       "  'CACNA1C',\n",
       "  'SCIN',\n",
       "  'DNLZ',\n",
       "  'STEAP4',\n",
       "  'CBLN1',\n",
       "  'CHP1',\n",
       "  'SAG',\n",
       "  'DOCK9',\n",
       "  'RRP15',\n",
       "  'SYNGAP1',\n",
       "  'CNTF',\n",
       "  'ECSCR',\n",
       "  'ELAVL4',\n",
       "  'FZD8',\n",
       "  'SCN2A',\n",
       "  'CNGB3',\n",
       "  'GABRA4',\n",
       "  'CACNB1',\n",
       "  'DEFB118',\n",
       "  'PNMA2',\n",
       "  'SMS',\n",
       "  'CDH4',\n",
       "  'SH3BGRL2',\n",
       "  'RAB3GAP1',\n",
       "  'RANBP2',\n",
       "  'MYOM1',\n",
       "  'CDKL5',\n",
       "  'CSPG5',\n",
       "  'CTNNA1',\n",
       "  'OMP',\n",
       "  'OTOA',\n",
       "  'GLP1R',\n",
       "  'CEND1',\n",
       "  'SNAP25',\n",
       "  'PCARE',\n",
       "  'FH',\n",
       "  'CORO6',\n",
       "  'SCN3B',\n",
       "  'DCUN1D1',\n",
       "  'NLGN2',\n",
       "  'DEFB104A_DEFB104B',\n",
       "  'DEFB116',\n",
       "  'CRYM',\n",
       "  'SPTBN2',\n",
       "  'GPR101',\n",
       "  'DGCR6',\n",
       "  'GRIN2B',\n",
       "  'ZPR1',\n",
       "  'CD3D',\n",
       "  'HTR1A',\n",
       "  'TFAP2A',\n",
       "  'BLOC1S2',\n",
       "  'IMPG1',\n",
       "  'BRME1',\n",
       "  'KLRC1',\n",
       "  'HTR1B',\n",
       "  'IFNL2',\n",
       "  'VAV3',\n",
       "  'ITPRIP',\n",
       "  'KLF4',\n",
       "  'KIF20B',\n",
       "  'ATXN2',\n",
       "  'TSPAN7',\n",
       "  'BCAT2',\n",
       "  'IGDCC3',\n",
       "  'LELP1',\n",
       "  'TMPRSS11B',\n",
       "  'KCNC4',\n",
       "  'MAP1LC3A',\n",
       "  'BRD2',\n",
       "  'LYPLA2',\n",
       "  'BOLA1',\n",
       "  'ART5',\n",
       "  'AGBL2',\n",
       "  'UPK3A',\n",
       "  'IL13RA2',\n",
       "  'HDAC9',\n",
       "  'ARMCX2',\n",
       "  'KIRREL1',\n",
       "  'TJP3',\n",
       "  'TUBB3',\n",
       "  'ARID3A',\n",
       "  'KRT8',\n",
       "  'BHLHE40',\n",
       "  'ARHGEF5',\n",
       "  'ADGRV1',\n",
       "  'LMOD2',\n",
       "  'GFRAL',\n",
       "  'DNAJB6',\n",
       "  'CD7',\n",
       "  'NAGA',\n",
       "  'PTPN9',\n",
       "  'NDUFA5',\n",
       "  'SCPEP1',\n",
       "  'PRR4',\n",
       "  'CSF3R',\n",
       "  'UNC5D',\n",
       "  'TYRP1',\n",
       "  'SHH',\n",
       "  'GLI2',\n",
       "  'GIPR',\n",
       "  'UBE2Z',\n",
       "  'GAD2',\n",
       "  'SLITRK1',\n",
       "  'BCL2L15',\n",
       "  'TLR1',\n",
       "  'EDNRB',\n",
       "  'NUMB',\n",
       "  'ALPI',\n",
       "  'KLRF1',\n",
       "  'SIRT1',\n",
       "  'HS6ST2',\n",
       "  'GIT1',\n",
       "  'CD36',\n",
       "  'TLR4',\n",
       "  'CSNK1D',\n",
       "  'CSF2RB',\n",
       "  'CD3G',\n",
       "  'RNF168',\n",
       "  'RAP1A',\n",
       "  'FGF12',\n",
       "  'REPS1',\n",
       "  'FOLH1',\n",
       "  'RICTOR',\n",
       "  'TRAF3',\n",
       "  'NFAT5',\n",
       "  'FOXJ3',\n",
       "  'CEBPA',\n",
       "  'TPSG1',\n",
       "  'NEDD9',\n",
       "  'RNF31',\n",
       "  'CEMIP2',\n",
       "  'RPA2',\n",
       "  'CLEC12A',\n",
       "  'NEDD4L',\n",
       "  'S100A13',\n",
       "  'NECTIN1',\n",
       "  'TOP2B',\n",
       "  'TP53BP1',\n",
       "  'SEMA6C',\n",
       "  'RELB',\n",
       "  'FGF16',\n",
       "  'NME1',\n",
       "  'NPHS2',\n",
       "  'NPHS1',\n",
       "  'FGF20',\n",
       "  'RALB',\n",
       "  'FGF3',\n",
       "  'IL12RB2',\n",
       "  'ANKMY2',\n",
       "  'FGF6',\n",
       "  'PTP4A3',\n",
       "  'BAG4',\n",
       "  'CPOX',\n",
       "  'TSPYL1',\n",
       "  'BABAM1',\n",
       "  'LATS1',\n",
       "  'TSC1',\n",
       "  'IGFL4',\n",
       "  'RBPMS',\n",
       "  'CD226',\n",
       "  'NXPH3',\n",
       "  'MTDH',\n",
       "  'DGKA',\n",
       "  'STX7',\n",
       "  'STX5',\n",
       "  'HIF1A',\n",
       "  'EIF4E',\n",
       "  'IL36A',\n",
       "  'CASP9',\n",
       "  'PGR',\n",
       "  'DENR',\n",
       "  'ST8SIA1',\n",
       "  'TGFBR1',\n",
       "  'KDM3A',\n",
       "  'PPL',\n",
       "  'DDX4',\n",
       "  'DDX39A',\n",
       "  'ACP1',\n",
       "  'PDZK1',\n",
       "  'SMPD3',\n",
       "  'MKI67',\n",
       "  'POLR2A',\n",
       "  'POF1B',\n",
       "  'PIKFYVE',\n",
       "  'C1QL2',\n",
       "  'ACRV1',\n",
       "  'ZBP1',\n",
       "  'PLCB1',\n",
       "  'YY1',\n",
       "  'ZNF174',\n",
       "  'ADAM12',\n",
       "  'XIAP',\n",
       "  'EP300',\n",
       "  'TERF1',\n",
       "  'ADAMTS1',\n",
       "  'WASL',\n",
       "  'SUMF1',\n",
       "  'ADAMTS4',\n",
       "  'PPM1B',\n",
       "  'STAT2',\n",
       "  'ERMAP',\n",
       "  'HDAC8',\n",
       "  'DAPK2',\n",
       "  'DAND5',\n",
       "  'IL21R',\n",
       "  'IL31',\n",
       "  'VAMP8',\n",
       "  'IL20RB',\n",
       "  'CCNE1',\n",
       "  'EVI5',\n",
       "  'MRPS16',\n",
       "  'PRR5',\n",
       "  'PRSS22',\n",
       "  'PSMG4',\n",
       "  'AKR7L',\n",
       "  'PER3',\n",
       "  'BLNK',\n",
       "  'CA8',\n",
       "  'DBN1',\n",
       "  'SPRED2',\n",
       "  'PALLD',\n",
       "  'SSBP1',\n",
       "  'BNIP3L',\n",
       "  'VEGFB',\n",
       "  'MCEMP1',\n",
       "  'ITGAL',\n",
       "  'INSR',\n",
       "  'ESR1',\n",
       "  'IFI30',\n",
       "  'CNP',\n",
       "  'NAGK',\n",
       "  'LAMP1',\n",
       "  'TP73',\n",
       "  'PGM2',\n",
       "  'DYNLT1',\n",
       "  'CHM',\n",
       "  'PFDN6',\n",
       "  'TPBGL',\n",
       "  'FZD10',\n",
       "  'CLIC5',\n",
       "  'DTX2',\n",
       "  'CLNS1A',\n",
       "  'RRAS',\n",
       "  'CLGN',\n",
       "  'PDRG1',\n",
       "  'RPGR',\n",
       "  'DUSP29',\n",
       "  'CLEC2L',\n",
       "  'EFNB2',\n",
       "  'CHRM1',\n",
       "  'CIT',\n",
       "  'LRFN2',\n",
       "  'AP2B1',\n",
       "  'FRMD7',\n",
       "  'CRTAP',\n",
       "  'PTH',\n",
       "  'FARSA',\n",
       "  'AKR1B10',\n",
       "  'PSMD5',\n",
       "  'FBN2',\n",
       "  'CUZD1',\n",
       "  'OSTN',\n",
       "  'UROS',\n",
       "  'AIDA',\n",
       "  'PRKAG3',\n",
       "  'NRXN3',\n",
       "  'AMIGO1',\n",
       "  'DCC',\n",
       "  'PPT1',\n",
       "  'ERC2',\n",
       "  'DOC2B',\n",
       "  'RAC3',\n",
       "  'DDX25',\n",
       "  'DDX53',\n",
       "  'TTF2',\n",
       "  'KCNH2',\n",
       "  'DIPK1C',\n",
       "  'RBP1',\n",
       "  'TRIM40',\n",
       "  'NLGN1',\n",
       "  'PMS1',\n",
       "  'COL28A1',\n",
       "  'EPB41L5',\n",
       "  'IFT20',\n",
       "  'CNTNAP4',\n",
       "  'LRP2',\n",
       "  'C2orf69',\n",
       "  'LYSMD3',\n",
       "  'MAG',\n",
       "  'MRI1',\n",
       "  'SCT',\n",
       "  'CASC3',\n",
       "  'LRTM1',\n",
       "  'SLC44A4',\n",
       "  'GTPBP2',\n",
       "  'TDO2',\n",
       "  'SLC1A4',\n",
       "  'SV2A',\n",
       "  'MFAP3L',\n",
       "  'GBA',\n",
       "  'SOX9',\n",
       "  'CAMLG',\n",
       "  'MN1',\n",
       "  'CABP2',\n",
       "  'CCDC28A',\n",
       "  'TMCO5A',\n",
       "  'NAA80',\n",
       "  'TEX101',\n",
       "  'STX1B',\n",
       "  'BATF',\n",
       "  'CADPS',\n",
       "  'LRRC38',\n",
       "  'SEZ6',\n",
       "  'MSLNL',\n",
       "  'MYL6B',\n",
       "  'MDM1',\n",
       "  'SOWAHA',\n",
       "  'LRP2BP',\n",
       "  'SCN2B',\n",
       "  'CD164L2',\n",
       "  'TBR1',\n",
       "  'MYLPF',\n",
       "  'CGN',\n",
       "  'TARM1',\n",
       "  'MICALL2',\n",
       "  'GNGT1',\n",
       "  'SCN3A',\n",
       "  'HNF1A',\n",
       "  'ANXA1',\n",
       "  'SUSD5',\n",
       "  'RBPMS2',\n",
       "  'RANBP1',\n",
       "  'COQ7',\n",
       "  'MYBPC2',\n",
       "  'DMP1',\n",
       "  'ANP32C',\n",
       "  'PRRT3',\n",
       "  'PNMA1',\n",
       "  'HSDL2',\n",
       "  'TMEM132A',\n",
       "  'IGSF21',\n",
       "  'MYL4',\n",
       "  'DLL4',\n",
       "  'DMD',\n",
       "  'MYL3',\n",
       "  'EDN1',\n",
       "  'GIP',\n",
       "  'HSBP1',\n",
       "  'BOLA2_BOLA2B',\n",
       "  'AIF1L',\n",
       "  'OXCT1',\n",
       "  'PAGR1',\n",
       "  'SNED1',\n",
       "  'OPLAH',\n",
       "  'GNPDA1',\n",
       "  'SNX5',\n",
       "  'AHNAK2',\n",
       "  'AHNAK',\n",
       "  'BECN1',\n",
       "  'FAM172A',\n",
       "  'VIPR1',\n",
       "  'HRC',\n",
       "  'KHK',\n",
       "  'POMC',\n",
       "  'HS1BP3',\n",
       "  'NUDT10',\n",
       "  'PYDC1',\n",
       "  'SIL1',\n",
       "  'HMGCL',\n",
       "  'SIGLEC8',\n",
       "  'CRYZL1',\n",
       "  'CCER2',\n",
       "  'LAMB1',\n",
       "  'GRP',\n",
       "  'CBS',\n",
       "  'ADAMTSL4',\n",
       "  'EPPK1',\n",
       "  'LIPF',\n",
       "  'B3GNT7',\n",
       "  'RECK',\n",
       "  'SCRIB',\n",
       "  'SEC31A',\n",
       "  'RNF149',\n",
       "  'COMMD1',\n",
       "  'ATP6V1G1',\n",
       "  'RNF5',\n",
       "  'ROBO4',\n",
       "  'FSHB',\n",
       "  'RPL14',\n",
       "  'CEP170',\n",
       "  'AAMDC',\n",
       "  'EIF2S2',\n",
       "  'SCN4B',\n",
       "  'SEL1L',\n",
       "  'INPP5D',\n",
       "  'FSTL1',\n",
       "  'EHD3',\n",
       "  'PECR',\n",
       "  'ECHS1',\n",
       "  'MECR',\n",
       "  'TOR1AIP1',\n",
       "  'ASRGL1',\n",
       "  'IDO1',\n",
       "  'ZP3',\n",
       "  'GADD45GIP1',\n",
       "  'RNASE10',\n",
       "  'MAN1A2',\n",
       "  'COL2A1',\n",
       "  'NIT1',\n",
       "  'ITPR1',\n",
       "  'ENPP6',\n",
       "  'ENO3',\n",
       "  'LONP1',\n",
       "  'DNAJC6',\n",
       "  'NFE2',\n",
       "  'ENTR1',\n",
       "  'GATD3',\n",
       "  'M6PR',\n",
       "  'CALCOCO2',\n",
       "  'APOBR',\n",
       "  'ECM1',\n",
       "  'ACYP1',\n",
       "  'WFDC1',\n",
       "  'GM2A',\n",
       "  'PLG',\n",
       "  'SH3GL3',\n",
       "  'PCBD1',\n",
       "  'RLN2',\n",
       "  'C1QTNF9',\n",
       "  'SERPINI1',\n",
       "  'GLA',\n",
       "  'CACYBP',\n",
       "  'MARS1',\n",
       "  'HMCN2',\n",
       "  'C7',\n",
       "  'LPA',\n",
       "  'FGA',\n",
       "  'CLEC3B',\n",
       "  'PAXX',\n",
       "  'C1QTNF5',\n",
       "  'MENT',\n",
       "  'ADGRD1',\n",
       "  'VTI1A',\n",
       "  'DAAM1',\n",
       "  'GNPDA2',\n",
       "  'PENK',\n",
       "  'SYAP1',\n",
       "  'ADD1',\n",
       "  'PINLYP',\n",
       "  'JAM3',\n",
       "  'PRKG1',\n",
       "  'ITGA2',\n",
       "  'DNAJB2',\n",
       "  'SNX15',\n",
       "  'DIPK2B',\n",
       "  'TBCA',\n",
       "  'GP5',\n",
       "  'YWHAQ',\n",
       "  'PDE5A',\n",
       "  'DTD1',\n",
       "  'DDI2',\n",
       "  'ADH1B',\n",
       "  'ST13',\n",
       "  'INHBB',\n",
       "  'ERP29',\n",
       "  'PHYKPL',\n",
       "  'MOCS2',\n",
       "  'AFAP1',\n",
       "  'SPART',\n",
       "  'HEG1',\n",
       "  'BMPER',\n",
       "  'PDIA3',\n",
       "  'DCTD',\n",
       "  'MFAP4',\n",
       "  'BMP10',\n",
       "  'SPINK2',\n",
       "  'EPHA4',\n",
       "  'ACHE',\n",
       "  'CHAD',\n",
       "  'UBXN1',\n",
       "  'TNFRSF17',\n",
       "  'SLC9A3R1',\n",
       "  'LZTFL1',\n",
       "  'ARHGAP45',\n",
       "  'AMOT',\n",
       "  'CD72',\n",
       "  'CELSR2',\n",
       "  'GIMAP7',\n",
       "  'SDK2',\n",
       "  'GHR',\n",
       "  'RABEP1',\n",
       "  'CD300A',\n",
       "  'SEMA3G',\n",
       "  'CRELD1',\n",
       "  'RIDA',\n",
       "  'SFRP4',\n",
       "  'MXRA8',\n",
       "  'APPL2',\n",
       "  'MYOM3',\n",
       "  'FGFR4',\n",
       "  'TNFAIP8L2',\n",
       "  'PTRHD1',\n",
       "  'COL5A1',\n",
       "  'FUOM',\n",
       "  'AKAP12',\n",
       "  'CTSE',\n",
       "  'SCGB3A1',\n",
       "  'TPD52L2',\n",
       "  'NAGPA',\n",
       "  'UROD',\n",
       "  'GMPR2',\n",
       "  'SNCA',\n",
       "  'GLRX5',\n",
       "  'KCTD5',\n",
       "  'UPK3BL1',\n",
       "  'TRIM24',\n",
       "  'CTAG1A_CTAG1B',\n",
       "  'FUT1',\n",
       "  'HRAS',\n",
       "  'TET2',\n",
       "  'COL4A4',\n",
       "  'TCN1',\n",
       "  'KLKB1',\n",
       "  'QSOX1',\n",
       "  'CEACAM18',\n",
       "  'EFCAB2',\n",
       "  'NEK7',\n",
       "  'NFKB2',\n",
       "  'CEACAM20',\n",
       "  'RGL2',\n",
       "  'SEPTIN7',\n",
       "  'SAP18',\n",
       "  'ARAF',\n",
       "  'GABARAPL1',\n",
       "  'SAT2',\n",
       "  'ARHGAP30',\n",
       "  'TRDMT1',\n",
       "  'ID4',\n",
       "  'PKN3',\n",
       "  'MAPKAPK2',\n",
       "  'TNPO1',\n",
       "  'TAP1',\n",
       "  'TCP11',\n",
       "  'ITGAX',\n",
       "  'IFIT3',\n",
       "  'ACADM',\n",
       "  'CEP290',\n",
       "  'TAB2',\n",
       "  'GAS2',\n",
       "  'RPE',\n",
       "  'ZNF75D',\n",
       "  'LSM8',\n",
       "  'CENPJ',\n",
       "  'CINP',\n",
       "  'RNF43',\n",
       "  'IFIT1',\n",
       "  'CA7',\n",
       "  'RNF4',\n",
       "  'CENPF',\n",
       "  'TPPP2',\n",
       "  'IL9',\n",
       "  'PAFAH2',\n",
       "  'EPN1',\n",
       "  'COL9A2',\n",
       "  'PPIE',\n",
       "  'TLR2',\n",
       "  'MNAT1',\n",
       "  'ERI1',\n",
       "  'CD3E',\n",
       "  'MAGEA3',\n",
       "  'ALMS1',\n",
       "  'PPP1R12B',\n",
       "  'VPS28',\n",
       "  'PTTG1',\n",
       "  'MORF4L1',\n",
       "  'KIAA1549',\n",
       "  'SPRR1B',\n",
       "  'SLK',\n",
       "  'TK1',\n",
       "  'OFD1',\n",
       "  'KIAA1549L',\n",
       "  'MTHFSD',\n",
       "  'EVPL',\n",
       "  'GADD45B',\n",
       "  'TIGIT',\n",
       "  'CCND2',\n",
       "  'BRD1',\n",
       "  'SHPK',\n",
       "  'VSTM2B',\n",
       "  'TEX33',\n",
       "  'GUCY2C',\n",
       "  'CDH22',\n",
       "  'SERPINH1',\n",
       "  'RAPGEF2',\n",
       "  'PRUNE2',\n",
       "  'MTUS1',\n",
       "  'TMED1',\n",
       "  'GTF2IRD1',\n",
       "  'CASP4',\n",
       "  'OGT',\n",
       "  'RAD51',\n",
       "  'TXK',\n",
       "  'PARD3',\n",
       "  'CD82',\n",
       "  'BCHE',\n",
       "  'SERPINF2',\n",
       "  'SERPINA1',\n",
       "  'SERPINA4',\n",
       "  'SGSH',\n",
       "  'CFB',\n",
       "  'NPC2',\n",
       "  'PRDX2',\n",
       "  'TXN',\n",
       "  'CYB5R2',\n",
       "  'MST1',\n",
       "  'CAT',\n",
       "  'CTBS',\n",
       "  'SERPINF1',\n",
       "  'BRAP',\n",
       "  'HPSE',\n",
       "  'SERPINA5',\n",
       "  'F11',\n",
       "  'MBL2',\n",
       "  'CFHR5',\n",
       "  'IST1',\n",
       "  'PGLYRP2',\n",
       "  'CWC15',\n",
       "  'PALM',\n",
       "  'TTR',\n",
       "  'PSAP',\n",
       "  'ASAH1',\n",
       "  'HGFAC',\n",
       "  'AMOTL2',\n",
       "  'CRISP3',\n",
       "  'NMI',\n",
       "  'EIF2AK2',\n",
       "  'APCS',\n",
       "  'SLURP1',\n",
       "  'DTNB',\n",
       "  'LACRT',\n",
       "  'BTN1A1',\n",
       "  'THTPA',\n",
       "  'MPRIP',\n",
       "  'KLK15',\n",
       "  'RNASE6',\n",
       "  'NAP1L4',\n",
       "  'CDC26',\n",
       "  'LMNB1',\n",
       "  'NUDT16',\n",
       "  'PPBP',\n",
       "  'PF4',\n",
       "  'CFHR2',\n",
       "  'GSR',\n",
       "  'MDH1',\n",
       "  'IL2RG',\n",
       "  'REG3G',\n",
       "  'FNTA',\n",
       "  'RFC4',\n",
       "  'CMIP',\n",
       "  'NUBP1',\n",
       "  'FAM171B',\n",
       "  'NENF',\n",
       "  'AHSA1',\n",
       "  'IL22',\n",
       "  'COMMD9',\n",
       "  'VSIG10',\n",
       "  'KIAA2013',\n",
       "  'RCC1',\n",
       "  'ALDH2',\n",
       "  'UNG',\n",
       "  'VPS4B',\n",
       "  'RALY',\n",
       "  'RAB44',\n",
       "  'PXDNL',\n",
       "  'RAB2B',\n",
       "  'VSIG2',\n",
       "  'KIR2DL2',\n",
       "  'USP25',\n",
       "  'UBE2B',\n",
       "  'LARP1',\n",
       "  'S100A3',\n",
       "  'TDP1',\n",
       "  'CAPN3',\n",
       "  'MINDY1',\n",
       "  'SUSD4',\n",
       "  'TADA3',\n",
       "  'TARS1',\n",
       "  'LRRFIP1',\n",
       "  'TG',\n",
       "  'STAM',\n",
       "  'TGFB2',\n",
       "  'LTB',\n",
       "  'LUZP2',\n",
       "  'MAMDC4',\n",
       "  'HSPA2',\n",
       "  'BCL7B',\n",
       "  'CCDC134',\n",
       "  'GPRC5C',\n",
       "  'LAMTOR5',\n",
       "  'MTSS2',\n",
       "  'NDST1',\n",
       "  'GABARAP',\n",
       "  'CHCHD6',\n",
       "  'NACC1',\n",
       "  'AP1G2',\n",
       "  'TRIM58',\n",
       "  'SLC13A1',\n",
       "  'GPD1',\n",
       "  'SMAD2',\n",
       "  'SMAD3',\n",
       "  'GLYR1',\n",
       "  'SMPDL3B',\n",
       "  'SNX2',\n",
       "  'ARG2',\n",
       "  'SDCCAG8',\n",
       "  'TMEM106A',\n",
       "  'ACRBP',\n",
       "  'DUSP13',\n",
       "  'DYNC1H1',\n",
       "  'EDDM3B',\n",
       "  'DYNLT3',\n",
       "  'WDR46',\n",
       "  'PCDHB15',\n",
       "  'EPGN',\n",
       "  'DHPS',\n",
       "  'IMMT',\n",
       "  'PRC1',\n",
       "  'PPP1CC',\n",
       "  'ERN1',\n",
       "  'ZNRF4',\n",
       "  'ZNF830',\n",
       "  'YJU2',\n",
       "  'PCSK7',\n",
       "  'INSL4',\n",
       "  'ENOPH1',\n",
       "  'ITIH5',\n",
       "  'ENSA',\n",
       "  'TMPRSS11D',\n",
       "  'FTCD',\n",
       "  'PLSCR3',\n",
       "  'SEPTIN8',\n",
       "  'PRKAR2A',\n",
       "  'SMTN',\n",
       "  'NFU1',\n",
       "  'PBXIP1',\n",
       "  'HIP1R',\n",
       "  'ZFYVE19',\n",
       "  ...],\n",
       " 'output_size': 2,\n",
       " 'hidden_size': 256,\n",
       " 'lr': 0.004443650319903527,\n",
       " 'weight_decay': 0.004365535526638243,\n",
       " 'weight': [1, 1],\n",
       " 'batch_size': 256,\n",
       " 'num_resblocks': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[\"train_loop_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input df have NA: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>PRS</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BSA</th>\n",
       "      <th>genotype_array</th>\n",
       "      <th>age</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>...</th>\n",
       "      <th>TGFBR3</th>\n",
       "      <th>CRTAC1</th>\n",
       "      <th>IGFBP7</th>\n",
       "      <th>SELE</th>\n",
       "      <th>VWF</th>\n",
       "      <th>NOTCH3</th>\n",
       "      <th>CNTN1</th>\n",
       "      <th>ENG</th>\n",
       "      <th>ICAM2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19409</th>\n",
       "      <td>2883530.0</td>\n",
       "      <td>1.030583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>64.2</td>\n",
       "      <td>1.746282</td>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>71.3002</td>\n",
       "      <td>-100.66700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>-0.029539</td>\n",
       "      <td>0.022568</td>\n",
       "      <td>-0.027118</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>-0.026825</td>\n",
       "      <td>0.999796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19272</th>\n",
       "      <td>2867444.0</td>\n",
       "      <td>2.192278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>55.8</td>\n",
       "      <td>1.599219</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-12.4815</td>\n",
       "      <td>3.16181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.291950</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>-0.120500</td>\n",
       "      <td>0.597300</td>\n",
       "      <td>0.115700</td>\n",
       "      <td>0.243300</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.991804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49865</th>\n",
       "      <td>5869793.0</td>\n",
       "      <td>0.653794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>77.3</td>\n",
       "      <td>1.916181</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-11.4721</td>\n",
       "      <td>2.20519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.369750</td>\n",
       "      <td>-0.155300</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>-0.276700</td>\n",
       "      <td>-0.043900</td>\n",
       "      <td>0.195500</td>\n",
       "      <td>-0.111000</td>\n",
       "      <td>-0.990800</td>\n",
       "      <td>0.999830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39664</th>\n",
       "      <td>4880838.0</td>\n",
       "      <td>0.664819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>84.4</td>\n",
       "      <td>1.954852</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-11.1640</td>\n",
       "      <td>3.66252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0127</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.873200</td>\n",
       "      <td>0.236600</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.999749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30555</th>\n",
       "      <td>3987428.0</td>\n",
       "      <td>0.826465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>73.1</td>\n",
       "      <td>1.824859</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-11.4666</td>\n",
       "      <td>2.77498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5216</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>-0.160200</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>1.026700</td>\n",
       "      <td>-0.062150</td>\n",
       "      <td>-0.094500</td>\n",
       "      <td>-0.032700</td>\n",
       "      <td>0.213200</td>\n",
       "      <td>0.999845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43327</th>\n",
       "      <td>5241912.0</td>\n",
       "      <td>1.085083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.381409</td>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-10.8083</td>\n",
       "      <td>4.46241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2348</td>\n",
       "      <td>-0.919950</td>\n",
       "      <td>0.803300</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.481500</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>-0.226200</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.999857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29129</th>\n",
       "      <td>3851862.0</td>\n",
       "      <td>1.294348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>72.9</td>\n",
       "      <td>1.849932</td>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-12.6549</td>\n",
       "      <td>3.40064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3290</td>\n",
       "      <td>-0.251250</td>\n",
       "      <td>-0.787400</td>\n",
       "      <td>-0.919000</td>\n",
       "      <td>0.212700</td>\n",
       "      <td>-0.617800</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>-0.124100</td>\n",
       "      <td>-0.940500</td>\n",
       "      <td>0.998148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>1144512.0</td>\n",
       "      <td>0.722791</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>2.263883</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-12.7237</td>\n",
       "      <td>1.46547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>-0.284750</td>\n",
       "      <td>0.350300</td>\n",
       "      <td>1.608600</td>\n",
       "      <td>-0.341300</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>0.999782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>1177099.0</td>\n",
       "      <td>1.335307</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>75.1</td>\n",
       "      <td>1.910679</td>\n",
       "      <td>2</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-15.1573</td>\n",
       "      <td>7.36690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.172250</td>\n",
       "      <td>0.431300</td>\n",
       "      <td>0.121750</td>\n",
       "      <td>-0.754900</td>\n",
       "      <td>0.530700</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>-0.018900</td>\n",
       "      <td>-0.053400</td>\n",
       "      <td>0.999728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29456</th>\n",
       "      <td>3881441.0</td>\n",
       "      <td>1.055519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>1.614715</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-12.4170</td>\n",
       "      <td>4.44358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.291350</td>\n",
       "      <td>-0.231600</td>\n",
       "      <td>-0.446000</td>\n",
       "      <td>-0.775500</td>\n",
       "      <td>0.385750</td>\n",
       "      <td>0.243300</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.227400</td>\n",
       "      <td>0.999232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15432 rows × 2974 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             eid       PRS  sex  height  weight       BSA  genotype_array  \\\n",
       "19409  2883530.0  1.030583  1.0   171.0    64.2  1.746282               2   \n",
       "19272  2867444.0  2.192278  0.0   165.0    55.8  1.599219               2   \n",
       "49865  5869793.0  0.653794  1.0   171.0    77.3  1.916181               2   \n",
       "39664  4880838.0  0.664819  0.0   163.0    84.4  1.954852               2   \n",
       "30555  3987428.0  0.826465  0.0   164.0    73.1  1.824859               1   \n",
       "...          ...       ...  ...     ...     ...       ...             ...   \n",
       "43327  5241912.0  1.085083  1.0   176.0   116.0  2.381409               2   \n",
       "29129  3851862.0  1.294348  0.0   169.0    72.9  1.849932               2   \n",
       "1550   1144512.0  0.722791  1.0   191.0    96.6  2.263883               1   \n",
       "1888   1177099.0  1.335307  1.0   175.0    75.1  1.910679               2   \n",
       "29456  3881441.0  1.055519  0.0   161.0    58.3  1.614715               2   \n",
       "\n",
       "        age      PC1        PC2  ...  TGFBR3    CRTAC1    IGFBP7      SELE  \\\n",
       "19409  44.0  71.3002 -100.66700  ... -0.0087 -0.029539  0.022568 -0.027118   \n",
       "19272  53.0 -12.4815    3.16181  ...  0.1859  0.291950  0.147400 -0.120500   \n",
       "49865  62.0 -11.4721    2.20519  ...  0.0516  0.369750 -0.155300  0.035500   \n",
       "39664  62.0 -11.1640    3.66252  ... -0.0127  0.393200  0.174500  0.035700   \n",
       "30555  66.0 -11.4666    2.77498  ... -0.5216  0.005050 -0.160200  0.181900   \n",
       "...     ...      ...        ...  ...     ...       ...       ...       ...   \n",
       "43327  45.0 -10.8083    4.46241  ...  0.2348 -0.919950  0.803300  0.131600   \n",
       "29129  40.0 -12.6549    3.40064  ... -0.3290 -0.251250 -0.787400 -0.919000   \n",
       "1550   59.0 -12.7237    1.46547  ...  0.1043 -0.284750  0.350300  1.608600   \n",
       "1888   63.0 -15.1573    7.36690  ...  0.2172  0.172250  0.431300  0.121750   \n",
       "29456  53.0 -12.4170    4.44358  ...  0.1298  0.291350 -0.231600 -0.446000   \n",
       "\n",
       "            VWF    NOTCH3     CNTN1       ENG     ICAM2      pred  \n",
       "19409  0.008048  0.004249  0.000619  0.001707 -0.026825  0.999796  \n",
       "19272  0.597300  0.115700  0.243300  0.127800  0.063400  0.991804  \n",
       "49865 -0.276700 -0.043900  0.195500 -0.111000 -0.990800  0.999830  \n",
       "39664  0.873200  0.236600  0.114200  0.134400  0.008700  0.999749  \n",
       "30555  1.026700 -0.062150 -0.094500 -0.032700  0.213200  0.999845  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "43327  0.481500  0.279800 -0.226200  0.262600  0.239400  0.999857  \n",
       "29129  0.212700 -0.617800  0.123900 -0.124100 -0.940500  0.998148  \n",
       "1550  -0.341300  0.134100 -0.012000  0.226700  0.135200  0.999782  \n",
       "1888  -0.754900  0.530700  0.244000 -0.018900 -0.053400  0.999728  \n",
       "29456 -0.775500  0.385750  0.243300  0.219200  0.227400  0.999232  \n",
       "\n",
       "[15432 rows x 2974 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imputed = best_model.predict_df(test_imputed)\n",
    "test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cal_binary_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcal_binary_metrics\u001b[49m(test_imputed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincident_cad\u001b[39m\u001b[38;5;124m\"\u001b[39m], test_imputed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cal_binary_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "cal_binary_metrics(test_imputed[\"incident_cad\"], test_imputed[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "\n",
    "from tqdm.rich import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "\n",
    "def generate_multipletests_result(df, pvalue_col=\"pvalue\", alpha=0.05, method=\"fdr_bh\"):\n",
    "    df = df.copy()\n",
    "    pvalue_series = df[pvalue_col]\n",
    "    reject, pvals_corrected, _, _ = multipletests(\n",
    "        pvalue_series, alpha=alpha, method=\"fdr_bh\"\n",
    "    )\n",
    "    df[\"pval_corrected\"] = pvals_corrected\n",
    "    df[\"reject\"] = reject\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_best_cutoff(fpr, tpr, thresholds):\n",
    "    diff = tpr - fpr\n",
    "    Youden_index = np.argmax(diff)\n",
    "    optimal_threshold = thresholds[Youden_index]\n",
    "    optimal_FPR, optimal_TPR = fpr[Youden_index], tpr[Youden_index]\n",
    "    return optimal_threshold, optimal_FPR, optimal_TPR\n",
    "\n",
    "\n",
    "def cal_binary_metrics(y, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_pred)\n",
    "    AUC = roc_auc_score(y, y_pred)\n",
    "    # by best youden\n",
    "\n",
    "    optim_threshold, optim_fpr, optim_tpr = find_best_cutoff(fpr, tpr, thresholds)\n",
    "    y_pred_binary = (y_pred > optim_threshold).astype(int)\n",
    "    ACC = accuracy_score(y, y_pred_binary)\n",
    "    macro_f1 = f1_score(y, y_pred_binary, average=\"macro\")\n",
    "    sensitivity = optim_tpr\n",
    "    specificity = 1 - optim_fpr\n",
    "    precision, recall, _ = precision_recall_curve(y, y_pred)\n",
    "    APR = auc(recall, precision)\n",
    "\n",
    "    return {\n",
    "        \"AUC\": AUC,\n",
    "        \"ACC\": ACC,\n",
    "        \"Macro_F1\": macro_f1,\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"APR\": APR,\n",
    "    }\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.rich import tqdm\n",
    "\n",
    "# 定义神经网络模型\n",
    "\n",
    "\n",
    "class LinearResBlock(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearResBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "        self.batch_norm = nn.LayerNorm(output_size)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.fc1.weight, nonlinearity=\"relu\")  # <6>\n",
    "\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)  # <7>\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "\n",
    "\n",
    "class FullyConnectedNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_resblocks=3):\n",
    "        super(FullyConnectedNet, self).__init__()\n",
    "        self.norm = nn.LayerNorm(input_size)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *[LinearResBlock(hidden_size, hidden_size) for _ in range(num_resblocks)]\n",
    "        )\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        out = torch.relu(self.fc1(x))\n",
    "        out = self.resblocks(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# 定义训练函数\n",
    "def train(model, dataset, criterion, optimizer, num_epochs):\n",
    "    train_loader = dataset.train_dataloader()\n",
    "    val_loader = dataset.test_dataloader()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        auroc = torchmetrics.AUROC(num_classes=2, task=\"multiclass\")\n",
    "        for inputs, labels in tqdm(\n",
    "            train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", total=len(train_loader)\n",
    "        ):\n",
    "            inputs, labels = inputs.to(\"cuda:0\"), labels.to(\"cuda:0\")\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.squeeze(-1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            auroc.update(torch.softmax(outputs, dim=-1), torch.argmax(labels, dim=1))\n",
    "        auc = auroc.compute()\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, AUC: {auc}\"\n",
    "        )\n",
    "        if epoch % 1 == 0:\n",
    "            test_auc = torchmetrics.AUROC(num_classes=2, task=\"multiclass\")\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(\"cuda:0\"), labels.to(\"cuda:0\")\n",
    "                outputs = model(inputs)\n",
    "                test_auc.update(\n",
    "                    torch.softmax(outputs, dim=-1), torch.argmax(labels, dim=1)\n",
    "                )\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Test AUC: {test_auc.compute()}\")\n",
    "    # test_auc = torchmetrics.AUROC(num_classes=2, task=\"multiclass\")\n",
    "    # for inputs, labels in dataset.test_dataloader():\n",
    "    #     inputs, labels = inputs.to(\"cuda:0\"), labels.to(\"cuda:0\")\n",
    "    #     outputs = model(inputs)\n",
    "    #     test_auc.update(torch.softmax(outputs, dim=-1), torch.argmax(labels, dim=1))\n",
    "    # print(f\"Test AUC: {test_auc.compute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置训练参数\n",
    "input_size = len(proteomics)  # 输入特征维度\n",
    "hidden_size = 512  # 隐藏层维度\n",
    "output_size = 2  # 输出类别数\n",
    "learning_rate = 5e-4\n",
    "batch_size = 256\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "# 创建模型实例\n",
    "best_model = FullyConnectedNet(\n",
    "    input_size=len(proteomics), hidden_size=256, output_size=2, num_resblocks=6\n",
    ")\n",
    "best_model.to(\"cuda:0\")\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.Tensor([0.1, 100]).to(\"cuda:0\"))\n",
    "optimizer = optim.NAdam(best_model.parameters(), lr=learning_rate, weight_decay=5e-3)\n",
    "\n",
    "\n",
    "# 开始训练\n",
    "train(best_model, dataset, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_list = []\n",
    "AUC = torchmetrics.AUROC(num_classes=2, task=\"multiclass\")\n",
    "\n",
    "best_model.eval()\n",
    "for x, y in dataset.test_dataloader():\n",
    "    y_pred = best_model(x.to(\"cuda:0\")).cpu().detach()\n",
    "    y_pred_list.append(y_pred)\n",
    "    y_list.append(y)\n",
    "    AUC.update(torch.softmax(y_pred, dim=-1), torch.argmax(y, dim=1))\n",
    "\n",
    "AUC_values = AUC.compute()\n",
    "print(f\"AUC: {AUC_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.softmax(torch.cat(y_pred_list), dim=-1)[:, 1].numpy()\n",
    "y_true = torch.argmax(torch.cat(y_list), dim=1).numpy()\n",
    "\n",
    "test_df = pd.DataFrame(\n",
    "    {\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_true\": y_true,\n",
    "    }\n",
    ")\n",
    "\n",
    "cal_binary_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_binary_metrics(test_df[\"y_true\"], test_df[\"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
